2025-05-12 20:57:18,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:32,743:INFO:PyCaret RegressionExperiment
2025-05-12 21:41:32,743:INFO:Logging name: reg-default-name
2025-05-12 21:41:32,743:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:41:32,743:INFO:version 3.3.2
2025-05-12 21:41:32,743:INFO:Initializing setup()
2025-05-12 21:41:32,743:INFO:self.USI: a710
2025-05-12 21:41:32,743:INFO:self._variable_keys: {'idx', 'n_jobs_param', 'pipeline', 'memory', 'y_train', 'y_test', 'target_param', 'fold_shuffle_param', 'gpu_param', 'logging_param', '_ml_usecase', '_available_plots', 'transform_target_param', 'exp_name_log', 'X', 'data', 'log_plots_param', 'fold_generator', 'USI', 'exp_id', 'gpu_n_jobs_param', 'y', 'html_param', 'X_train', 'X_test', 'seed', 'fold_groups_param'}
2025-05-12 21:41:32,743:INFO:Checking environment
2025-05-12 21:41:32,743:INFO:python_version: 3.11.0
2025-05-12 21:41:32,743:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 21:41:32,743:INFO:machine: AMD64
2025-05-12 21:41:32,743:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 21:41:32,755:INFO:Memory: svmem(total=12759322624, available=1693810688, percent=86.7, used=11065511936, free=1693810688)
2025-05-12 21:41:32,756:INFO:Physical Core: 4
2025-05-12 21:41:32,758:INFO:Logical Core: 8
2025-05-12 21:41:32,758:INFO:Checking libraries
2025-05-12 21:41:32,758:INFO:System:
2025-05-12 21:41:32,759:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 21:41:32,759:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:41:32,759:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 21:41:32,759:INFO:PyCaret required dependencies:
2025-05-12 21:41:32,949:INFO:                 pip: 22.3
2025-05-12 21:41:32,950:INFO:          setuptools: 65.5.0
2025-05-12 21:41:32,950:INFO:             pycaret: 3.3.2
2025-05-12 21:41:32,950:INFO:             IPython: 9.2.0
2025-05-12 21:41:32,950:INFO:          ipywidgets: 8.1.7
2025-05-12 21:41:32,950:INFO:                tqdm: 4.67.1
2025-05-12 21:41:32,950:INFO:               numpy: 1.26.4
2025-05-12 21:41:32,950:INFO:              pandas: 2.1.4
2025-05-12 21:41:32,950:INFO:              jinja2: 3.1.6
2025-05-12 21:41:32,950:INFO:               scipy: 1.11.4
2025-05-12 21:41:32,950:INFO:              joblib: 1.3.2
2025-05-12 21:41:32,950:INFO:             sklearn: 1.4.2
2025-05-12 21:41:32,950:INFO:                pyod: 2.0.5
2025-05-12 21:41:32,950:INFO:            imblearn: 0.13.0
2025-05-12 21:41:32,950:INFO:   category_encoders: 2.7.0
2025-05-12 21:41:32,950:INFO:            lightgbm: 4.6.0
2025-05-12 21:41:32,951:INFO:               numba: 0.61.2
2025-05-12 21:41:32,951:INFO:            requests: 2.32.3
2025-05-12 21:41:32,951:INFO:          matplotlib: 3.7.5
2025-05-12 21:41:32,951:INFO:          scikitplot: 0.3.7
2025-05-12 21:41:32,951:INFO:         yellowbrick: 1.5
2025-05-12 21:41:32,951:INFO:              plotly: 5.24.1
2025-05-12 21:41:32,951:INFO:    plotly-resampler: Not installed
2025-05-12 21:41:32,951:INFO:             kaleido: 0.2.1
2025-05-12 21:41:32,951:INFO:           schemdraw: 0.15
2025-05-12 21:41:32,951:INFO:         statsmodels: 0.14.4
2025-05-12 21:41:32,952:INFO:              sktime: 0.26.0
2025-05-12 21:41:32,952:INFO:               tbats: 1.1.3
2025-05-12 21:41:32,952:INFO:            pmdarima: 2.0.4
2025-05-12 21:41:32,952:INFO:              psutil: 7.0.0
2025-05-12 21:41:32,952:INFO:          markupsafe: 3.0.2
2025-05-12 21:41:32,953:INFO:             pickle5: Not installed
2025-05-12 21:41:32,953:INFO:         cloudpickle: 3.1.1
2025-05-12 21:41:32,953:INFO:         deprecation: 2.1.0
2025-05-12 21:41:32,954:INFO:              xxhash: 3.5.0
2025-05-12 21:41:32,955:INFO:           wurlitzer: Not installed
2025-05-12 21:41:32,955:INFO:PyCaret optional dependencies:
2025-05-12 21:41:32,995:INFO:                shap: Not installed
2025-05-12 21:41:32,995:INFO:           interpret: Not installed
2025-05-12 21:41:32,995:INFO:                umap: Not installed
2025-05-12 21:41:32,995:INFO:     ydata_profiling: Not installed
2025-05-12 21:41:32,995:INFO:  explainerdashboard: Not installed
2025-05-12 21:41:32,995:INFO:             autoviz: Not installed
2025-05-12 21:41:32,995:INFO:           fairlearn: Not installed
2025-05-12 21:41:32,995:INFO:          deepchecks: Not installed
2025-05-12 21:41:32,995:INFO:             xgboost: Not installed
2025-05-12 21:41:32,995:INFO:            catboost: Not installed
2025-05-12 21:41:32,995:INFO:              kmodes: Not installed
2025-05-12 21:41:32,996:INFO:             mlxtend: Not installed
2025-05-12 21:41:32,996:INFO:       statsforecast: Not installed
2025-05-12 21:41:32,996:INFO:        tune_sklearn: Not installed
2025-05-12 21:41:32,996:INFO:                 ray: Not installed
2025-05-12 21:41:32,996:INFO:            hyperopt: Not installed
2025-05-12 21:41:32,996:INFO:              optuna: Not installed
2025-05-12 21:41:32,996:INFO:               skopt: Not installed
2025-05-12 21:41:32,996:INFO:              mlflow: Not installed
2025-05-12 21:41:32,996:INFO:              gradio: Not installed
2025-05-12 21:41:32,996:INFO:             fastapi: Not installed
2025-05-12 21:41:32,996:INFO:             uvicorn: Not installed
2025-05-12 21:41:32,996:INFO:              m2cgen: Not installed
2025-05-12 21:41:32,996:INFO:           evidently: Not installed
2025-05-12 21:41:32,996:INFO:               fugue: Not installed
2025-05-12 21:41:32,997:INFO:           streamlit: Not installed
2025-05-12 21:41:32,997:INFO:             prophet: Not installed
2025-05-12 21:41:32,997:INFO:None
2025-05-12 21:41:32,997:INFO:Set up data.
2025-05-12 21:41:33,015:INFO:Set up folding strategy.
2025-05-12 21:41:33,015:INFO:Set up train/test split.
2025-05-12 21:41:33,096:INFO:Set up index.
2025-05-12 21:41:33,098:INFO:Assigning column types.
2025-05-12 21:41:33,108:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:41:33,109:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,118:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,326:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,474:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:41:33,479:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,484:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,603:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,711:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:41:33,720:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,947:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:41:34,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:41:34,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,559:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:41:34,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,783:INFO:Preparing preprocessing pipeline...
2025-05-12 21:41:34,783:INFO:Set up simple imputation.
2025-05-12 21:41:34,788:INFO:Set up encoding of categorical features.
2025-05-12 21:41:34,789:INFO:Set up feature normalization.
2025-05-12 21:41:34,845:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:41:34,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:41:34,854:INFO:Creating final display dataframe.
2025-05-12 21:41:34,997:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              a710
2025-05-12 21:41:35,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,232:INFO:setup() successfully completed in 2.49s...............
2025-05-12 21:41:57,222:INFO:Initializing compare_models()
2025-05-12 21:41:57,222:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:41:57,222:INFO:Checking exceptions
2025-05-12 21:41:57,226:INFO:Preparing display monitor
2025-05-12 21:41:57,284:INFO:Initializing Linear Regression
2025-05-12 21:41:57,284:INFO:Total runtime is 0.0 minutes
2025-05-12 21:41:57,294:INFO:SubProcess create_model() called ==================================
2025-05-12 21:41:57,296:INFO:Initializing create_model()
2025-05-12 21:41:57,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:41:57,296:INFO:Checking exceptions
2025-05-12 21:41:57,296:INFO:Importing libraries
2025-05-12 21:41:57,297:INFO:Copying training dataset
2025-05-12 21:41:57,305:INFO:Defining folds
2025-05-12 21:41:57,305:INFO:Declaring metric variables
2025-05-12 21:41:57,316:INFO:Importing untrained model
2025-05-12 21:41:57,322:INFO:Linear Regression Imported successfully
2025-05-12 21:41:57,331:INFO:Starting cross validation
2025-05-12 21:41:57,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:11,081:INFO:Calculating mean and std
2025-05-12 21:42:11,084:INFO:Creating metrics dataframe
2025-05-12 21:42:11,088:INFO:Uploading results into container
2025-05-12 21:42:11,090:INFO:Uploading model into container now
2025-05-12 21:42:11,091:INFO:_master_model_container: 1
2025-05-12 21:42:11,092:INFO:_display_container: 2
2025-05-12 21:42:11,092:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:11,093:INFO:create_model() successfully completed......................................
2025-05-12 21:42:11,203:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:11,203:INFO:Creating metrics dataframe
2025-05-12 21:42:11,214:INFO:Initializing Lasso Regression
2025-05-12 21:42:11,215:INFO:Total runtime is 0.23218616247177123 minutes
2025-05-12 21:42:11,223:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:11,223:INFO:Initializing create_model()
2025-05-12 21:42:11,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:11,224:INFO:Checking exceptions
2025-05-12 21:42:11,224:INFO:Importing libraries
2025-05-12 21:42:11,224:INFO:Copying training dataset
2025-05-12 21:42:11,231:INFO:Defining folds
2025-05-12 21:42:11,231:INFO:Declaring metric variables
2025-05-12 21:42:11,238:INFO:Importing untrained model
2025-05-12 21:42:11,244:INFO:Lasso Regression Imported successfully
2025-05-12 21:42:11,258:INFO:Starting cross validation
2025-05-12 21:42:11,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:11,602:INFO:Calculating mean and std
2025-05-12 21:42:11,604:INFO:Creating metrics dataframe
2025-05-12 21:42:11,609:INFO:Uploading results into container
2025-05-12 21:42:11,611:INFO:Uploading model into container now
2025-05-12 21:42:11,611:INFO:_master_model_container: 2
2025-05-12 21:42:11,611:INFO:_display_container: 2
2025-05-12 21:42:11,612:INFO:Lasso(random_state=123)
2025-05-12 21:42:11,612:INFO:create_model() successfully completed......................................
2025-05-12 21:42:11,705:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:11,705:INFO:Creating metrics dataframe
2025-05-12 21:42:11,715:INFO:Initializing Ridge Regression
2025-05-12 21:42:11,716:INFO:Total runtime is 0.2405272841453552 minutes
2025-05-12 21:42:11,722:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:11,723:INFO:Initializing create_model()
2025-05-12 21:42:11,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:11,723:INFO:Checking exceptions
2025-05-12 21:42:11,723:INFO:Importing libraries
2025-05-12 21:42:11,723:INFO:Copying training dataset
2025-05-12 21:42:11,730:INFO:Defining folds
2025-05-12 21:42:11,730:INFO:Declaring metric variables
2025-05-12 21:42:11,736:INFO:Importing untrained model
2025-05-12 21:42:11,746:INFO:Ridge Regression Imported successfully
2025-05-12 21:42:11,761:INFO:Starting cross validation
2025-05-12 21:42:11,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:12,120:INFO:Calculating mean and std
2025-05-12 21:42:12,122:INFO:Creating metrics dataframe
2025-05-12 21:42:12,125:INFO:Uploading results into container
2025-05-12 21:42:12,126:INFO:Uploading model into container now
2025-05-12 21:42:12,127:INFO:_master_model_container: 3
2025-05-12 21:42:12,127:INFO:_display_container: 2
2025-05-12 21:42:12,128:INFO:Ridge(random_state=123)
2025-05-12 21:42:12,128:INFO:create_model() successfully completed......................................
2025-05-12 21:42:12,238:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:12,238:INFO:Creating metrics dataframe
2025-05-12 21:42:12,252:INFO:Initializing Elastic Net
2025-05-12 21:42:12,252:INFO:Total runtime is 0.24947164853413897 minutes
2025-05-12 21:42:12,260:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:12,260:INFO:Initializing create_model()
2025-05-12 21:42:12,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:12,261:INFO:Checking exceptions
2025-05-12 21:42:12,261:INFO:Importing libraries
2025-05-12 21:42:12,261:INFO:Copying training dataset
2025-05-12 21:42:12,271:INFO:Defining folds
2025-05-12 21:42:12,271:INFO:Declaring metric variables
2025-05-12 21:42:12,277:INFO:Importing untrained model
2025-05-12 21:42:12,288:INFO:Elastic Net Imported successfully
2025-05-12 21:42:12,299:INFO:Starting cross validation
2025-05-12 21:42:12,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:12,621:INFO:Calculating mean and std
2025-05-12 21:42:12,623:INFO:Creating metrics dataframe
2025-05-12 21:42:12,625:INFO:Uploading results into container
2025-05-12 21:42:12,626:INFO:Uploading model into container now
2025-05-12 21:42:12,626:INFO:_master_model_container: 4
2025-05-12 21:42:12,626:INFO:_display_container: 2
2025-05-12 21:42:12,627:INFO:ElasticNet(random_state=123)
2025-05-12 21:42:12,627:INFO:create_model() successfully completed......................................
2025-05-12 21:42:12,712:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:12,712:INFO:Creating metrics dataframe
2025-05-12 21:42:12,722:INFO:Initializing Least Angle Regression
2025-05-12 21:42:12,723:INFO:Total runtime is 0.25730806191762284 minutes
2025-05-12 21:42:12,728:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:12,729:INFO:Initializing create_model()
2025-05-12 21:42:12,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:12,729:INFO:Checking exceptions
2025-05-12 21:42:12,729:INFO:Importing libraries
2025-05-12 21:42:12,729:INFO:Copying training dataset
2025-05-12 21:42:12,739:INFO:Defining folds
2025-05-12 21:42:12,739:INFO:Declaring metric variables
2025-05-12 21:42:12,744:INFO:Importing untrained model
2025-05-12 21:42:12,753:INFO:Least Angle Regression Imported successfully
2025-05-12 21:42:12,764:INFO:Starting cross validation
2025-05-12 21:42:12,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:13,162:INFO:Calculating mean and std
2025-05-12 21:42:13,164:INFO:Creating metrics dataframe
2025-05-12 21:42:13,168:INFO:Uploading results into container
2025-05-12 21:42:13,169:INFO:Uploading model into container now
2025-05-12 21:42:13,170:INFO:_master_model_container: 5
2025-05-12 21:42:13,170:INFO:_display_container: 2
2025-05-12 21:42:13,171:INFO:Lars(random_state=123)
2025-05-12 21:42:13,171:INFO:create_model() successfully completed......................................
2025-05-12 21:42:13,274:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:13,274:INFO:Creating metrics dataframe
2025-05-12 21:42:13,289:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:42:13,289:INFO:Total runtime is 0.26675569216410316 minutes
2025-05-12 21:42:13,294:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:13,296:INFO:Initializing create_model()
2025-05-12 21:42:13,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:13,297:INFO:Checking exceptions
2025-05-12 21:42:13,298:INFO:Importing libraries
2025-05-12 21:42:13,298:INFO:Copying training dataset
2025-05-12 21:42:13,310:INFO:Defining folds
2025-05-12 21:42:13,311:INFO:Declaring metric variables
2025-05-12 21:42:13,321:INFO:Importing untrained model
2025-05-12 21:42:13,330:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:42:13,343:INFO:Starting cross validation
2025-05-12 21:42:13,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:13,653:INFO:Calculating mean and std
2025-05-12 21:42:13,656:INFO:Creating metrics dataframe
2025-05-12 21:42:13,660:INFO:Uploading results into container
2025-05-12 21:42:13,661:INFO:Uploading model into container now
2025-05-12 21:42:13,662:INFO:_master_model_container: 6
2025-05-12 21:42:13,662:INFO:_display_container: 2
2025-05-12 21:42:13,663:INFO:LassoLars(random_state=123)
2025-05-12 21:42:13,663:INFO:create_model() successfully completed......................................
2025-05-12 21:42:13,765:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:13,765:INFO:Creating metrics dataframe
2025-05-12 21:42:13,779:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:42:13,779:INFO:Total runtime is 0.27492601474126177 minutes
2025-05-12 21:42:13,786:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:13,787:INFO:Initializing create_model()
2025-05-12 21:42:13,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:13,787:INFO:Checking exceptions
2025-05-12 21:42:13,788:INFO:Importing libraries
2025-05-12 21:42:13,788:INFO:Copying training dataset
2025-05-12 21:42:13,799:INFO:Defining folds
2025-05-12 21:42:13,799:INFO:Declaring metric variables
2025-05-12 21:42:13,810:INFO:Importing untrained model
2025-05-12 21:42:13,820:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:42:13,840:INFO:Starting cross validation
2025-05-12 21:42:13,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,188:INFO:Calculating mean and std
2025-05-12 21:42:14,190:INFO:Creating metrics dataframe
2025-05-12 21:42:14,193:INFO:Uploading results into container
2025-05-12 21:42:14,194:INFO:Uploading model into container now
2025-05-12 21:42:14,195:INFO:_master_model_container: 7
2025-05-12 21:42:14,195:INFO:_display_container: 2
2025-05-12 21:42:14,196:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:42:14,196:INFO:create_model() successfully completed......................................
2025-05-12 21:42:14,286:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:14,286:INFO:Creating metrics dataframe
2025-05-12 21:42:14,297:INFO:Initializing Bayesian Ridge
2025-05-12 21:42:14,298:INFO:Total runtime is 0.2835631728172302 minutes
2025-05-12 21:42:14,304:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:14,304:INFO:Initializing create_model()
2025-05-12 21:42:14,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:14,304:INFO:Checking exceptions
2025-05-12 21:42:14,305:INFO:Importing libraries
2025-05-12 21:42:14,305:INFO:Copying training dataset
2025-05-12 21:42:14,311:INFO:Defining folds
2025-05-12 21:42:14,311:INFO:Declaring metric variables
2025-05-12 21:42:14,318:INFO:Importing untrained model
2025-05-12 21:42:14,326:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:42:14,341:INFO:Starting cross validation
2025-05-12 21:42:14,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,646:INFO:Calculating mean and std
2025-05-12 21:42:14,649:INFO:Creating metrics dataframe
2025-05-12 21:42:14,652:INFO:Uploading results into container
2025-05-12 21:42:14,654:INFO:Uploading model into container now
2025-05-12 21:42:14,655:INFO:_master_model_container: 8
2025-05-12 21:42:14,655:INFO:_display_container: 2
2025-05-12 21:42:14,655:INFO:BayesianRidge()
2025-05-12 21:42:14,655:INFO:create_model() successfully completed......................................
2025-05-12 21:42:14,746:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:14,746:INFO:Creating metrics dataframe
2025-05-12 21:42:14,760:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:42:14,761:INFO:Total runtime is 0.2912874658902486 minutes
2025-05-12 21:42:14,768:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:14,769:INFO:Initializing create_model()
2025-05-12 21:42:14,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:14,769:INFO:Checking exceptions
2025-05-12 21:42:14,769:INFO:Importing libraries
2025-05-12 21:42:14,770:INFO:Copying training dataset
2025-05-12 21:42:14,782:INFO:Defining folds
2025-05-12 21:42:14,783:INFO:Declaring metric variables
2025-05-12 21:42:14,789:INFO:Importing untrained model
2025-05-12 21:42:14,798:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:42:14,810:INFO:Starting cross validation
2025-05-12 21:42:14,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,966:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,967:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,980:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,077:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,084:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,120:INFO:Calculating mean and std
2025-05-12 21:42:15,123:INFO:Creating metrics dataframe
2025-05-12 21:42:15,126:INFO:Uploading results into container
2025-05-12 21:42:15,127:INFO:Uploading model into container now
2025-05-12 21:42:15,128:INFO:_master_model_container: 9
2025-05-12 21:42:15,129:INFO:_display_container: 2
2025-05-12 21:42:15,129:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:42:15,130:INFO:create_model() successfully completed......................................
2025-05-12 21:42:15,219:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:15,219:INFO:Creating metrics dataframe
2025-05-12 21:42:15,230:INFO:Initializing Huber Regressor
2025-05-12 21:42:15,231:INFO:Total runtime is 0.2991190433502197 minutes
2025-05-12 21:42:15,237:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:15,238:INFO:Initializing create_model()
2025-05-12 21:42:15,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:15,238:INFO:Checking exceptions
2025-05-12 21:42:15,238:INFO:Importing libraries
2025-05-12 21:42:15,238:INFO:Copying training dataset
2025-05-12 21:42:15,244:INFO:Defining folds
2025-05-12 21:42:15,244:INFO:Declaring metric variables
2025-05-12 21:42:15,250:INFO:Importing untrained model
2025-05-12 21:42:15,257:INFO:Huber Regressor Imported successfully
2025-05-12 21:42:15,269:INFO:Starting cross validation
2025-05-12 21:42:15,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:15,606:INFO:Calculating mean and std
2025-05-12 21:42:15,608:INFO:Creating metrics dataframe
2025-05-12 21:42:15,612:INFO:Uploading results into container
2025-05-12 21:42:15,612:INFO:Uploading model into container now
2025-05-12 21:42:15,613:INFO:_master_model_container: 10
2025-05-12 21:42:15,613:INFO:_display_container: 2
2025-05-12 21:42:15,614:INFO:HuberRegressor()
2025-05-12 21:42:15,614:INFO:create_model() successfully completed......................................
2025-05-12 21:42:15,718:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:15,718:INFO:Creating metrics dataframe
2025-05-12 21:42:15,736:INFO:Initializing K Neighbors Regressor
2025-05-12 21:42:15,736:INFO:Total runtime is 0.3075305501619975 minutes
2025-05-12 21:42:15,742:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:15,742:INFO:Initializing create_model()
2025-05-12 21:42:15,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:15,743:INFO:Checking exceptions
2025-05-12 21:42:15,743:INFO:Importing libraries
2025-05-12 21:42:15,743:INFO:Copying training dataset
2025-05-12 21:42:15,752:INFO:Defining folds
2025-05-12 21:42:15,752:INFO:Declaring metric variables
2025-05-12 21:42:15,760:INFO:Importing untrained model
2025-05-12 21:42:15,769:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:42:15,784:INFO:Starting cross validation
2025-05-12 21:42:15,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:16,168:INFO:Calculating mean and std
2025-05-12 21:42:16,172:INFO:Creating metrics dataframe
2025-05-12 21:42:16,179:INFO:Uploading results into container
2025-05-12 21:42:16,180:INFO:Uploading model into container now
2025-05-12 21:42:16,181:INFO:_master_model_container: 11
2025-05-12 21:42:16,181:INFO:_display_container: 2
2025-05-12 21:42:16,182:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:42:16,182:INFO:create_model() successfully completed......................................
2025-05-12 21:42:16,262:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:16,262:INFO:Creating metrics dataframe
2025-05-12 21:42:16,275:INFO:Initializing Decision Tree Regressor
2025-05-12 21:42:16,276:INFO:Total runtime is 0.31653995911280314 minutes
2025-05-12 21:42:16,280:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:16,280:INFO:Initializing create_model()
2025-05-12 21:42:16,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:16,281:INFO:Checking exceptions
2025-05-12 21:42:16,281:INFO:Importing libraries
2025-05-12 21:42:16,281:INFO:Copying training dataset
2025-05-12 21:42:16,287:INFO:Defining folds
2025-05-12 21:42:16,288:INFO:Declaring metric variables
2025-05-12 21:42:16,293:INFO:Importing untrained model
2025-05-12 21:42:16,301:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:42:16,352:INFO:Starting cross validation
2025-05-12 21:42:16,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:16,683:INFO:Calculating mean and std
2025-05-12 21:42:16,685:INFO:Creating metrics dataframe
2025-05-12 21:42:16,690:INFO:Uploading results into container
2025-05-12 21:42:16,691:INFO:Uploading model into container now
2025-05-12 21:42:16,691:INFO:_master_model_container: 12
2025-05-12 21:42:16,692:INFO:_display_container: 2
2025-05-12 21:42:16,693:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:42:16,693:INFO:create_model() successfully completed......................................
2025-05-12 21:42:16,787:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:16,788:INFO:Creating metrics dataframe
2025-05-12 21:42:16,802:INFO:Initializing Random Forest Regressor
2025-05-12 21:42:16,802:INFO:Total runtime is 0.3253070036570231 minutes
2025-05-12 21:42:16,808:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:16,809:INFO:Initializing create_model()
2025-05-12 21:42:16,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:16,809:INFO:Checking exceptions
2025-05-12 21:42:16,809:INFO:Importing libraries
2025-05-12 21:42:16,810:INFO:Copying training dataset
2025-05-12 21:42:16,817:INFO:Defining folds
2025-05-12 21:42:16,817:INFO:Declaring metric variables
2025-05-12 21:42:16,824:INFO:Importing untrained model
2025-05-12 21:42:16,834:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:42:16,850:INFO:Starting cross validation
2025-05-12 21:42:16,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:18,063:INFO:Calculating mean and std
2025-05-12 21:42:18,066:INFO:Creating metrics dataframe
2025-05-12 21:42:18,072:INFO:Uploading results into container
2025-05-12 21:42:18,073:INFO:Uploading model into container now
2025-05-12 21:42:18,074:INFO:_master_model_container: 13
2025-05-12 21:42:18,074:INFO:_display_container: 2
2025-05-12 21:42:18,075:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:18,075:INFO:create_model() successfully completed......................................
2025-05-12 21:42:18,179:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:18,179:INFO:Creating metrics dataframe
2025-05-12 21:42:18,205:INFO:Initializing Extra Trees Regressor
2025-05-12 21:42:18,205:INFO:Total runtime is 0.34867718219757077 minutes
2025-05-12 21:42:18,212:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:18,213:INFO:Initializing create_model()
2025-05-12 21:42:18,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:18,213:INFO:Checking exceptions
2025-05-12 21:42:18,213:INFO:Importing libraries
2025-05-12 21:42:18,213:INFO:Copying training dataset
2025-05-12 21:42:18,223:INFO:Defining folds
2025-05-12 21:42:18,223:INFO:Declaring metric variables
2025-05-12 21:42:18,233:INFO:Importing untrained model
2025-05-12 21:42:18,241:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:42:18,255:INFO:Starting cross validation
2025-05-12 21:42:18,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:19,306:INFO:Calculating mean and std
2025-05-12 21:42:19,308:INFO:Creating metrics dataframe
2025-05-12 21:42:19,311:INFO:Uploading results into container
2025-05-12 21:42:19,313:INFO:Uploading model into container now
2025-05-12 21:42:19,313:INFO:_master_model_container: 14
2025-05-12 21:42:19,314:INFO:_display_container: 2
2025-05-12 21:42:19,315:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:19,315:INFO:create_model() successfully completed......................................
2025-05-12 21:42:19,408:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:19,408:INFO:Creating metrics dataframe
2025-05-12 21:42:19,424:INFO:Initializing AdaBoost Regressor
2025-05-12 21:42:19,424:INFO:Total runtime is 0.3690035939216613 minutes
2025-05-12 21:42:19,429:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:19,429:INFO:Initializing create_model()
2025-05-12 21:42:19,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:19,430:INFO:Checking exceptions
2025-05-12 21:42:19,430:INFO:Importing libraries
2025-05-12 21:42:19,430:INFO:Copying training dataset
2025-05-12 21:42:19,437:INFO:Defining folds
2025-05-12 21:42:19,437:INFO:Declaring metric variables
2025-05-12 21:42:19,444:INFO:Importing untrained model
2025-05-12 21:42:19,452:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:42:19,464:INFO:Starting cross validation
2025-05-12 21:42:19,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:20,047:INFO:Calculating mean and std
2025-05-12 21:42:20,050:INFO:Creating metrics dataframe
2025-05-12 21:42:20,053:INFO:Uploading results into container
2025-05-12 21:42:20,055:INFO:Uploading model into container now
2025-05-12 21:42:20,055:INFO:_master_model_container: 15
2025-05-12 21:42:20,055:INFO:_display_container: 2
2025-05-12 21:42:20,056:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:42:20,056:INFO:create_model() successfully completed......................................
2025-05-12 21:42:20,144:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:20,144:INFO:Creating metrics dataframe
2025-05-12 21:42:20,158:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:42:20,159:INFO:Total runtime is 0.3812346736590067 minutes
2025-05-12 21:42:20,163:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:20,163:INFO:Initializing create_model()
2025-05-12 21:42:20,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:20,163:INFO:Checking exceptions
2025-05-12 21:42:20,164:INFO:Importing libraries
2025-05-12 21:42:20,164:INFO:Copying training dataset
2025-05-12 21:42:20,171:INFO:Defining folds
2025-05-12 21:42:20,171:INFO:Declaring metric variables
2025-05-12 21:42:20,175:INFO:Importing untrained model
2025-05-12 21:42:20,184:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:42:20,193:INFO:Starting cross validation
2025-05-12 21:42:20,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:20,679:INFO:Calculating mean and std
2025-05-12 21:42:20,681:INFO:Creating metrics dataframe
2025-05-12 21:42:20,683:INFO:Uploading results into container
2025-05-12 21:42:20,684:INFO:Uploading model into container now
2025-05-12 21:42:20,684:INFO:_master_model_container: 16
2025-05-12 21:42:20,684:INFO:_display_container: 2
2025-05-12 21:42:20,685:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:42:20,685:INFO:create_model() successfully completed......................................
2025-05-12 21:42:20,777:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:20,778:INFO:Creating metrics dataframe
2025-05-12 21:42:20,794:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:42:20,794:INFO:Total runtime is 0.39183076222737623 minutes
2025-05-12 21:42:20,800:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:20,800:INFO:Initializing create_model()
2025-05-12 21:42:20,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:20,800:INFO:Checking exceptions
2025-05-12 21:42:20,801:INFO:Importing libraries
2025-05-12 21:42:20,801:INFO:Copying training dataset
2025-05-12 21:42:20,805:INFO:Defining folds
2025-05-12 21:42:20,805:INFO:Declaring metric variables
2025-05-12 21:42:20,810:INFO:Importing untrained model
2025-05-12 21:42:20,815:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:42:20,825:INFO:Starting cross validation
2025-05-12 21:42:20,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:21,358:INFO:Calculating mean and std
2025-05-12 21:42:21,361:INFO:Creating metrics dataframe
2025-05-12 21:42:21,366:INFO:Uploading results into container
2025-05-12 21:42:21,368:INFO:Uploading model into container now
2025-05-12 21:42:21,369:INFO:_master_model_container: 17
2025-05-12 21:42:21,369:INFO:_display_container: 2
2025-05-12 21:42:21,370:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:21,370:INFO:create_model() successfully completed......................................
2025-05-12 21:42:21,501:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:21,501:INFO:Creating metrics dataframe
2025-05-12 21:42:21,523:INFO:Initializing Dummy Regressor
2025-05-12 21:42:21,523:INFO:Total runtime is 0.4039914647738138 minutes
2025-05-12 21:42:21,534:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:21,535:INFO:Initializing create_model()
2025-05-12 21:42:21,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:21,536:INFO:Checking exceptions
2025-05-12 21:42:21,536:INFO:Importing libraries
2025-05-12 21:42:21,536:INFO:Copying training dataset
2025-05-12 21:42:21,546:INFO:Defining folds
2025-05-12 21:42:21,546:INFO:Declaring metric variables
2025-05-12 21:42:21,557:INFO:Importing untrained model
2025-05-12 21:42:21,570:INFO:Dummy Regressor Imported successfully
2025-05-12 21:42:21,583:INFO:Starting cross validation
2025-05-12 21:42:21,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:21,962:INFO:Calculating mean and std
2025-05-12 21:42:21,967:INFO:Creating metrics dataframe
2025-05-12 21:42:21,972:INFO:Uploading results into container
2025-05-12 21:42:21,974:INFO:Uploading model into container now
2025-05-12 21:42:21,975:INFO:_master_model_container: 18
2025-05-12 21:42:21,975:INFO:_display_container: 2
2025-05-12 21:42:21,976:INFO:DummyRegressor()
2025-05-12 21:42:21,976:INFO:create_model() successfully completed......................................
2025-05-12 21:42:22,134:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:22,134:INFO:Creating metrics dataframe
2025-05-12 21:42:22,178:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:42:22,275:INFO:Initializing create_model()
2025-05-12 21:42:22,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:22,283:INFO:Checking exceptions
2025-05-12 21:42:22,302:INFO:Importing libraries
2025-05-12 21:42:22,302:INFO:Copying training dataset
2025-05-12 21:42:22,334:INFO:Defining folds
2025-05-12 21:42:22,334:INFO:Declaring metric variables
2025-05-12 21:42:22,335:INFO:Importing untrained model
2025-05-12 21:42:22,335:INFO:Declaring custom model
2025-05-12 21:42:22,339:INFO:Linear Regression Imported successfully
2025-05-12 21:42:22,344:INFO:Cross validation set to False
2025-05-12 21:42:22,344:INFO:Fitting Model
2025-05-12 21:42:22,469:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:22,469:INFO:create_model() successfully completed......................................
2025-05-12 21:42:22,653:INFO:_master_model_container: 18
2025-05-12 21:42:22,653:INFO:_display_container: 2
2025-05-12 21:42:22,654:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:22,654:INFO:compare_models() successfully completed......................................
2025-05-12 21:42:30,783:INFO:Initializing create_model()
2025-05-12 21:42:30,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:30,783:INFO:Checking exceptions
2025-05-12 21:42:30,817:INFO:Importing libraries
2025-05-12 21:42:30,817:INFO:Copying training dataset
2025-05-12 21:42:30,826:INFO:Defining folds
2025-05-12 21:42:30,827:INFO:Declaring metric variables
2025-05-12 21:42:30,836:INFO:Importing untrained model
2025-05-12 21:42:30,845:INFO:Linear Regression Imported successfully
2025-05-12 21:42:30,869:INFO:Starting cross validation
2025-05-12 21:42:30,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:31,709:INFO:Calculating mean and std
2025-05-12 21:42:31,711:INFO:Creating metrics dataframe
2025-05-12 21:42:31,734:INFO:Finalizing model
2025-05-12 21:42:31,915:INFO:Uploading results into container
2025-05-12 21:42:31,920:INFO:Uploading model into container now
2025-05-12 21:42:31,967:INFO:_master_model_container: 19
2025-05-12 21:42:31,968:INFO:_display_container: 3
2025-05-12 21:42:31,968:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:31,969:INFO:create_model() successfully completed......................................
2025-05-12 21:42:45,943:INFO:Initializing create_model()
2025-05-12 21:42:45,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:45,943:INFO:Checking exceptions
2025-05-12 21:42:45,971:INFO:Importing libraries
2025-05-12 21:42:45,971:INFO:Copying training dataset
2025-05-12 21:42:45,977:INFO:Defining folds
2025-05-12 21:42:45,979:INFO:Declaring metric variables
2025-05-12 21:42:45,986:INFO:Importing untrained model
2025-05-12 21:42:45,991:INFO:Linear Regression Imported successfully
2025-05-12 21:42:46,006:INFO:Starting cross validation
2025-05-12 21:42:46,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:46,486:INFO:Calculating mean and std
2025-05-12 21:42:46,487:INFO:Creating metrics dataframe
2025-05-12 21:42:46,499:INFO:Finalizing model
2025-05-12 21:42:46,591:INFO:Uploading results into container
2025-05-12 21:42:46,593:INFO:Uploading model into container now
2025-05-12 21:42:46,622:INFO:_master_model_container: 20
2025-05-12 21:42:46,623:INFO:_display_container: 4
2025-05-12 21:42:46,624:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:46,624:INFO:create_model() successfully completed......................................
2025-05-12 21:43:57,722:INFO:Initializing tune_model()
2025-05-12 21:43:57,722:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:43:57,722:INFO:Checking exceptions
2025-05-12 21:43:57,747:INFO:Copying training dataset
2025-05-12 21:43:57,752:INFO:Checking base model
2025-05-12 21:43:57,752:INFO:Base model : Linear Regression
2025-05-12 21:43:57,760:INFO:Declaring metric variables
2025-05-12 21:43:57,766:INFO:Defining Hyperparameters
2025-05-12 21:43:57,766:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:43:57,916:INFO:Tuning with n_jobs=-1
2025-05-12 21:43:57,917:INFO:Initializing GridSearchCV
2025-05-12 21:43:58,618:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:43:58,618:INFO:Hyperparameter search completed
2025-05-12 21:43:58,619:INFO:SubProcess create_model() called ==================================
2025-05-12 21:43:58,620:INFO:Initializing create_model()
2025-05-12 21:43:58,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021218DEF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:43:58,620:INFO:Checking exceptions
2025-05-12 21:43:58,621:INFO:Importing libraries
2025-05-12 21:43:58,621:INFO:Copying training dataset
2025-05-12 21:43:58,631:INFO:Defining folds
2025-05-12 21:43:58,631:INFO:Declaring metric variables
2025-05-12 21:43:58,639:INFO:Importing untrained model
2025-05-12 21:43:58,639:INFO:Declaring custom model
2025-05-12 21:43:58,646:INFO:Linear Regression Imported successfully
2025-05-12 21:43:58,665:INFO:Starting cross validation
2025-05-12 21:43:58,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:43:59,139:INFO:Calculating mean and std
2025-05-12 21:43:59,143:INFO:Creating metrics dataframe
2025-05-12 21:43:59,162:INFO:Finalizing model
2025-05-12 21:43:59,292:INFO:Uploading results into container
2025-05-12 21:43:59,294:INFO:Uploading model into container now
2025-05-12 21:43:59,295:INFO:_master_model_container: 21
2025-05-12 21:43:59,295:INFO:_display_container: 5
2025-05-12 21:43:59,296:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,296:INFO:create_model() successfully completed......................................
2025-05-12 21:43:59,407:INFO:SubProcess create_model() end ==================================
2025-05-12 21:43:59,408:INFO:choose_better activated
2025-05-12 21:43:59,412:INFO:SubProcess create_model() called ==================================
2025-05-12 21:43:59,413:INFO:Initializing create_model()
2025-05-12 21:43:59,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:43:59,413:INFO:Checking exceptions
2025-05-12 21:43:59,415:INFO:Importing libraries
2025-05-12 21:43:59,415:INFO:Copying training dataset
2025-05-12 21:43:59,421:INFO:Defining folds
2025-05-12 21:43:59,421:INFO:Declaring metric variables
2025-05-12 21:43:59,422:INFO:Importing untrained model
2025-05-12 21:43:59,422:INFO:Declaring custom model
2025-05-12 21:43:59,422:INFO:Linear Regression Imported successfully
2025-05-12 21:43:59,423:INFO:Starting cross validation
2025-05-12 21:43:59,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:43:59,725:INFO:Calculating mean and std
2025-05-12 21:43:59,727:INFO:Creating metrics dataframe
2025-05-12 21:43:59,733:INFO:Finalizing model
2025-05-12 21:43:59,822:INFO:Uploading results into container
2025-05-12 21:43:59,823:INFO:Uploading model into container now
2025-05-12 21:43:59,823:INFO:_master_model_container: 22
2025-05-12 21:43:59,824:INFO:_display_container: 6
2025-05-12 21:43:59,824:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,824:INFO:create_model() successfully completed......................................
2025-05-12 21:43:59,919:INFO:SubProcess create_model() end ==================================
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:43:59,921:INFO:choose_better completed
2025-05-12 21:43:59,921:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:43:59,933:INFO:_master_model_container: 22
2025-05-12 21:43:59,933:INFO:_display_container: 5
2025-05-12 21:43:59,934:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,934:INFO:tune_model() successfully completed......................................
2025-05-12 21:46:31,234:INFO:Initializing evaluate_model()
2025-05-12 21:46:31,234:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:46:31,243:INFO:Initializing plot_model()
2025-05-12 21:46:31,243:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:46:31,244:INFO:Checking exceptions
2025-05-12 21:46:31,247:INFO:Preloading libraries
2025-05-12 21:46:31,247:INFO:Copying training dataset
2025-05-12 21:46:31,248:INFO:Plot type: pipeline
2025-05-12 21:46:31,754:INFO:Visual Rendered Successfully
2025-05-12 21:46:31,995:INFO:plot_model() successfully completed......................................
2025-05-12 21:47:16,907:INFO:Initializing predict_model()
2025-05-12 21:47:16,908:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021219076340>)
2025-05-12 21:47:16,908:INFO:Checking exceptions
2025-05-12 21:47:16,908:INFO:Preloading libraries
2025-05-12 21:47:17,371:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:00:56,427:INFO:Initializing save_model()
2025-05-12 22:00:56,428:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:00:56,428:INFO:Adding model into prep_pipe
2025-05-12 22:00:56,439:INFO:modelo_precio_final.pkl saved in current working directory
2025-05-12 22:00:56,448:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-05-12 22:00:56,448:INFO:save_model() successfully completed......................................
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:14:10,348:INFO:PyCaret RegressionExperiment
2025-05-12 22:14:10,349:INFO:Logging name: reg-default-name
2025-05-12 22:14:10,349:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:14:10,349:INFO:version 3.3.2
2025-05-12 22:14:10,349:INFO:Initializing setup()
2025-05-12 22:14:10,349:INFO:self.USI: beb0
2025-05-12 22:14:10,349:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'html_param', 'data', 'transform_target_param', 'y', 'gpu_param', 'logging_param', 'exp_name_log', 'exp_id', 'X_test', 'pipeline', 'n_jobs_param', 'USI', 'log_plots_param', 'fold_shuffle_param', 'idx', 'y_train', '_available_plots', 'X', 'target_param', '_ml_usecase', 'memory', 'y_test', 'fold_generator', 'X_train', 'fold_groups_param'}
2025-05-12 22:14:10,349:INFO:Checking environment
2025-05-12 22:14:10,349:INFO:python_version: 3.11.0
2025-05-12 22:14:10,349:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 22:14:10,349:INFO:machine: AMD64
2025-05-12 22:14:10,349:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 22:14:10,355:INFO:Memory: svmem(total=12759322624, available=1950679040, percent=84.7, used=10808643584, free=1950679040)
2025-05-12 22:14:10,355:INFO:Physical Core: 4
2025-05-12 22:14:10,355:INFO:Logical Core: 8
2025-05-12 22:14:10,355:INFO:Checking libraries
2025-05-12 22:14:10,356:INFO:System:
2025-05-12 22:14:10,356:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 22:14:10,356:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:14:10,356:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 22:14:10,356:INFO:PyCaret required dependencies:
2025-05-12 22:14:10,400:INFO:                 pip: 22.3
2025-05-12 22:14:10,400:INFO:          setuptools: 65.5.0
2025-05-12 22:14:10,400:INFO:             pycaret: 3.3.2
2025-05-12 22:14:10,400:INFO:             IPython: 9.2.0
2025-05-12 22:14:10,400:INFO:          ipywidgets: 8.1.7
2025-05-12 22:14:10,400:INFO:                tqdm: 4.67.1
2025-05-12 22:14:10,400:INFO:               numpy: 1.26.4
2025-05-12 22:14:10,400:INFO:              pandas: 2.1.4
2025-05-12 22:14:10,400:INFO:              jinja2: 3.1.6
2025-05-12 22:14:10,400:INFO:               scipy: 1.11.4
2025-05-12 22:14:10,400:INFO:              joblib: 1.3.2
2025-05-12 22:14:10,400:INFO:             sklearn: 1.4.2
2025-05-12 22:14:10,400:INFO:                pyod: 2.0.5
2025-05-12 22:14:10,400:INFO:            imblearn: 0.13.0
2025-05-12 22:14:10,400:INFO:   category_encoders: 2.7.0
2025-05-12 22:14:10,400:INFO:            lightgbm: 4.6.0
2025-05-12 22:14:10,400:INFO:               numba: 0.61.2
2025-05-12 22:14:10,400:INFO:            requests: 2.32.3
2025-05-12 22:14:10,400:INFO:          matplotlib: 3.7.5
2025-05-12 22:14:10,400:INFO:          scikitplot: 0.3.7
2025-05-12 22:14:10,400:INFO:         yellowbrick: 1.5
2025-05-12 22:14:10,401:INFO:              plotly: 5.24.1
2025-05-12 22:14:10,401:INFO:    plotly-resampler: Not installed
2025-05-12 22:14:10,401:INFO:             kaleido: 0.2.1
2025-05-12 22:14:10,401:INFO:           schemdraw: 0.15
2025-05-12 22:14:10,401:INFO:         statsmodels: 0.14.4
2025-05-12 22:14:10,401:INFO:              sktime: 0.26.0
2025-05-12 22:14:10,401:INFO:               tbats: 1.1.3
2025-05-12 22:14:10,401:INFO:            pmdarima: 2.0.4
2025-05-12 22:14:10,401:INFO:              psutil: 7.0.0
2025-05-12 22:14:10,401:INFO:          markupsafe: 3.0.2
2025-05-12 22:14:10,401:INFO:             pickle5: Not installed
2025-05-12 22:14:10,401:INFO:         cloudpickle: 3.1.1
2025-05-12 22:14:10,401:INFO:         deprecation: 2.1.0
2025-05-12 22:14:10,401:INFO:              xxhash: 3.5.0
2025-05-12 22:14:10,401:INFO:           wurlitzer: Not installed
2025-05-12 22:14:10,401:INFO:PyCaret optional dependencies:
2025-05-12 22:14:10,418:INFO:                shap: Not installed
2025-05-12 22:14:10,419:INFO:           interpret: Not installed
2025-05-12 22:14:10,419:INFO:                umap: Not installed
2025-05-12 22:14:10,419:INFO:     ydata_profiling: Not installed
2025-05-12 22:14:10,419:INFO:  explainerdashboard: Not installed
2025-05-12 22:14:10,419:INFO:             autoviz: Not installed
2025-05-12 22:14:10,419:INFO:           fairlearn: Not installed
2025-05-12 22:14:10,419:INFO:          deepchecks: Not installed
2025-05-12 22:14:10,419:INFO:             xgboost: Not installed
2025-05-12 22:14:10,419:INFO:            catboost: Not installed
2025-05-12 22:14:10,419:INFO:              kmodes: Not installed
2025-05-12 22:14:10,419:INFO:             mlxtend: Not installed
2025-05-12 22:14:10,419:INFO:       statsforecast: Not installed
2025-05-12 22:14:10,420:INFO:        tune_sklearn: Not installed
2025-05-12 22:14:10,420:INFO:                 ray: Not installed
2025-05-12 22:14:10,420:INFO:            hyperopt: Not installed
2025-05-12 22:14:10,420:INFO:              optuna: Not installed
2025-05-12 22:14:10,420:INFO:               skopt: Not installed
2025-05-12 22:14:10,420:INFO:              mlflow: Not installed
2025-05-12 22:14:10,420:INFO:              gradio: Not installed
2025-05-12 22:14:10,420:INFO:             fastapi: Not installed
2025-05-12 22:14:10,420:INFO:             uvicorn: Not installed
2025-05-12 22:14:10,420:INFO:              m2cgen: Not installed
2025-05-12 22:14:10,420:INFO:           evidently: Not installed
2025-05-12 22:14:10,420:INFO:               fugue: Not installed
2025-05-12 22:14:10,420:INFO:           streamlit: Not installed
2025-05-12 22:14:10,421:INFO:             prophet: Not installed
2025-05-12 22:14:10,421:INFO:None
2025-05-12 22:14:10,421:INFO:Set up data.
2025-05-12 22:14:10,428:INFO:Set up folding strategy.
2025-05-12 22:14:10,428:INFO:Set up train/test split.
2025-05-12 22:14:10,436:INFO:Set up index.
2025-05-12 22:14:10,437:INFO:Assigning column types.
2025-05-12 22:14:10,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:14:10,441:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,445:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,558:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,694:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:14:10,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,708:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,855:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,950:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,011:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:14:11,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,270:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:14:11,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,572:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:14:11,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,797:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:14:11,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,052:INFO:Preparing preprocessing pipeline...
2025-05-12 22:14:12,052:INFO:Set up simple imputation.
2025-05-12 22:14:12,055:INFO:Set up encoding of categorical features.
2025-05-12 22:14:12,055:INFO:Set up feature normalization.
2025-05-12 22:15:09,876:INFO:PyCaret RegressionExperiment
2025-05-12 22:15:09,876:INFO:Logging name: reg-default-name
2025-05-12 22:15:09,876:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:15:09,876:INFO:version 3.3.2
2025-05-12 22:15:09,877:INFO:Initializing setup()
2025-05-12 22:15:09,877:INFO:self.USI: e29e
2025-05-12 22:15:09,877:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'html_param', 'data', 'transform_target_param', 'y', 'gpu_param', 'logging_param', 'exp_name_log', 'exp_id', 'X_test', 'pipeline', 'n_jobs_param', 'USI', 'log_plots_param', 'fold_shuffle_param', 'idx', 'y_train', '_available_plots', 'X', 'target_param', '_ml_usecase', 'memory', 'y_test', 'fold_generator', 'X_train', 'fold_groups_param'}
2025-05-12 22:15:09,877:INFO:Checking environment
2025-05-12 22:15:09,877:INFO:python_version: 3.11.0
2025-05-12 22:15:09,877:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 22:15:09,877:INFO:machine: AMD64
2025-05-12 22:15:09,877:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 22:15:09,905:INFO:Memory: svmem(total=12759322624, available=1700532224, percent=86.7, used=11058790400, free=1700532224)
2025-05-12 22:15:09,906:INFO:Physical Core: 4
2025-05-12 22:15:09,906:INFO:Logical Core: 8
2025-05-12 22:15:09,906:INFO:Checking libraries
2025-05-12 22:15:09,906:INFO:System:
2025-05-12 22:15:09,906:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 22:15:09,906:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:15:09,906:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 22:15:09,906:INFO:PyCaret required dependencies:
2025-05-12 22:15:09,906:INFO:                 pip: 22.3
2025-05-12 22:15:09,907:INFO:          setuptools: 65.5.0
2025-05-12 22:15:09,907:INFO:             pycaret: 3.3.2
2025-05-12 22:15:09,907:INFO:             IPython: 9.2.0
2025-05-12 22:15:09,907:INFO:          ipywidgets: 8.1.7
2025-05-12 22:15:09,907:INFO:                tqdm: 4.67.1
2025-05-12 22:15:09,907:INFO:               numpy: 1.26.4
2025-05-12 22:15:09,907:INFO:              pandas: 2.1.4
2025-05-12 22:15:09,907:INFO:              jinja2: 3.1.6
2025-05-12 22:15:09,907:INFO:               scipy: 1.11.4
2025-05-12 22:15:09,907:INFO:              joblib: 1.3.2
2025-05-12 22:15:09,907:INFO:             sklearn: 1.4.2
2025-05-12 22:15:09,908:INFO:                pyod: 2.0.5
2025-05-12 22:15:09,908:INFO:            imblearn: 0.13.0
2025-05-12 22:15:09,908:INFO:   category_encoders: 2.7.0
2025-05-12 22:15:09,908:INFO:            lightgbm: 4.6.0
2025-05-12 22:15:09,908:INFO:               numba: 0.61.2
2025-05-12 22:15:09,908:INFO:            requests: 2.32.3
2025-05-12 22:15:09,908:INFO:          matplotlib: 3.7.5
2025-05-12 22:15:09,908:INFO:          scikitplot: 0.3.7
2025-05-12 22:15:09,908:INFO:         yellowbrick: 1.5
2025-05-12 22:15:09,908:INFO:              plotly: 5.24.1
2025-05-12 22:15:09,908:INFO:    plotly-resampler: Not installed
2025-05-12 22:15:09,908:INFO:             kaleido: 0.2.1
2025-05-12 22:15:09,909:INFO:           schemdraw: 0.15
2025-05-12 22:15:09,909:INFO:         statsmodels: 0.14.4
2025-05-12 22:15:09,909:INFO:              sktime: 0.26.0
2025-05-12 22:15:09,909:INFO:               tbats: 1.1.3
2025-05-12 22:15:09,909:INFO:            pmdarima: 2.0.4
2025-05-12 22:15:09,909:INFO:              psutil: 7.0.0
2025-05-12 22:15:09,909:INFO:          markupsafe: 3.0.2
2025-05-12 22:15:09,909:INFO:             pickle5: Not installed
2025-05-12 22:15:09,909:INFO:         cloudpickle: 3.1.1
2025-05-12 22:15:09,909:INFO:         deprecation: 2.1.0
2025-05-12 22:15:09,909:INFO:              xxhash: 3.5.0
2025-05-12 22:15:09,909:INFO:           wurlitzer: Not installed
2025-05-12 22:15:09,909:INFO:PyCaret optional dependencies:
2025-05-12 22:15:09,910:INFO:                shap: Not installed
2025-05-12 22:15:09,910:INFO:           interpret: Not installed
2025-05-12 22:15:09,910:INFO:                umap: Not installed
2025-05-12 22:15:09,910:INFO:     ydata_profiling: Not installed
2025-05-12 22:15:09,910:INFO:  explainerdashboard: Not installed
2025-05-12 22:15:09,910:INFO:             autoviz: Not installed
2025-05-12 22:15:09,910:INFO:           fairlearn: Not installed
2025-05-12 22:15:09,910:INFO:          deepchecks: Not installed
2025-05-12 22:15:09,910:INFO:             xgboost: Not installed
2025-05-12 22:15:09,910:INFO:            catboost: Not installed
2025-05-12 22:15:09,910:INFO:              kmodes: Not installed
2025-05-12 22:15:09,910:INFO:             mlxtend: Not installed
2025-05-12 22:15:09,910:INFO:       statsforecast: Not installed
2025-05-12 22:15:09,911:INFO:        tune_sklearn: Not installed
2025-05-12 22:15:09,911:INFO:                 ray: Not installed
2025-05-12 22:15:09,911:INFO:            hyperopt: Not installed
2025-05-12 22:15:09,911:INFO:              optuna: Not installed
2025-05-12 22:15:09,911:INFO:               skopt: Not installed
2025-05-12 22:15:09,911:INFO:              mlflow: Not installed
2025-05-12 22:15:09,911:INFO:              gradio: Not installed
2025-05-12 22:15:09,911:INFO:             fastapi: Not installed
2025-05-12 22:15:09,911:INFO:             uvicorn: Not installed
2025-05-12 22:15:09,911:INFO:              m2cgen: Not installed
2025-05-12 22:15:09,911:INFO:           evidently: Not installed
2025-05-12 22:15:09,911:INFO:               fugue: Not installed
2025-05-12 22:15:09,911:INFO:           streamlit: Not installed
2025-05-12 22:15:09,911:INFO:             prophet: Not installed
2025-05-12 22:15:09,911:INFO:None
2025-05-12 22:15:09,911:INFO:Set up data.
2025-05-12 22:15:09,919:INFO:Set up folding strategy.
2025-05-12 22:15:09,919:INFO:Set up train/test split.
2025-05-12 22:15:09,927:INFO:Set up index.
2025-05-12 22:15:09,927:INFO:Assigning column types.
2025-05-12 22:15:09,938:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:15:09,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:15:09,958:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:09,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,104:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,116:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,252:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:15:10,258:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,444:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,542:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,611:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:15:10,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,951:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:15:11,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:15:11,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,988:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:15:12,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,386:INFO:Preparing preprocessing pipeline...
2025-05-12 22:15:12,386:INFO:Set up simple imputation.
2025-05-12 22:15:12,389:INFO:Set up encoding of categorical features.
2025-05-12 22:15:12,389:INFO:Set up feature normalization.
2025-05-12 22:15:12,488:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:15:12,501:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:15:12,501:INFO:Creating final display dataframe.
2025-05-12 22:15:12,782:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              e29e
2025-05-12 22:15:12,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,080:INFO:setup() successfully completed in 3.21s...............
2025-05-12 22:16:10,400:INFO:Initializing compare_models()
2025-05-12 22:16:10,400:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:16:10,400:INFO:Checking exceptions
2025-05-12 22:16:10,403:INFO:Preparing display monitor
2025-05-12 22:16:10,440:INFO:Initializing Linear Regression
2025-05-12 22:16:10,441:INFO:Total runtime is 1.661380132039388e-05 minutes
2025-05-12 22:16:10,448:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:10,449:INFO:Initializing create_model()
2025-05-12 22:16:10,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:10,449:INFO:Checking exceptions
2025-05-12 22:16:10,450:INFO:Importing libraries
2025-05-12 22:16:10,450:INFO:Copying training dataset
2025-05-12 22:16:10,459:INFO:Defining folds
2025-05-12 22:16:10,459:INFO:Declaring metric variables
2025-05-12 22:16:10,465:INFO:Importing untrained model
2025-05-12 22:16:10,471:INFO:Linear Regression Imported successfully
2025-05-12 22:16:10,484:INFO:Starting cross validation
2025-05-12 22:16:10,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:20,465:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:20,497:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:22,139:INFO:Calculating mean and std
2025-05-12 22:16:22,144:INFO:Creating metrics dataframe
2025-05-12 22:16:22,156:INFO:Uploading results into container
2025-05-12 22:16:22,158:INFO:Uploading model into container now
2025-05-12 22:16:22,161:INFO:_master_model_container: 1
2025-05-12 22:16:22,161:INFO:_display_container: 2
2025-05-12 22:16:22,162:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:16:22,162:INFO:create_model() successfully completed......................................
2025-05-12 22:16:22,347:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:22,348:INFO:Creating metrics dataframe
2025-05-12 22:16:22,374:INFO:Initializing Lasso Regression
2025-05-12 22:16:22,375:INFO:Total runtime is 0.1989244818687439 minutes
2025-05-12 22:16:22,384:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:22,384:INFO:Initializing create_model()
2025-05-12 22:16:22,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:22,385:INFO:Checking exceptions
2025-05-12 22:16:22,385:INFO:Importing libraries
2025-05-12 22:16:22,385:INFO:Copying training dataset
2025-05-12 22:16:22,398:INFO:Defining folds
2025-05-12 22:16:22,398:INFO:Declaring metric variables
2025-05-12 22:16:22,412:INFO:Importing untrained model
2025-05-12 22:16:22,423:INFO:Lasso Regression Imported successfully
2025-05-12 22:16:22,445:INFO:Starting cross validation
2025-05-12 22:16:22,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:22,953:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:22,953:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:22,960:INFO:Calculating mean and std
2025-05-12 22:16:22,965:INFO:Creating metrics dataframe
2025-05-12 22:16:22,973:INFO:Uploading results into container
2025-05-12 22:16:22,974:INFO:Uploading model into container now
2025-05-12 22:16:22,976:INFO:_master_model_container: 2
2025-05-12 22:16:22,976:INFO:_display_container: 2
2025-05-12 22:16:22,977:INFO:Lasso(random_state=123)
2025-05-12 22:16:22,978:INFO:create_model() successfully completed......................................
2025-05-12 22:16:23,108:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:23,108:INFO:Creating metrics dataframe
2025-05-12 22:16:23,124:INFO:Initializing Ridge Regression
2025-05-12 22:16:23,124:INFO:Total runtime is 0.21140274206797283 minutes
2025-05-12 22:16:23,131:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:23,132:INFO:Initializing create_model()
2025-05-12 22:16:23,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:23,132:INFO:Checking exceptions
2025-05-12 22:16:23,133:INFO:Importing libraries
2025-05-12 22:16:23,133:INFO:Copying training dataset
2025-05-12 22:16:23,145:INFO:Defining folds
2025-05-12 22:16:23,145:INFO:Declaring metric variables
2025-05-12 22:16:23,156:INFO:Importing untrained model
2025-05-12 22:16:23,166:INFO:Ridge Regression Imported successfully
2025-05-12 22:16:23,186:INFO:Starting cross validation
2025-05-12 22:16:23,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:23,630:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:23,631:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:23,642:INFO:Calculating mean and std
2025-05-12 22:16:23,645:INFO:Creating metrics dataframe
2025-05-12 22:16:23,649:INFO:Uploading results into container
2025-05-12 22:16:23,650:INFO:Uploading model into container now
2025-05-12 22:16:23,650:INFO:_master_model_container: 3
2025-05-12 22:16:23,651:INFO:_display_container: 2
2025-05-12 22:16:23,652:INFO:Ridge(random_state=123)
2025-05-12 22:16:23,652:INFO:create_model() successfully completed......................................
2025-05-12 22:16:23,768:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:23,769:INFO:Creating metrics dataframe
2025-05-12 22:16:23,784:INFO:Initializing Elastic Net
2025-05-12 22:16:23,784:INFO:Total runtime is 0.22240562438964845 minutes
2025-05-12 22:16:23,792:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:23,793:INFO:Initializing create_model()
2025-05-12 22:16:23,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:23,793:INFO:Checking exceptions
2025-05-12 22:16:23,793:INFO:Importing libraries
2025-05-12 22:16:23,793:INFO:Copying training dataset
2025-05-12 22:16:23,805:INFO:Defining folds
2025-05-12 22:16:23,805:INFO:Declaring metric variables
2025-05-12 22:16:23,815:INFO:Importing untrained model
2025-05-12 22:16:23,827:INFO:Elastic Net Imported successfully
2025-05-12 22:16:23,848:INFO:Starting cross validation
2025-05-12 22:16:23,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:24,302:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:24,303:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:24,310:INFO:Calculating mean and std
2025-05-12 22:16:24,312:INFO:Creating metrics dataframe
2025-05-12 22:16:24,315:INFO:Uploading results into container
2025-05-12 22:16:24,316:INFO:Uploading model into container now
2025-05-12 22:16:24,317:INFO:_master_model_container: 4
2025-05-12 22:16:24,317:INFO:_display_container: 2
2025-05-12 22:16:24,319:INFO:ElasticNet(random_state=123)
2025-05-12 22:16:24,319:INFO:create_model() successfully completed......................................
2025-05-12 22:16:24,430:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:24,431:INFO:Creating metrics dataframe
2025-05-12 22:16:24,448:INFO:Initializing Least Angle Regression
2025-05-12 22:16:24,449:INFO:Total runtime is 0.23349436124165854 minutes
2025-05-12 22:16:24,457:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:24,457:INFO:Initializing create_model()
2025-05-12 22:16:24,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:24,458:INFO:Checking exceptions
2025-05-12 22:16:24,458:INFO:Importing libraries
2025-05-12 22:16:24,458:INFO:Copying training dataset
2025-05-12 22:16:24,467:INFO:Defining folds
2025-05-12 22:16:24,467:INFO:Declaring metric variables
2025-05-12 22:16:24,477:INFO:Importing untrained model
2025-05-12 22:16:24,486:INFO:Least Angle Regression Imported successfully
2025-05-12 22:16:24,503:INFO:Starting cross validation
2025-05-12 22:16:24,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:24,960:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:24,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:24,964:INFO:Calculating mean and std
2025-05-12 22:16:24,966:INFO:Creating metrics dataframe
2025-05-12 22:16:24,971:INFO:Uploading results into container
2025-05-12 22:16:24,972:INFO:Uploading model into container now
2025-05-12 22:16:24,972:INFO:_master_model_container: 5
2025-05-12 22:16:24,972:INFO:_display_container: 2
2025-05-12 22:16:24,973:INFO:Lars(random_state=123)
2025-05-12 22:16:24,974:INFO:create_model() successfully completed......................................
2025-05-12 22:16:25,106:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:25,107:INFO:Creating metrics dataframe
2025-05-12 22:16:25,125:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:16:25,125:INFO:Total runtime is 0.24475714763005577 minutes
2025-05-12 22:16:25,134:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:25,135:INFO:Initializing create_model()
2025-05-12 22:16:25,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:25,136:INFO:Checking exceptions
2025-05-12 22:16:25,136:INFO:Importing libraries
2025-05-12 22:16:25,136:INFO:Copying training dataset
2025-05-12 22:16:25,144:INFO:Defining folds
2025-05-12 22:16:25,144:INFO:Declaring metric variables
2025-05-12 22:16:25,153:INFO:Importing untrained model
2025-05-12 22:16:25,162:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:16:25,178:INFO:Starting cross validation
2025-05-12 22:16:25,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:25,611:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:25,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:25,619:INFO:Calculating mean and std
2025-05-12 22:16:25,621:INFO:Creating metrics dataframe
2025-05-12 22:16:25,626:INFO:Uploading results into container
2025-05-12 22:16:25,627:INFO:Uploading model into container now
2025-05-12 22:16:25,628:INFO:_master_model_container: 6
2025-05-12 22:16:25,629:INFO:_display_container: 2
2025-05-12 22:16:25,630:INFO:LassoLars(random_state=123)
2025-05-12 22:16:25,630:INFO:create_model() successfully completed......................................
2025-05-12 22:16:25,753:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:25,754:INFO:Creating metrics dataframe
2025-05-12 22:16:25,775:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:16:25,776:INFO:Total runtime is 0.25560639301935834 minutes
2025-05-12 22:16:25,785:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:25,785:INFO:Initializing create_model()
2025-05-12 22:16:25,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:25,786:INFO:Checking exceptions
2025-05-12 22:16:25,787:INFO:Importing libraries
2025-05-12 22:16:25,787:INFO:Copying training dataset
2025-05-12 22:16:25,799:INFO:Defining folds
2025-05-12 22:16:25,799:INFO:Declaring metric variables
2025-05-12 22:16:25,810:INFO:Importing untrained model
2025-05-12 22:16:25,820:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:16:25,843:INFO:Starting cross validation
2025-05-12 22:16:25,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:26,438:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:26,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:26,449:INFO:Calculating mean and std
2025-05-12 22:16:26,453:INFO:Creating metrics dataframe
2025-05-12 22:16:26,465:INFO:Uploading results into container
2025-05-12 22:16:26,466:INFO:Uploading model into container now
2025-05-12 22:16:26,467:INFO:_master_model_container: 7
2025-05-12 22:16:26,467:INFO:_display_container: 2
2025-05-12 22:16:26,469:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:16:26,470:INFO:create_model() successfully completed......................................
2025-05-12 22:16:26,594:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:26,594:INFO:Creating metrics dataframe
2025-05-12 22:16:26,613:INFO:Initializing Bayesian Ridge
2025-05-12 22:16:26,613:INFO:Total runtime is 0.26956028143564864 minutes
2025-05-12 22:16:26,620:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:26,621:INFO:Initializing create_model()
2025-05-12 22:16:26,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:26,622:INFO:Checking exceptions
2025-05-12 22:16:26,622:INFO:Importing libraries
2025-05-12 22:16:26,623:INFO:Copying training dataset
2025-05-12 22:16:26,632:INFO:Defining folds
2025-05-12 22:16:26,632:INFO:Declaring metric variables
2025-05-12 22:16:26,642:INFO:Importing untrained model
2025-05-12 22:16:26,652:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:16:26,675:INFO:Starting cross validation
2025-05-12 22:16:26,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:27,333:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:27,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:27,361:INFO:Calculating mean and std
2025-05-12 22:16:27,364:INFO:Creating metrics dataframe
2025-05-12 22:16:27,370:INFO:Uploading results into container
2025-05-12 22:16:27,372:INFO:Uploading model into container now
2025-05-12 22:16:27,373:INFO:_master_model_container: 8
2025-05-12 22:16:27,373:INFO:_display_container: 2
2025-05-12 22:16:27,374:INFO:BayesianRidge()
2025-05-12 22:16:27,374:INFO:create_model() successfully completed......................................
2025-05-12 22:16:27,484:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:27,485:INFO:Creating metrics dataframe
2025-05-12 22:16:27,508:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:16:27,508:INFO:Total runtime is 0.2844772100448609 minutes
2025-05-12 22:16:27,516:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:27,516:INFO:Initializing create_model()
2025-05-12 22:16:27,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:27,517:INFO:Checking exceptions
2025-05-12 22:16:27,517:INFO:Importing libraries
2025-05-12 22:16:27,519:INFO:Copying training dataset
2025-05-12 22:16:27,533:INFO:Defining folds
2025-05-12 22:16:27,534:INFO:Declaring metric variables
2025-05-12 22:16:27,548:INFO:Importing untrained model
2025-05-12 22:16:27,561:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:16:27,582:INFO:Starting cross validation
2025-05-12 22:16:27,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:28,277:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:28,278:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:28,288:INFO:Calculating mean and std
2025-05-12 22:16:28,291:INFO:Creating metrics dataframe
2025-05-12 22:16:28,295:INFO:Uploading results into container
2025-05-12 22:16:28,296:INFO:Uploading model into container now
2025-05-12 22:16:28,297:INFO:_master_model_container: 9
2025-05-12 22:16:28,297:INFO:_display_container: 2
2025-05-12 22:16:28,298:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:16:28,299:INFO:create_model() successfully completed......................................
2025-05-12 22:16:28,439:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:28,439:INFO:Creating metrics dataframe
2025-05-12 22:16:28,459:INFO:Initializing Huber Regressor
2025-05-12 22:16:28,459:INFO:Total runtime is 0.3003216147422791 minutes
2025-05-12 22:16:28,467:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:28,468:INFO:Initializing create_model()
2025-05-12 22:16:28,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:28,469:INFO:Checking exceptions
2025-05-12 22:16:28,469:INFO:Importing libraries
2025-05-12 22:16:28,469:INFO:Copying training dataset
2025-05-12 22:16:28,478:INFO:Defining folds
2025-05-12 22:16:28,478:INFO:Declaring metric variables
2025-05-12 22:16:28,489:INFO:Importing untrained model
2025-05-12 22:16:28,495:INFO:Huber Regressor Imported successfully
2025-05-12 22:16:28,518:INFO:Starting cross validation
2025-05-12 22:16:28,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:29,583:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:29,584:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:29,593:INFO:Calculating mean and std
2025-05-12 22:16:29,595:INFO:Creating metrics dataframe
2025-05-12 22:16:29,602:INFO:Uploading results into container
2025-05-12 22:16:29,603:INFO:Uploading model into container now
2025-05-12 22:16:29,604:INFO:_master_model_container: 10
2025-05-12 22:16:29,604:INFO:_display_container: 2
2025-05-12 22:16:29,604:INFO:HuberRegressor()
2025-05-12 22:16:29,604:INFO:create_model() successfully completed......................................
2025-05-12 22:16:29,724:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:29,724:INFO:Creating metrics dataframe
2025-05-12 22:16:29,747:INFO:Initializing K Neighbors Regressor
2025-05-12 22:16:29,747:INFO:Total runtime is 0.32178559303283694 minutes
2025-05-12 22:16:29,755:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:29,756:INFO:Initializing create_model()
2025-05-12 22:16:29,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:29,757:INFO:Checking exceptions
2025-05-12 22:16:29,757:INFO:Importing libraries
2025-05-12 22:16:29,758:INFO:Copying training dataset
2025-05-12 22:16:29,766:INFO:Defining folds
2025-05-12 22:16:29,766:INFO:Declaring metric variables
2025-05-12 22:16:29,778:INFO:Importing untrained model
2025-05-12 22:16:29,790:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:16:29,814:INFO:Starting cross validation
2025-05-12 22:16:29,818:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:30,488:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:30,489:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:30,501:INFO:Calculating mean and std
2025-05-12 22:16:30,505:INFO:Creating metrics dataframe
2025-05-12 22:16:30,512:INFO:Uploading results into container
2025-05-12 22:16:30,514:INFO:Uploading model into container now
2025-05-12 22:16:30,515:INFO:_master_model_container: 11
2025-05-12 22:16:30,516:INFO:_display_container: 2
2025-05-12 22:16:30,517:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:16:30,519:INFO:create_model() successfully completed......................................
2025-05-12 22:16:30,815:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:30,815:INFO:Creating metrics dataframe
2025-05-12 22:16:30,848:INFO:Initializing Decision Tree Regressor
2025-05-12 22:16:30,848:INFO:Total runtime is 0.3401374737421672 minutes
2025-05-12 22:16:30,890:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:30,891:INFO:Initializing create_model()
2025-05-12 22:16:30,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:30,891:INFO:Checking exceptions
2025-05-12 22:16:30,891:INFO:Importing libraries
2025-05-12 22:16:30,892:INFO:Copying training dataset
2025-05-12 22:16:30,914:INFO:Defining folds
2025-05-12 22:16:30,915:INFO:Declaring metric variables
2025-05-12 22:16:30,933:INFO:Importing untrained model
2025-05-12 22:16:30,995:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:16:31,015:INFO:Starting cross validation
2025-05-12 22:16:31,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:31,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:31,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:31,618:INFO:Calculating mean and std
2025-05-12 22:16:31,620:INFO:Creating metrics dataframe
2025-05-12 22:16:31,624:INFO:Uploading results into container
2025-05-12 22:16:31,625:INFO:Uploading model into container now
2025-05-12 22:16:31,626:INFO:_master_model_container: 12
2025-05-12 22:16:31,627:INFO:_display_container: 2
2025-05-12 22:16:31,628:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:16:31,628:INFO:create_model() successfully completed......................................
2025-05-12 22:16:31,747:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:31,748:INFO:Creating metrics dataframe
2025-05-12 22:16:31,782:INFO:Initializing Random Forest Regressor
2025-05-12 22:16:31,782:INFO:Total runtime is 0.3557050744692485 minutes
2025-05-12 22:16:31,798:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:31,799:INFO:Initializing create_model()
2025-05-12 22:16:31,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:31,799:INFO:Checking exceptions
2025-05-12 22:16:31,800:INFO:Importing libraries
2025-05-12 22:16:31,800:INFO:Copying training dataset
2025-05-12 22:16:31,822:INFO:Defining folds
2025-05-12 22:16:31,822:INFO:Declaring metric variables
2025-05-12 22:16:31,833:INFO:Importing untrained model
2025-05-12 22:16:31,853:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:16:31,876:INFO:Starting cross validation
2025-05-12 22:16:31,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:33,241:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:33,242:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:33,251:INFO:Calculating mean and std
2025-05-12 22:16:33,254:INFO:Creating metrics dataframe
2025-05-12 22:16:33,260:INFO:Uploading results into container
2025-05-12 22:16:33,262:INFO:Uploading model into container now
2025-05-12 22:16:33,263:INFO:_master_model_container: 13
2025-05-12 22:16:33,263:INFO:_display_container: 2
2025-05-12 22:16:33,264:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:33,264:INFO:create_model() successfully completed......................................
2025-05-12 22:16:33,371:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:33,372:INFO:Creating metrics dataframe
2025-05-12 22:16:33,392:INFO:Initializing Extra Trees Regressor
2025-05-12 22:16:33,392:INFO:Total runtime is 0.3825367649396261 minutes
2025-05-12 22:16:33,398:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:33,398:INFO:Initializing create_model()
2025-05-12 22:16:33,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:33,398:INFO:Checking exceptions
2025-05-12 22:16:33,399:INFO:Importing libraries
2025-05-12 22:16:33,399:INFO:Copying training dataset
2025-05-12 22:16:33,407:INFO:Defining folds
2025-05-12 22:16:33,407:INFO:Declaring metric variables
2025-05-12 22:16:33,414:INFO:Importing untrained model
2025-05-12 22:16:33,422:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:16:33,436:INFO:Starting cross validation
2025-05-12 22:16:33,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:34,465:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:34,466:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:34,468:INFO:Calculating mean and std
2025-05-12 22:16:34,470:INFO:Creating metrics dataframe
2025-05-12 22:16:34,474:INFO:Uploading results into container
2025-05-12 22:16:34,475:INFO:Uploading model into container now
2025-05-12 22:16:34,476:INFO:_master_model_container: 14
2025-05-12 22:16:34,476:INFO:_display_container: 2
2025-05-12 22:16:34,477:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:34,477:INFO:create_model() successfully completed......................................
2025-05-12 22:16:34,571:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:34,571:INFO:Creating metrics dataframe
2025-05-12 22:16:34,586:INFO:Initializing AdaBoost Regressor
2025-05-12 22:16:34,586:INFO:Total runtime is 0.4024460752805074 minutes
2025-05-12 22:16:34,592:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:34,592:INFO:Initializing create_model()
2025-05-12 22:16:34,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:34,592:INFO:Checking exceptions
2025-05-12 22:16:34,593:INFO:Importing libraries
2025-05-12 22:16:34,593:INFO:Copying training dataset
2025-05-12 22:16:34,599:INFO:Defining folds
2025-05-12 22:16:34,599:INFO:Declaring metric variables
2025-05-12 22:16:34,606:INFO:Importing untrained model
2025-05-12 22:16:34,613:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:16:34,629:INFO:Starting cross validation
2025-05-12 22:16:34,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:35,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:35,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:35,338:INFO:Calculating mean and std
2025-05-12 22:16:35,340:INFO:Creating metrics dataframe
2025-05-12 22:16:35,344:INFO:Uploading results into container
2025-05-12 22:16:35,345:INFO:Uploading model into container now
2025-05-12 22:16:35,346:INFO:_master_model_container: 15
2025-05-12 22:16:35,346:INFO:_display_container: 2
2025-05-12 22:16:35,347:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:16:35,347:INFO:create_model() successfully completed......................................
2025-05-12 22:16:35,455:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:35,455:INFO:Creating metrics dataframe
2025-05-12 22:16:35,476:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:16:35,476:INFO:Total runtime is 0.4172772765159607 minutes
2025-05-12 22:16:35,484:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:35,485:INFO:Initializing create_model()
2025-05-12 22:16:35,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:35,486:INFO:Checking exceptions
2025-05-12 22:16:35,486:INFO:Importing libraries
2025-05-12 22:16:35,486:INFO:Copying training dataset
2025-05-12 22:16:35,550:INFO:Defining folds
2025-05-12 22:16:35,550:INFO:Declaring metric variables
2025-05-12 22:16:35,560:INFO:Importing untrained model
2025-05-12 22:16:35,608:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:16:35,641:INFO:Starting cross validation
2025-05-12 22:16:35,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:36,344:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:36,344:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:36,346:INFO:Calculating mean and std
2025-05-12 22:16:36,351:INFO:Creating metrics dataframe
2025-05-12 22:16:36,360:INFO:Uploading results into container
2025-05-12 22:16:36,361:INFO:Uploading model into container now
2025-05-12 22:16:36,362:INFO:_master_model_container: 16
2025-05-12 22:16:36,362:INFO:_display_container: 2
2025-05-12 22:16:36,363:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:16:36,363:INFO:create_model() successfully completed......................................
2025-05-12 22:16:36,469:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:36,470:INFO:Creating metrics dataframe
2025-05-12 22:16:36,495:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:16:36,495:INFO:Total runtime is 0.4342536012331645 minutes
2025-05-12 22:16:36,504:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:36,504:INFO:Initializing create_model()
2025-05-12 22:16:36,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:36,505:INFO:Checking exceptions
2025-05-12 22:16:36,505:INFO:Importing libraries
2025-05-12 22:16:36,505:INFO:Copying training dataset
2025-05-12 22:16:36,514:INFO:Defining folds
2025-05-12 22:16:36,515:INFO:Declaring metric variables
2025-05-12 22:16:36,526:INFO:Importing untrained model
2025-05-12 22:16:36,545:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:16:36,610:INFO:Starting cross validation
2025-05-12 22:16:36,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:37,926:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:37,926:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:37,950:INFO:Calculating mean and std
2025-05-12 22:16:37,953:INFO:Creating metrics dataframe
2025-05-12 22:16:37,958:INFO:Uploading results into container
2025-05-12 22:16:37,962:INFO:Uploading model into container now
2025-05-12 22:16:37,963:INFO:_master_model_container: 17
2025-05-12 22:16:37,963:INFO:_display_container: 2
2025-05-12 22:16:37,965:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:37,965:INFO:create_model() successfully completed......................................
2025-05-12 22:16:38,092:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:38,093:INFO:Creating metrics dataframe
2025-05-12 22:16:38,112:INFO:Initializing Dummy Regressor
2025-05-12 22:16:38,113:INFO:Total runtime is 0.4612179676691691 minutes
2025-05-12 22:16:38,120:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:38,121:INFO:Initializing create_model()
2025-05-12 22:16:38,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:38,121:INFO:Checking exceptions
2025-05-12 22:16:38,122:INFO:Importing libraries
2025-05-12 22:16:38,122:INFO:Copying training dataset
2025-05-12 22:16:38,137:INFO:Defining folds
2025-05-12 22:16:38,138:INFO:Declaring metric variables
2025-05-12 22:16:38,147:INFO:Importing untrained model
2025-05-12 22:16:38,163:INFO:Dummy Regressor Imported successfully
2025-05-12 22:16:38,194:INFO:Starting cross validation
2025-05-12 22:16:38,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:38,736:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:38,737:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:38,992:INFO:Calculating mean and std
2025-05-12 22:16:38,995:INFO:Creating metrics dataframe
2025-05-12 22:16:39,002:INFO:Uploading results into container
2025-05-12 22:16:39,003:INFO:Uploading model into container now
2025-05-12 22:16:39,004:INFO:_master_model_container: 18
2025-05-12 22:16:39,004:INFO:_display_container: 2
2025-05-12 22:16:39,004:INFO:DummyRegressor()
2025-05-12 22:16:39,005:INFO:create_model() successfully completed......................................
2025-05-12 22:16:39,315:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:39,315:INFO:Creating metrics dataframe
2025-05-12 22:16:39,345:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:16:39,370:INFO:Initializing create_model()
2025-05-12 22:16:39,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:39,371:INFO:Checking exceptions
2025-05-12 22:16:39,374:INFO:Importing libraries
2025-05-12 22:16:39,374:INFO:Copying training dataset
2025-05-12 22:16:39,386:INFO:Defining folds
2025-05-12 22:16:39,386:INFO:Declaring metric variables
2025-05-12 22:16:39,386:INFO:Importing untrained model
2025-05-12 22:16:39,386:INFO:Declaring custom model
2025-05-12 22:16:39,387:INFO:Lasso Regression Imported successfully
2025-05-12 22:16:39,392:INFO:Cross validation set to False
2025-05-12 22:16:39,392:INFO:Fitting Model
2025-05-12 22:16:39,503:INFO:Lasso(random_state=123)
2025-05-12 22:16:39,503:INFO:create_model() successfully completed......................................
2025-05-12 22:16:39,663:INFO:_master_model_container: 18
2025-05-12 22:16:39,663:INFO:_display_container: 2
2025-05-12 22:16:39,664:INFO:Lasso(random_state=123)
2025-05-12 22:16:39,664:INFO:compare_models() successfully completed......................................
2025-05-12 22:18:08,758:INFO:Initializing create_model()
2025-05-12 22:18:08,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:08,758:INFO:Checking exceptions
2025-05-12 22:18:08,780:INFO:Importing libraries
2025-05-12 22:18:08,780:INFO:Copying training dataset
2025-05-12 22:18:08,788:INFO:Defining folds
2025-05-12 22:18:08,788:INFO:Declaring metric variables
2025-05-12 22:18:08,795:INFO:Importing untrained model
2025-05-12 22:18:08,800:INFO:Linear Regression Imported successfully
2025-05-12 22:18:08,812:INFO:Starting cross validation
2025-05-12 22:18:08,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:09,115:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:09,116:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:09,125:INFO:Calculating mean and std
2025-05-12 22:18:09,125:INFO:Creating metrics dataframe
2025-05-12 22:18:09,130:INFO:Finalizing model
2025-05-12 22:18:09,192:INFO:Uploading results into container
2025-05-12 22:18:09,193:INFO:Uploading model into container now
2025-05-12 22:18:09,204:INFO:_master_model_container: 19
2025-05-12 22:18:09,204:INFO:_display_container: 3
2025-05-12 22:18:09,204:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:09,204:INFO:create_model() successfully completed......................................
2025-05-12 22:18:13,220:INFO:Initializing tune_model()
2025-05-12 22:18:13,220:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:18:13,220:INFO:Checking exceptions
2025-05-12 22:18:13,240:INFO:Copying training dataset
2025-05-12 22:18:13,244:INFO:Checking base model
2025-05-12 22:18:13,245:INFO:Base model : Linear Regression
2025-05-12 22:18:13,250:INFO:Declaring metric variables
2025-05-12 22:18:13,255:INFO:Defining Hyperparameters
2025-05-12 22:18:13,255:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 22:18:13,351:INFO:Tuning with n_jobs=-1
2025-05-12 22:18:13,351:INFO:Initializing GridSearchCV
2025-05-12 22:18:13,923:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 22:18:13,923:INFO:Hyperparameter search completed
2025-05-12 22:18:13,924:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:13,924:INFO:Initializing create_model()
2025-05-12 22:18:13,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC04A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 22:18:13,924:INFO:Checking exceptions
2025-05-12 22:18:13,924:INFO:Importing libraries
2025-05-12 22:18:13,924:INFO:Copying training dataset
2025-05-12 22:18:13,931:INFO:Defining folds
2025-05-12 22:18:13,932:INFO:Declaring metric variables
2025-05-12 22:18:13,936:INFO:Importing untrained model
2025-05-12 22:18:13,936:INFO:Declaring custom model
2025-05-12 22:18:13,943:INFO:Linear Regression Imported successfully
2025-05-12 22:18:13,955:INFO:Starting cross validation
2025-05-12 22:18:13,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:14,421:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:14,421:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:14,433:INFO:Calculating mean and std
2025-05-12 22:18:14,437:INFO:Creating metrics dataframe
2025-05-12 22:18:14,453:INFO:Finalizing model
2025-05-12 22:18:14,588:INFO:Uploading results into container
2025-05-12 22:18:14,590:INFO:Uploading model into container now
2025-05-12 22:18:14,591:INFO:_master_model_container: 20
2025-05-12 22:18:14,592:INFO:_display_container: 4
2025-05-12 22:18:14,592:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:14,592:INFO:create_model() successfully completed......................................
2025-05-12 22:18:14,746:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:14,746:INFO:choose_better activated
2025-05-12 22:18:14,755:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:14,756:INFO:Initializing create_model()
2025-05-12 22:18:14,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:14,757:INFO:Checking exceptions
2025-05-12 22:18:14,761:INFO:Importing libraries
2025-05-12 22:18:14,761:INFO:Copying training dataset
2025-05-12 22:18:14,771:INFO:Defining folds
2025-05-12 22:18:14,771:INFO:Declaring metric variables
2025-05-12 22:18:14,772:INFO:Importing untrained model
2025-05-12 22:18:14,772:INFO:Declaring custom model
2025-05-12 22:18:14,773:INFO:Linear Regression Imported successfully
2025-05-12 22:18:14,773:INFO:Starting cross validation
2025-05-12 22:18:14,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:15,214:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:15,215:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:15,219:INFO:Calculating mean and std
2025-05-12 22:18:15,220:INFO:Creating metrics dataframe
2025-05-12 22:18:15,223:INFO:Finalizing model
2025-05-12 22:18:15,313:INFO:Uploading results into container
2025-05-12 22:18:15,313:INFO:Uploading model into container now
2025-05-12 22:18:15,314:INFO:_master_model_container: 21
2025-05-12 22:18:15,314:INFO:_display_container: 5
2025-05-12 22:18:15,314:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:15,314:INFO:create_model() successfully completed......................................
2025-05-12 22:18:15,420:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:15,420:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.1485
2025-05-12 22:18:15,421:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.1485
2025-05-12 22:18:15,422:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 22:18:15,422:INFO:choose_better completed
2025-05-12 22:18:15,422:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:18:15,443:INFO:_master_model_container: 21
2025-05-12 22:18:15,443:INFO:_display_container: 4
2025-05-12 22:18:15,444:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:15,444:INFO:tune_model() successfully completed......................................
2025-05-12 22:18:20,758:INFO:Initializing evaluate_model()
2025-05-12 22:18:20,758:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:18:20,777:INFO:Initializing plot_model()
2025-05-12 22:18:20,777:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:18:20,778:INFO:Checking exceptions
2025-05-12 22:18:20,781:INFO:Preloading libraries
2025-05-12 22:18:20,782:INFO:Copying training dataset
2025-05-12 22:18:20,782:INFO:Plot type: pipeline
2025-05-12 22:18:21,145:INFO:Visual Rendered Successfully
2025-05-12 22:18:21,251:INFO:plot_model() successfully completed......................................
2025-05-12 22:18:25,687:INFO:Initializing predict_model()
2025-05-12 22:18:25,688:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3C80D8720>)
2025-05-12 22:18:25,688:INFO:Checking exceptions
2025-05-12 22:18:25,688:INFO:Preloading libraries
2025-05-12 22:18:25,802:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:20:05,343:INFO:Initializing create_model()
2025-05-12 22:20:05,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:20:05,343:INFO:Checking exceptions
2025-05-12 22:20:05,363:INFO:Importing libraries
2025-05-12 22:20:05,363:INFO:Copying training dataset
2025-05-12 22:20:05,371:INFO:Defining folds
2025-05-12 22:20:05,371:INFO:Declaring metric variables
2025-05-12 22:20:05,397:INFO:Importing untrained model
2025-05-12 22:20:05,406:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:05,434:INFO:Starting cross validation
2025-05-12 22:20:05,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:05,769:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:05,770:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:05,780:INFO:Calculating mean and std
2025-05-12 22:20:05,781:INFO:Creating metrics dataframe
2025-05-12 22:20:05,784:INFO:Finalizing model
2025-05-12 22:20:05,833:INFO:Uploading results into container
2025-05-12 22:20:05,834:INFO:Uploading model into container now
2025-05-12 22:20:05,847:INFO:_master_model_container: 22
2025-05-12 22:20:05,847:INFO:_display_container: 6
2025-05-12 22:20:05,848:INFO:Lasso(random_state=123)
2025-05-12 22:20:05,848:INFO:create_model() successfully completed......................................
2025-05-12 22:20:08,411:INFO:Initializing tune_model()
2025-05-12 22:20:08,411:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:20:08,411:INFO:Checking exceptions
2025-05-12 22:20:08,434:INFO:Copying training dataset
2025-05-12 22:20:08,439:INFO:Checking base model
2025-05-12 22:20:08,439:INFO:Base model : Lasso Regression
2025-05-12 22:20:08,445:INFO:Declaring metric variables
2025-05-12 22:20:08,452:INFO:Defining Hyperparameters
2025-05-12 22:20:08,540:INFO:Tuning with n_jobs=-1
2025-05-12 22:20:08,541:INFO:Initializing RandomizedSearchCV
2025-05-12 22:20:10,238:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:20:10,239:INFO:Hyperparameter search completed
2025-05-12 22:20:10,239:INFO:SubProcess create_model() called ==================================
2025-05-12 22:20:10,239:INFO:Initializing create_model()
2025-05-12 22:20:10,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2A0210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:20:10,239:INFO:Checking exceptions
2025-05-12 22:20:10,239:INFO:Importing libraries
2025-05-12 22:20:10,240:INFO:Copying training dataset
2025-05-12 22:20:10,245:INFO:Defining folds
2025-05-12 22:20:10,245:INFO:Declaring metric variables
2025-05-12 22:20:10,248:INFO:Importing untrained model
2025-05-12 22:20:10,248:INFO:Declaring custom model
2025-05-12 22:20:10,251:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:10,258:INFO:Starting cross validation
2025-05-12 22:20:10,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:10,475:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:10,475:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:10,480:INFO:Calculating mean and std
2025-05-12 22:20:10,481:INFO:Creating metrics dataframe
2025-05-12 22:20:10,485:INFO:Finalizing model
2025-05-12 22:20:10,532:INFO:Uploading results into container
2025-05-12 22:20:10,533:INFO:Uploading model into container now
2025-05-12 22:20:10,533:INFO:_master_model_container: 23
2025-05-12 22:20:10,533:INFO:_display_container: 7
2025-05-12 22:20:10,534:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:20:10,534:INFO:create_model() successfully completed......................................
2025-05-12 22:20:10,606:INFO:SubProcess create_model() end ==================================
2025-05-12 22:20:10,607:INFO:choose_better activated
2025-05-12 22:20:10,611:INFO:SubProcess create_model() called ==================================
2025-05-12 22:20:10,612:INFO:Initializing create_model()
2025-05-12 22:20:10,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:20:10,612:INFO:Checking exceptions
2025-05-12 22:20:10,615:INFO:Importing libraries
2025-05-12 22:20:10,615:INFO:Copying training dataset
2025-05-12 22:20:10,620:INFO:Defining folds
2025-05-12 22:20:10,620:INFO:Declaring metric variables
2025-05-12 22:20:10,621:INFO:Importing untrained model
2025-05-12 22:20:10,621:INFO:Declaring custom model
2025-05-12 22:20:10,622:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:10,622:INFO:Starting cross validation
2025-05-12 22:20:10,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:10,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:10,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:10,924:INFO:Calculating mean and std
2025-05-12 22:20:10,925:INFO:Creating metrics dataframe
2025-05-12 22:20:10,927:INFO:Finalizing model
2025-05-12 22:20:10,985:INFO:Uploading results into container
2025-05-12 22:20:10,986:INFO:Uploading model into container now
2025-05-12 22:20:10,986:INFO:_master_model_container: 24
2025-05-12 22:20:10,986:INFO:_display_container: 8
2025-05-12 22:20:10,987:INFO:Lasso(random_state=123)
2025-05-12 22:20:10,987:INFO:create_model() successfully completed......................................
2025-05-12 22:20:11,055:INFO:SubProcess create_model() end ==================================
2025-05-12 22:20:11,056:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:20:11,056:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:20:11,057:INFO:Lasso(random_state=123) is best model
2025-05-12 22:20:11,057:INFO:choose_better completed
2025-05-12 22:20:11,057:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:20:11,069:INFO:_master_model_container: 24
2025-05-12 22:20:11,069:INFO:_display_container: 7
2025-05-12 22:20:11,069:INFO:Lasso(random_state=123)
2025-05-12 22:20:11,069:INFO:tune_model() successfully completed......................................
2025-05-12 22:20:14,086:INFO:Initializing evaluate_model()
2025-05-12 22:20:14,087:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:20:14,096:INFO:Initializing plot_model()
2025-05-12 22:20:14,096:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:20:14,097:INFO:Checking exceptions
2025-05-12 22:20:14,099:INFO:Preloading libraries
2025-05-12 22:20:14,099:INFO:Copying training dataset
2025-05-12 22:20:14,099:INFO:Plot type: pipeline
2025-05-12 22:20:14,236:INFO:Visual Rendered Successfully
2025-05-12 22:20:14,323:INFO:plot_model() successfully completed......................................
2025-05-12 22:20:17,035:INFO:Initializing predict_model()
2025-05-12 22:20:17,035:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECB03420>)
2025-05-12 22:20:17,035:INFO:Checking exceptions
2025-05-12 22:20:17,035:INFO:Preloading libraries
2025-05-12 22:20:17,167:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:37,186:INFO:Initializing create_model()
2025-05-12 22:25:37,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=en, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:37,188:INFO:Checking exceptions
2025-05-12 22:25:37,205:INFO:Importing libraries
2025-05-12 22:25:37,206:INFO:Copying training dataset
2025-05-12 22:25:37,212:INFO:Defining folds
2025-05-12 22:25:37,212:INFO:Declaring metric variables
2025-05-12 22:25:37,218:INFO:Importing untrained model
2025-05-12 22:25:37,222:INFO:Elastic Net Imported successfully
2025-05-12 22:25:37,232:INFO:Starting cross validation
2025-05-12 22:25:37,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:47,008:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:47,009:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:47,370:INFO:Calculating mean and std
2025-05-12 22:25:47,371:INFO:Creating metrics dataframe
2025-05-12 22:25:47,379:INFO:Finalizing model
2025-05-12 22:25:47,449:INFO:Uploading results into container
2025-05-12 22:25:47,450:INFO:Uploading model into container now
2025-05-12 22:25:47,472:INFO:_master_model_container: 25
2025-05-12 22:25:47,472:INFO:_display_container: 9
2025-05-12 22:25:47,473:INFO:ElasticNet(random_state=123)
2025-05-12 22:25:47,473:INFO:create_model() successfully completed......................................
2025-05-12 22:25:58,332:INFO:Initializing tune_model()
2025-05-12 22:25:58,332:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:58,332:INFO:Checking exceptions
2025-05-12 22:25:58,354:INFO:Copying training dataset
2025-05-12 22:25:58,358:INFO:Checking base model
2025-05-12 22:25:58,359:INFO:Base model : Elastic Net
2025-05-12 22:25:58,364:INFO:Declaring metric variables
2025-05-12 22:25:58,370:INFO:Defining Hyperparameters
2025-05-12 22:25:58,453:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:58,453:INFO:Initializing RandomizedSearchCV
2025-05-12 22:26:00,250:INFO:best_params: {'actual_estimator__l1_ratio': 0.664, 'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 9.88}
2025-05-12 22:26:00,251:INFO:Hyperparameter search completed
2025-05-12 22:26:00,251:INFO:SubProcess create_model() called ==================================
2025-05-12 22:26:00,252:INFO:Initializing create_model()
2025-05-12 22:26:00,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC1073D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'l1_ratio': 0.664, 'fit_intercept': True, 'alpha': 9.88})
2025-05-12 22:26:00,252:INFO:Checking exceptions
2025-05-12 22:26:00,252:INFO:Importing libraries
2025-05-12 22:26:00,252:INFO:Copying training dataset
2025-05-12 22:26:00,258:INFO:Defining folds
2025-05-12 22:26:00,259:INFO:Declaring metric variables
2025-05-12 22:26:00,263:INFO:Importing untrained model
2025-05-12 22:26:00,263:INFO:Declaring custom model
2025-05-12 22:26:00,268:INFO:Elastic Net Imported successfully
2025-05-12 22:26:00,279:INFO:Starting cross validation
2025-05-12 22:26:00,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:26:00,556:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:26:00,556:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:26:00,561:INFO:Calculating mean and std
2025-05-12 22:26:00,562:INFO:Creating metrics dataframe
2025-05-12 22:26:00,568:INFO:Finalizing model
2025-05-12 22:26:00,619:INFO:Uploading results into container
2025-05-12 22:26:00,620:INFO:Uploading model into container now
2025-05-12 22:26:00,620:INFO:_master_model_container: 26
2025-05-12 22:26:00,621:INFO:_display_container: 10
2025-05-12 22:26:00,621:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123)
2025-05-12 22:26:00,621:INFO:create_model() successfully completed......................................
2025-05-12 22:26:00,705:INFO:SubProcess create_model() end ==================================
2025-05-12 22:26:00,705:INFO:choose_better activated
2025-05-12 22:26:00,708:INFO:SubProcess create_model() called ==================================
2025-05-12 22:26:00,709:INFO:Initializing create_model()
2025-05-12 22:26:00,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:26:00,709:INFO:Checking exceptions
2025-05-12 22:26:00,710:INFO:Importing libraries
2025-05-12 22:26:00,710:INFO:Copying training dataset
2025-05-12 22:26:00,715:INFO:Defining folds
2025-05-12 22:26:00,715:INFO:Declaring metric variables
2025-05-12 22:26:00,715:INFO:Importing untrained model
2025-05-12 22:26:00,715:INFO:Declaring custom model
2025-05-12 22:26:00,716:INFO:Elastic Net Imported successfully
2025-05-12 22:26:00,716:INFO:Starting cross validation
2025-05-12 22:26:00,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:26:00,977:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:26:00,978:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:26:00,981:INFO:Calculating mean and std
2025-05-12 22:26:00,981:INFO:Creating metrics dataframe
2025-05-12 22:26:00,983:INFO:Finalizing model
2025-05-12 22:26:01,024:INFO:Uploading results into container
2025-05-12 22:26:01,024:INFO:Uploading model into container now
2025-05-12 22:26:01,025:INFO:_master_model_container: 27
2025-05-12 22:26:01,025:INFO:_display_container: 11
2025-05-12 22:26:01,025:INFO:ElasticNet(random_state=123)
2025-05-12 22:26:01,025:INFO:create_model() successfully completed......................................
2025-05-12 22:26:01,098:INFO:SubProcess create_model() end ==================================
2025-05-12 22:26:01,098:INFO:ElasticNet(random_state=123) result for R2 is -0.0421
2025-05-12 22:26:01,099:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123) result for R2 is -0.0421
2025-05-12 22:26:01,099:INFO:ElasticNet(random_state=123) is best model
2025-05-12 22:26:01,099:INFO:choose_better completed
2025-05-12 22:26:01,100:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:26:01,110:INFO:_master_model_container: 27
2025-05-12 22:26:01,110:INFO:_display_container: 10
2025-05-12 22:26:01,110:INFO:ElasticNet(random_state=123)
2025-05-12 22:26:01,110:INFO:tune_model() successfully completed......................................
2025-05-12 22:26:03,825:INFO:Initializing evaluate_model()
2025-05-12 22:26:03,825:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:26:03,837:INFO:Initializing plot_model()
2025-05-12 22:26:03,837:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:03,837:INFO:Checking exceptions
2025-05-12 22:26:03,839:INFO:Preloading libraries
2025-05-12 22:26:03,839:INFO:Copying training dataset
2025-05-12 22:26:03,839:INFO:Plot type: pipeline
2025-05-12 22:26:04,029:INFO:Visual Rendered Successfully
2025-05-12 22:26:04,103:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:06,114:INFO:Initializing plot_model()
2025-05-12 22:26:06,114:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:06,114:INFO:Checking exceptions
2025-05-12 22:26:06,116:INFO:Preloading libraries
2025-05-12 22:26:06,117:INFO:Copying training dataset
2025-05-12 22:26:06,117:INFO:Plot type: parameter
2025-05-12 22:26:06,122:INFO:Visual Rendered Successfully
2025-05-12 22:26:06,215:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:07,450:INFO:Initializing plot_model()
2025-05-12 22:26:07,450:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:07,450:INFO:Checking exceptions
2025-05-12 22:26:07,454:INFO:Preloading libraries
2025-05-12 22:26:07,454:INFO:Copying training dataset
2025-05-12 22:26:07,454:INFO:Plot type: residuals
2025-05-12 22:26:07,683:INFO:Fitting Model
2025-05-12 22:26:07,683:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names
  warnings.warn(

2025-05-12 22:26:07,726:INFO:Scoring test/hold-out set
2025-05-12 22:26:08,673:INFO:Visual Rendered Successfully
2025-05-12 22:26:08,746:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:08,846:INFO:Initializing plot_model()
2025-05-12 22:26:08,847:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:08,847:INFO:Checking exceptions
2025-05-12 22:26:08,850:INFO:Preloading libraries
2025-05-12 22:26:08,850:INFO:Copying training dataset
2025-05-12 22:26:08,850:INFO:Plot type: error
2025-05-12 22:26:09,124:INFO:Fitting Model
2025-05-12 22:26:09,124:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names
  warnings.warn(

2025-05-12 22:26:09,124:INFO:Scoring test/hold-out set
2025-05-12 22:26:09,386:INFO:Visual Rendered Successfully
2025-05-12 22:26:09,498:INFO:plot_model() successfully completed......................................
2025-05-12 22:27:59,133:INFO:Initializing predict_model()
2025-05-12 22:27:59,133:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECD14AE0>)
2025-05-12 22:27:59,133:INFO:Checking exceptions
2025-05-12 22:27:59,133:INFO:Preloading libraries
2025-05-12 22:27:59,373:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:36:22,188:INFO:Initializing create_model()
2025-05-12 22:36:22,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:36:22,189:INFO:Checking exceptions
2025-05-12 22:36:22,216:INFO:Importing libraries
2025-05-12 22:36:22,216:INFO:Copying training dataset
2025-05-12 22:36:22,224:INFO:Defining folds
2025-05-12 22:36:22,224:INFO:Declaring metric variables
2025-05-12 22:36:22,233:INFO:Importing untrained model
2025-05-12 22:36:22,241:INFO:Lasso Regression Imported successfully
2025-05-12 22:36:22,255:INFO:Starting cross validation
2025-05-12 22:36:22,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:36:30,540:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:36:30,541:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:36:31,158:INFO:Calculating mean and std
2025-05-12 22:36:31,160:INFO:Creating metrics dataframe
2025-05-12 22:36:31,170:INFO:Finalizing model
2025-05-12 22:36:31,225:INFO:Uploading results into container
2025-05-12 22:36:31,226:INFO:Uploading model into container now
2025-05-12 22:36:31,235:INFO:_master_model_container: 28
2025-05-12 22:36:31,236:INFO:_display_container: 12
2025-05-12 22:36:31,236:INFO:Lasso(random_state=123)
2025-05-12 22:36:31,236:INFO:create_model() successfully completed......................................
2025-05-12 22:46:40,121:INFO:Initializing tune_model()
2025-05-12 22:46:40,121:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:46:40,121:INFO:Checking exceptions
2025-05-12 22:46:40,140:INFO:Copying training dataset
2025-05-12 22:46:40,144:INFO:Checking base model
2025-05-12 22:46:40,144:INFO:Base model : Lasso Regression
2025-05-12 22:46:40,149:INFO:Declaring metric variables
2025-05-12 22:46:40,155:INFO:Defining Hyperparameters
2025-05-12 22:46:40,245:INFO:Tuning with n_jobs=-1
2025-05-12 22:46:40,246:INFO:Initializing RandomizedSearchCV
2025-05-12 22:46:50,358:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:46:50,360:INFO:Hyperparameter search completed
2025-05-12 22:46:50,361:INFO:SubProcess create_model() called ==================================
2025-05-12 22:46:50,362:INFO:Initializing create_model()
2025-05-12 22:46:50,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3ECF40090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:46:50,363:INFO:Checking exceptions
2025-05-12 22:46:50,364:INFO:Importing libraries
2025-05-12 22:46:50,364:INFO:Copying training dataset
2025-05-12 22:46:50,378:INFO:Defining folds
2025-05-12 22:46:50,378:INFO:Declaring metric variables
2025-05-12 22:46:50,386:INFO:Importing untrained model
2025-05-12 22:46:50,386:INFO:Declaring custom model
2025-05-12 22:46:50,395:INFO:Lasso Regression Imported successfully
2025-05-12 22:46:50,413:INFO:Starting cross validation
2025-05-12 22:46:50,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:46:50,780:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:46:50,780:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:46:50,789:INFO:Calculating mean and std
2025-05-12 22:46:50,791:INFO:Creating metrics dataframe
2025-05-12 22:46:50,798:INFO:Finalizing model
2025-05-12 22:46:50,871:INFO:Uploading results into container
2025-05-12 22:46:50,872:INFO:Uploading model into container now
2025-05-12 22:46:50,873:INFO:_master_model_container: 29
2025-05-12 22:46:50,873:INFO:_display_container: 13
2025-05-12 22:46:50,874:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:46:50,874:INFO:create_model() successfully completed......................................
2025-05-12 22:46:50,966:INFO:SubProcess create_model() end ==================================
2025-05-12 22:46:50,966:INFO:choose_better activated
2025-05-12 22:46:50,972:INFO:SubProcess create_model() called ==================================
2025-05-12 22:46:50,973:INFO:Initializing create_model()
2025-05-12 22:46:50,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:46:50,973:INFO:Checking exceptions
2025-05-12 22:46:50,975:INFO:Importing libraries
2025-05-12 22:46:50,975:INFO:Copying training dataset
2025-05-12 22:46:50,980:INFO:Defining folds
2025-05-12 22:46:50,980:INFO:Declaring metric variables
2025-05-12 22:46:50,980:INFO:Importing untrained model
2025-05-12 22:46:50,980:INFO:Declaring custom model
2025-05-12 22:46:50,981:INFO:Lasso Regression Imported successfully
2025-05-12 22:46:50,981:INFO:Starting cross validation
2025-05-12 22:46:50,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:46:51,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:46:51,266:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:46:51,277:INFO:Calculating mean and std
2025-05-12 22:46:51,278:INFO:Creating metrics dataframe
2025-05-12 22:46:51,281:INFO:Finalizing model
2025-05-12 22:46:51,371:INFO:Uploading results into container
2025-05-12 22:46:51,372:INFO:Uploading model into container now
2025-05-12 22:46:51,372:INFO:_master_model_container: 30
2025-05-12 22:46:51,373:INFO:_display_container: 14
2025-05-12 22:46:51,373:INFO:Lasso(random_state=123)
2025-05-12 22:46:51,373:INFO:create_model() successfully completed......................................
2025-05-12 22:46:51,477:INFO:SubProcess create_model() end ==================================
2025-05-12 22:46:51,477:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:46:51,478:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:46:51,478:INFO:Lasso(random_state=123) is best model
2025-05-12 22:46:51,478:INFO:choose_better completed
2025-05-12 22:46:51,478:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:46:51,495:INFO:_master_model_container: 30
2025-05-12 22:46:51,495:INFO:_display_container: 13
2025-05-12 22:46:51,495:INFO:Lasso(random_state=123)
2025-05-12 22:46:51,496:INFO:tune_model() successfully completed......................................
2025-05-12 22:46:54,225:INFO:Initializing evaluate_model()
2025-05-12 22:46:54,225:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:46:54,234:INFO:Initializing plot_model()
2025-05-12 22:46:54,234:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:46:54,234:INFO:Checking exceptions
2025-05-12 22:46:54,237:INFO:Preloading libraries
2025-05-12 22:46:54,237:INFO:Copying training dataset
2025-05-12 22:46:54,237:INFO:Plot type: pipeline
2025-05-12 22:46:54,362:INFO:Visual Rendered Successfully
2025-05-12 22:46:54,430:INFO:plot_model() successfully completed......................................
2025-05-12 22:46:56,395:INFO:Initializing predict_model()
2025-05-12 22:46:56,395:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECD14400>)
2025-05-12 22:46:56,395:INFO:Checking exceptions
2025-05-12 22:46:56,395:INFO:Preloading libraries
2025-05-12 22:46:56,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:47:00,391:INFO:Initializing save_model()
2025-05-12 22:47:00,391:INFO:save_model(model=Lasso(random_state=123), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:47:00,392:INFO:Adding model into prep_pipe
2025-05-12 22:47:00,401:INFO:modelo_precio_final.pkl saved in current working directory
2025-05-12 22:47:00,413:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', Lasso(random_state=123))])
2025-05-12 22:47:00,413:INFO:save_model() successfully completed......................................
2025-05-19 19:54:32,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:04:22,759:INFO:PyCaret ClassificationExperiment
2025-05-19 20:04:22,759:INFO:Logging name: clf-default-name
2025-05-19 20:04:22,759:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 20:04:22,759:INFO:version 3.3.2
2025-05-19 20:04:22,759:INFO:Initializing setup()
2025-05-19 20:04:22,759:INFO:self.USI: 1301
2025-05-19 20:04:22,759:INFO:self._variable_keys: {'USI', 'logging_param', 'idx', 'fold_shuffle_param', 'data', 'pipeline', '_ml_usecase', 'exp_id', 'memory', 'y_test', 'X', 'log_plots_param', 'y_train', 'X_test', 'html_param', 'y', 'seed', 'gpu_param', 'exp_name_log', 'fold_generator', 'is_multiclass', 'n_jobs_param', 'fold_groups_param', '_available_plots', 'X_train', 'target_param', 'fix_imbalance', 'gpu_n_jobs_param'}
2025-05-19 20:04:23,075:INFO:Checking environment
2025-05-19 20:04:23,075:INFO:python_version: 3.11.0
2025-05-19 20:04:23,075:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-19 20:04:23,075:INFO:machine: AMD64
2025-05-19 20:04:23,075:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-19 20:04:23,080:INFO:Memory: svmem(total=12759322624, available=1364443136, percent=89.3, used=11394879488, free=1364443136)
2025-05-19 20:04:23,081:INFO:Physical Core: 4
2025-05-19 20:04:23,081:INFO:Logical Core: 8
2025-05-19 20:04:23,081:INFO:Checking libraries
2025-05-19 20:04:23,081:INFO:System:
2025-05-19 20:04:23,081:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-19 20:04:23,081:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-19 20:04:23,081:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-19 20:04:23,081:INFO:PyCaret required dependencies:
2025-05-19 20:04:23,282:INFO:                 pip: 22.3
2025-05-19 20:04:23,282:INFO:          setuptools: 65.5.0
2025-05-19 20:04:23,282:INFO:             pycaret: 3.3.2
2025-05-19 20:04:23,282:INFO:             IPython: 9.2.0
2025-05-19 20:04:23,282:INFO:          ipywidgets: 8.1.7
2025-05-19 20:04:23,282:INFO:                tqdm: 4.67.1
2025-05-19 20:04:23,282:INFO:               numpy: 1.26.4
2025-05-19 20:04:23,282:INFO:              pandas: 2.1.4
2025-05-19 20:04:23,282:INFO:              jinja2: 3.1.6
2025-05-19 20:04:23,282:INFO:               scipy: 1.11.4
2025-05-19 20:04:23,282:INFO:              joblib: 1.3.2
2025-05-19 20:04:23,283:INFO:             sklearn: 1.4.2
2025-05-19 20:04:23,283:INFO:                pyod: 2.0.5
2025-05-19 20:04:23,283:INFO:            imblearn: 0.13.0
2025-05-19 20:04:23,283:INFO:   category_encoders: 2.7.0
2025-05-19 20:04:23,283:INFO:            lightgbm: 4.6.0
2025-05-19 20:04:23,283:INFO:               numba: 0.61.2
2025-05-19 20:04:23,283:INFO:            requests: 2.32.3
2025-05-19 20:04:23,283:INFO:          matplotlib: 3.7.5
2025-05-19 20:04:23,283:INFO:          scikitplot: 0.3.7
2025-05-19 20:04:23,283:INFO:         yellowbrick: 1.5
2025-05-19 20:04:23,283:INFO:              plotly: 5.24.1
2025-05-19 20:04:23,283:INFO:    plotly-resampler: Not installed
2025-05-19 20:04:23,283:INFO:             kaleido: 0.2.1
2025-05-19 20:04:23,283:INFO:           schemdraw: 0.15
2025-05-19 20:04:23,283:INFO:         statsmodels: 0.14.4
2025-05-19 20:04:23,283:INFO:              sktime: 0.26.0
2025-05-19 20:04:23,283:INFO:               tbats: 1.1.3
2025-05-19 20:04:23,284:INFO:            pmdarima: 2.0.4
2025-05-19 20:04:23,284:INFO:              psutil: 7.0.0
2025-05-19 20:04:23,284:INFO:          markupsafe: 3.0.2
2025-05-19 20:04:23,284:INFO:             pickle5: Not installed
2025-05-19 20:04:23,284:INFO:         cloudpickle: 3.1.1
2025-05-19 20:04:23,284:INFO:         deprecation: 2.1.0
2025-05-19 20:04:23,284:INFO:              xxhash: 3.5.0
2025-05-19 20:04:23,284:INFO:           wurlitzer: Not installed
2025-05-19 20:04:23,284:INFO:PyCaret optional dependencies:
2025-05-19 20:04:23,307:INFO:                shap: Not installed
2025-05-19 20:04:23,308:INFO:           interpret: Not installed
2025-05-19 20:04:23,308:INFO:                umap: Not installed
2025-05-19 20:04:23,308:INFO:     ydata_profiling: Not installed
2025-05-19 20:04:23,308:INFO:  explainerdashboard: Not installed
2025-05-19 20:04:23,308:INFO:             autoviz: Not installed
2025-05-19 20:04:23,308:INFO:           fairlearn: Not installed
2025-05-19 20:04:23,308:INFO:          deepchecks: Not installed
2025-05-19 20:04:23,308:INFO:             xgboost: Not installed
2025-05-19 20:04:23,308:INFO:            catboost: Not installed
2025-05-19 20:04:23,308:INFO:              kmodes: Not installed
2025-05-19 20:04:23,308:INFO:             mlxtend: Not installed
2025-05-19 20:04:23,308:INFO:       statsforecast: Not installed
2025-05-19 20:04:23,308:INFO:        tune_sklearn: Not installed
2025-05-19 20:04:23,308:INFO:                 ray: Not installed
2025-05-19 20:04:23,309:INFO:            hyperopt: Not installed
2025-05-19 20:04:23,309:INFO:              optuna: Not installed
2025-05-19 20:04:23,309:INFO:               skopt: Not installed
2025-05-19 20:04:23,309:INFO:              mlflow: Not installed
2025-05-19 20:04:23,309:INFO:              gradio: Not installed
2025-05-19 20:04:23,309:INFO:             fastapi: Not installed
2025-05-19 20:04:23,309:INFO:             uvicorn: Not installed
2025-05-19 20:04:23,309:INFO:              m2cgen: Not installed
2025-05-19 20:04:23,309:INFO:           evidently: Not installed
2025-05-19 20:04:23,309:INFO:               fugue: Not installed
2025-05-19 20:04:23,309:INFO:           streamlit: Not installed
2025-05-19 20:04:23,309:INFO:             prophet: Not installed
2025-05-19 20:04:23,309:INFO:None
2025-05-19 20:04:23,309:INFO:Set up data.
2025-05-19 20:04:23,320:INFO:Set up folding strategy.
2025-05-19 20:04:23,320:INFO:Set up train/test split.
2025-05-19 20:04:23,390:INFO:Set up index.
2025-05-19 20:04:23,390:INFO:Assigning column types.
2025-05-19 20:04:23,396:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 20:04:23,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 20:04:23,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:24,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:24,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,279:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 20:04:24,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,662:INFO:Preparing preprocessing pipeline...
2025-05-19 20:04:24,667:INFO:Set up simple imputation.
2025-05-19 20:04:24,673:INFO:Set up encoding of categorical features.
2025-05-19 20:04:24,673:INFO:Set up removing multicollinearity.
2025-05-19 20:04:24,674:INFO:Set up column transformation.
2025-05-19 20:04:24,674:INFO:Set up feature normalization.
2025-05-19 20:04:24,674:INFO:Set up feature selection.
2025-05-19 20:04:24,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:25,588:INFO:Finished creating preprocessing pipeline.
2025-05-19 20:04:25,627:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transform...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 20:04:25,627:INFO:Creating final display dataframe.
2025-05-19 20:04:26,384:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              1301
2025-05-19 20:04:26,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,689:INFO:setup() successfully completed in 3.94s...............
2025-05-19 20:05:16,601:INFO:Initializing compare_models()
2025-05-19 20:05:16,602:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 20:05:16,602:INFO:Checking exceptions
2025-05-19 20:05:16,611:INFO:Preparing display monitor
2025-05-19 20:05:16,652:INFO:Initializing Logistic Regression
2025-05-19 20:05:16,653:INFO:Total runtime is 0.0 minutes
2025-05-19 20:05:16,659:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:16,660:INFO:Initializing create_model()
2025-05-19 20:05:16,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:16,660:INFO:Checking exceptions
2025-05-19 20:05:16,661:INFO:Importing libraries
2025-05-19 20:05:16,661:INFO:Copying training dataset
2025-05-19 20:05:16,671:INFO:Defining folds
2025-05-19 20:05:16,671:INFO:Declaring metric variables
2025-05-19 20:05:16,675:INFO:Importing untrained model
2025-05-19 20:05:16,683:INFO:Logistic Regression Imported successfully
2025-05-19 20:05:16,693:INFO:Starting cross validation
2025-05-19 20:05:16,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:28,132:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,320:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,426:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,629:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,647:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,904:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,924:INFO:Calculating mean and std
2025-05-19 20:05:28,928:INFO:Creating metrics dataframe
2025-05-19 20:05:28,931:INFO:Uploading results into container
2025-05-19 20:05:28,932:INFO:Uploading model into container now
2025-05-19 20:05:28,933:INFO:_master_model_container: 1
2025-05-19 20:05:28,933:INFO:_display_container: 2
2025-05-19 20:05:28,934:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 20:05:28,935:INFO:create_model() successfully completed......................................
2025-05-19 20:05:29,065:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:29,065:INFO:Creating metrics dataframe
2025-05-19 20:05:29,076:INFO:Initializing K Neighbors Classifier
2025-05-19 20:05:29,076:INFO:Total runtime is 0.20707589785257977 minutes
2025-05-19 20:05:29,083:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:29,083:INFO:Initializing create_model()
2025-05-19 20:05:29,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:29,083:INFO:Checking exceptions
2025-05-19 20:05:29,083:INFO:Importing libraries
2025-05-19 20:05:29,084:INFO:Copying training dataset
2025-05-19 20:05:29,091:INFO:Defining folds
2025-05-19 20:05:29,091:INFO:Declaring metric variables
2025-05-19 20:05:29,100:INFO:Importing untrained model
2025-05-19 20:05:29,107:INFO:K Neighbors Classifier Imported successfully
2025-05-19 20:05:29,131:INFO:Starting cross validation
2025-05-19 20:05:29,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:30,262:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:30,876:INFO:Calculating mean and std
2025-05-19 20:05:30,879:INFO:Creating metrics dataframe
2025-05-19 20:05:30,882:INFO:Uploading results into container
2025-05-19 20:05:30,883:INFO:Uploading model into container now
2025-05-19 20:05:30,884:INFO:_master_model_container: 2
2025-05-19 20:05:30,885:INFO:_display_container: 2
2025-05-19 20:05:30,886:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 20:05:30,886:INFO:create_model() successfully completed......................................
2025-05-19 20:05:30,988:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:30,988:INFO:Creating metrics dataframe
2025-05-19 20:05:30,998:INFO:Initializing Naive Bayes
2025-05-19 20:05:30,998:INFO:Total runtime is 0.2391100565592448 minutes
2025-05-19 20:05:31,003:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:31,003:INFO:Initializing create_model()
2025-05-19 20:05:31,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:31,004:INFO:Checking exceptions
2025-05-19 20:05:31,004:INFO:Importing libraries
2025-05-19 20:05:31,004:INFO:Copying training dataset
2025-05-19 20:05:31,011:INFO:Defining folds
2025-05-19 20:05:31,011:INFO:Declaring metric variables
2025-05-19 20:05:31,018:INFO:Importing untrained model
2025-05-19 20:05:31,025:INFO:Naive Bayes Imported successfully
2025-05-19 20:05:31,037:INFO:Starting cross validation
2025-05-19 20:05:31,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:31,722:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,724:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,754:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,765:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,876:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,981:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,010:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,111:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,168:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,207:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,224:INFO:Calculating mean and std
2025-05-19 20:05:32,227:INFO:Creating metrics dataframe
2025-05-19 20:05:32,231:INFO:Uploading results into container
2025-05-19 20:05:32,233:INFO:Uploading model into container now
2025-05-19 20:05:32,234:INFO:_master_model_container: 3
2025-05-19 20:05:32,234:INFO:_display_container: 2
2025-05-19 20:05:32,235:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 20:05:32,235:INFO:create_model() successfully completed......................................
2025-05-19 20:05:32,339:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:32,340:INFO:Creating metrics dataframe
2025-05-19 20:05:32,352:INFO:Initializing Decision Tree Classifier
2025-05-19 20:05:32,353:INFO:Total runtime is 0.2616799831390381 minutes
2025-05-19 20:05:32,358:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:32,358:INFO:Initializing create_model()
2025-05-19 20:05:32,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:32,359:INFO:Checking exceptions
2025-05-19 20:05:32,359:INFO:Importing libraries
2025-05-19 20:05:32,359:INFO:Copying training dataset
2025-05-19 20:05:32,367:INFO:Defining folds
2025-05-19 20:05:32,367:INFO:Declaring metric variables
2025-05-19 20:05:32,377:INFO:Importing untrained model
2025-05-19 20:05:32,386:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:05:32,398:INFO:Starting cross validation
2025-05-19 20:05:32,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:33,694:INFO:Calculating mean and std
2025-05-19 20:05:33,696:INFO:Creating metrics dataframe
2025-05-19 20:05:33,699:INFO:Uploading results into container
2025-05-19 20:05:33,701:INFO:Uploading model into container now
2025-05-19 20:05:33,702:INFO:_master_model_container: 4
2025-05-19 20:05:33,702:INFO:_display_container: 2
2025-05-19 20:05:33,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:33,703:INFO:create_model() successfully completed......................................
2025-05-19 20:05:33,792:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:33,792:INFO:Creating metrics dataframe
2025-05-19 20:05:33,802:INFO:Initializing SVM - Linear Kernel
2025-05-19 20:05:33,803:INFO:Total runtime is 0.28585828940073654 minutes
2025-05-19 20:05:33,807:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:33,807:INFO:Initializing create_model()
2025-05-19 20:05:33,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:33,808:INFO:Checking exceptions
2025-05-19 20:05:33,808:INFO:Importing libraries
2025-05-19 20:05:33,808:INFO:Copying training dataset
2025-05-19 20:05:33,814:INFO:Defining folds
2025-05-19 20:05:33,814:INFO:Declaring metric variables
2025-05-19 20:05:33,819:INFO:Importing untrained model
2025-05-19 20:05:33,826:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 20:05:33,838:INFO:Starting cross validation
2025-05-19 20:05:33,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:34,566:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,571:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,740:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,860:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,073:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,085:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,099:INFO:Calculating mean and std
2025-05-19 20:05:35,101:INFO:Creating metrics dataframe
2025-05-19 20:05:35,106:INFO:Uploading results into container
2025-05-19 20:05:35,107:INFO:Uploading model into container now
2025-05-19 20:05:35,109:INFO:_master_model_container: 5
2025-05-19 20:05:35,109:INFO:_display_container: 2
2025-05-19 20:05:35,111:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 20:05:35,111:INFO:create_model() successfully completed......................................
2025-05-19 20:05:35,220:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:35,220:INFO:Creating metrics dataframe
2025-05-19 20:05:35,244:INFO:Initializing Ridge Classifier
2025-05-19 20:05:35,244:INFO:Total runtime is 0.3098706444104513 minutes
2025-05-19 20:05:35,250:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:35,250:INFO:Initializing create_model()
2025-05-19 20:05:35,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:35,250:INFO:Checking exceptions
2025-05-19 20:05:35,251:INFO:Importing libraries
2025-05-19 20:05:35,251:INFO:Copying training dataset
2025-05-19 20:05:35,258:INFO:Defining folds
2025-05-19 20:05:35,258:INFO:Declaring metric variables
2025-05-19 20:05:35,263:INFO:Importing untrained model
2025-05-19 20:05:35,271:INFO:Ridge Classifier Imported successfully
2025-05-19 20:05:35,285:INFO:Starting cross validation
2025-05-19 20:05:35,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:36,039:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,047:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,057:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,059:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,223:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,226:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,372:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,378:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,546:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,560:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,576:INFO:Calculating mean and std
2025-05-19 20:05:36,579:INFO:Creating metrics dataframe
2025-05-19 20:05:36,583:INFO:Uploading results into container
2025-05-19 20:05:36,584:INFO:Uploading model into container now
2025-05-19 20:05:36,585:INFO:_master_model_container: 6
2025-05-19 20:05:36,585:INFO:_display_container: 2
2025-05-19 20:05:36,585:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 20:05:36,586:INFO:create_model() successfully completed......................................
2025-05-19 20:05:36,680:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:36,680:INFO:Creating metrics dataframe
2025-05-19 20:05:36,691:INFO:Initializing Random Forest Classifier
2025-05-19 20:05:36,691:INFO:Total runtime is 0.33399424950281786 minutes
2025-05-19 20:05:36,696:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:36,696:INFO:Initializing create_model()
2025-05-19 20:05:36,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:36,697:INFO:Checking exceptions
2025-05-19 20:05:36,697:INFO:Importing libraries
2025-05-19 20:05:36,697:INFO:Copying training dataset
2025-05-19 20:05:36,703:INFO:Defining folds
2025-05-19 20:05:36,703:INFO:Declaring metric variables
2025-05-19 20:05:36,709:INFO:Importing untrained model
2025-05-19 20:05:36,716:INFO:Random Forest Classifier Imported successfully
2025-05-19 20:05:36,726:INFO:Starting cross validation
2025-05-19 20:05:36,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:38,783:INFO:Calculating mean and std
2025-05-19 20:05:38,785:INFO:Creating metrics dataframe
2025-05-19 20:05:38,788:INFO:Uploading results into container
2025-05-19 20:05:38,789:INFO:Uploading model into container now
2025-05-19 20:05:38,791:INFO:_master_model_container: 7
2025-05-19 20:05:38,792:INFO:_display_container: 2
2025-05-19 20:05:38,793:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 20:05:38,794:INFO:create_model() successfully completed......................................
2025-05-19 20:05:38,879:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:38,880:INFO:Creating metrics dataframe
2025-05-19 20:05:38,890:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 20:05:38,890:INFO:Total runtime is 0.37062769333521534 minutes
2025-05-19 20:05:38,896:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:38,896:INFO:Initializing create_model()
2025-05-19 20:05:38,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:38,896:INFO:Checking exceptions
2025-05-19 20:05:38,896:INFO:Importing libraries
2025-05-19 20:05:38,896:INFO:Copying training dataset
2025-05-19 20:05:38,900:INFO:Defining folds
2025-05-19 20:05:38,900:INFO:Declaring metric variables
2025-05-19 20:05:38,906:INFO:Importing untrained model
2025-05-19 20:05:38,913:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 20:05:38,922:INFO:Starting cross validation
2025-05-19 20:05:38,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:39,600:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,603:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,608:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,621:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,757:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,763:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,914:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,924:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,135:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,138:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,155:INFO:Calculating mean and std
2025-05-19 20:05:40,157:INFO:Creating metrics dataframe
2025-05-19 20:05:40,162:INFO:Uploading results into container
2025-05-19 20:05:40,163:INFO:Uploading model into container now
2025-05-19 20:05:40,164:INFO:_master_model_container: 8
2025-05-19 20:05:40,164:INFO:_display_container: 2
2025-05-19 20:05:40,165:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 20:05:40,165:INFO:create_model() successfully completed......................................
2025-05-19 20:05:40,273:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:40,273:INFO:Creating metrics dataframe
2025-05-19 20:05:40,293:INFO:Initializing Ada Boost Classifier
2025-05-19 20:05:40,293:INFO:Total runtime is 0.3940156221389771 minutes
2025-05-19 20:05:40,299:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:40,299:INFO:Initializing create_model()
2025-05-19 20:05:40,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:40,299:INFO:Checking exceptions
2025-05-19 20:05:40,300:INFO:Importing libraries
2025-05-19 20:05:40,300:INFO:Copying training dataset
2025-05-19 20:05:40,308:INFO:Defining folds
2025-05-19 20:05:40,308:INFO:Declaring metric variables
2025-05-19 20:05:40,314:INFO:Importing untrained model
2025-05-19 20:05:40,322:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:05:40,348:INFO:Starting cross validation
2025-05-19 20:05:40,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:40,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,970:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,423:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,567:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,648:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,692:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,957:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,958:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:42,024:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:42,189:INFO:Calculating mean and std
2025-05-19 20:05:42,196:INFO:Creating metrics dataframe
2025-05-19 20:05:42,216:INFO:Uploading results into container
2025-05-19 20:05:42,220:INFO:Uploading model into container now
2025-05-19 20:05:42,221:INFO:_master_model_container: 9
2025-05-19 20:05:42,222:INFO:_display_container: 2
2025-05-19 20:05:42,223:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:05:42,223:INFO:create_model() successfully completed......................................
2025-05-19 20:05:42,321:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:42,321:INFO:Creating metrics dataframe
2025-05-19 20:05:42,333:INFO:Initializing Gradient Boosting Classifier
2025-05-19 20:05:42,334:INFO:Total runtime is 0.42803772687911995 minutes
2025-05-19 20:05:42,338:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:42,339:INFO:Initializing create_model()
2025-05-19 20:05:42,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:42,339:INFO:Checking exceptions
2025-05-19 20:05:42,340:INFO:Importing libraries
2025-05-19 20:05:42,340:INFO:Copying training dataset
2025-05-19 20:05:42,348:INFO:Defining folds
2025-05-19 20:05:42,348:INFO:Declaring metric variables
2025-05-19 20:05:42,355:INFO:Importing untrained model
2025-05-19 20:05:42,363:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 20:05:42,372:INFO:Starting cross validation
2025-05-19 20:05:42,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:43,944:INFO:Calculating mean and std
2025-05-19 20:05:43,946:INFO:Creating metrics dataframe
2025-05-19 20:05:43,948:INFO:Uploading results into container
2025-05-19 20:05:43,949:INFO:Uploading model into container now
2025-05-19 20:05:43,950:INFO:_master_model_container: 10
2025-05-19 20:05:43,950:INFO:_display_container: 2
2025-05-19 20:05:43,951:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 20:05:43,951:INFO:create_model() successfully completed......................................
2025-05-19 20:05:44,035:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:44,035:INFO:Creating metrics dataframe
2025-05-19 20:05:44,049:INFO:Initializing Linear Discriminant Analysis
2025-05-19 20:05:44,050:INFO:Total runtime is 0.45663642883300787 minutes
2025-05-19 20:05:44,055:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:44,055:INFO:Initializing create_model()
2025-05-19 20:05:44,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:44,055:INFO:Checking exceptions
2025-05-19 20:05:44,056:INFO:Importing libraries
2025-05-19 20:05:44,056:INFO:Copying training dataset
2025-05-19 20:05:44,062:INFO:Defining folds
2025-05-19 20:05:44,062:INFO:Declaring metric variables
2025-05-19 20:05:44,067:INFO:Importing untrained model
2025-05-19 20:05:44,072:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 20:05:44,083:INFO:Starting cross validation
2025-05-19 20:05:44,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:44,757:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,764:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,770:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,797:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,020:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,208:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,285:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,286:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,461:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,462:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,479:INFO:Calculating mean and std
2025-05-19 20:05:45,482:INFO:Creating metrics dataframe
2025-05-19 20:05:45,486:INFO:Uploading results into container
2025-05-19 20:05:45,487:INFO:Uploading model into container now
2025-05-19 20:05:45,488:INFO:_master_model_container: 11
2025-05-19 20:05:45,488:INFO:_display_container: 2
2025-05-19 20:05:45,489:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 20:05:45,489:INFO:create_model() successfully completed......................................
2025-05-19 20:05:45,600:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:45,601:INFO:Creating metrics dataframe
2025-05-19 20:05:45,617:INFO:Initializing Extra Trees Classifier
2025-05-19 20:05:45,617:INFO:Total runtime is 0.48275386095047 minutes
2025-05-19 20:05:45,624:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:45,624:INFO:Initializing create_model()
2025-05-19 20:05:45,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:45,625:INFO:Checking exceptions
2025-05-19 20:05:45,625:INFO:Importing libraries
2025-05-19 20:05:45,625:INFO:Copying training dataset
2025-05-19 20:05:45,631:INFO:Defining folds
2025-05-19 20:05:45,631:INFO:Declaring metric variables
2025-05-19 20:05:45,636:INFO:Importing untrained model
2025-05-19 20:05:45,644:INFO:Extra Trees Classifier Imported successfully
2025-05-19 20:05:45,655:INFO:Starting cross validation
2025-05-19 20:05:45,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:47,587:INFO:Calculating mean and std
2025-05-19 20:05:47,588:INFO:Creating metrics dataframe
2025-05-19 20:05:47,591:INFO:Uploading results into container
2025-05-19 20:05:47,591:INFO:Uploading model into container now
2025-05-19 20:05:47,592:INFO:_master_model_container: 12
2025-05-19 20:05:47,592:INFO:_display_container: 2
2025-05-19 20:05:47,593:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 20:05:47,593:INFO:create_model() successfully completed......................................
2025-05-19 20:05:47,674:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:47,674:INFO:Creating metrics dataframe
2025-05-19 20:05:47,687:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 20:05:47,687:INFO:Total runtime is 0.5172545711199443 minutes
2025-05-19 20:05:47,692:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:47,692:INFO:Initializing create_model()
2025-05-19 20:05:47,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:47,693:INFO:Checking exceptions
2025-05-19 20:05:47,693:INFO:Importing libraries
2025-05-19 20:05:47,693:INFO:Copying training dataset
2025-05-19 20:05:47,698:INFO:Defining folds
2025-05-19 20:05:47,698:INFO:Declaring metric variables
2025-05-19 20:05:47,703:INFO:Importing untrained model
2025-05-19 20:05:47,709:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 20:05:47,716:INFO:Starting cross validation
2025-05-19 20:05:47,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:48,651:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,704:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,744:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:49,301:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:49,326:INFO:Calculating mean and std
2025-05-19 20:05:49,329:INFO:Creating metrics dataframe
2025-05-19 20:05:49,335:INFO:Uploading results into container
2025-05-19 20:05:49,336:INFO:Uploading model into container now
2025-05-19 20:05:49,337:INFO:_master_model_container: 13
2025-05-19 20:05:49,337:INFO:_display_container: 2
2025-05-19 20:05:49,339:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 20:05:49,339:INFO:create_model() successfully completed......................................
2025-05-19 20:05:49,458:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:49,458:INFO:Creating metrics dataframe
2025-05-19 20:05:49,471:INFO:Initializing Dummy Classifier
2025-05-19 20:05:49,471:INFO:Total runtime is 0.5469799002011618 minutes
2025-05-19 20:05:49,477:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:49,478:INFO:Initializing create_model()
2025-05-19 20:05:49,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:49,478:INFO:Checking exceptions
2025-05-19 20:05:49,478:INFO:Importing libraries
2025-05-19 20:05:49,478:INFO:Copying training dataset
2025-05-19 20:05:49,485:INFO:Defining folds
2025-05-19 20:05:49,485:INFO:Declaring metric variables
2025-05-19 20:05:49,494:INFO:Importing untrained model
2025-05-19 20:05:49,499:INFO:Dummy Classifier Imported successfully
2025-05-19 20:05:49,514:INFO:Starting cross validation
2025-05-19 20:05:49,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:50,413:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,427:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,455:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,597:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,835:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,997:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,021:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,187:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,241:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,245:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,259:INFO:Calculating mean and std
2025-05-19 20:05:51,261:INFO:Creating metrics dataframe
2025-05-19 20:05:51,266:INFO:Uploading results into container
2025-05-19 20:05:51,267:INFO:Uploading model into container now
2025-05-19 20:05:51,269:INFO:_master_model_container: 14
2025-05-19 20:05:51,269:INFO:_display_container: 2
2025-05-19 20:05:51,269:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 20:05:51,269:INFO:create_model() successfully completed......................................
2025-05-19 20:05:51,380:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:51,380:INFO:Creating metrics dataframe
2025-05-19 20:05:51,403:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 20:05:51,421:INFO:Initializing create_model()
2025-05-19 20:05:51,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:51,421:INFO:Checking exceptions
2025-05-19 20:05:51,426:INFO:Importing libraries
2025-05-19 20:05:51,426:INFO:Copying training dataset
2025-05-19 20:05:51,467:INFO:Defining folds
2025-05-19 20:05:51,467:INFO:Declaring metric variables
2025-05-19 20:05:51,468:INFO:Importing untrained model
2025-05-19 20:05:51,468:INFO:Declaring custom model
2025-05-19 20:05:51,469:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:05:51,508:INFO:Cross validation set to False
2025-05-19 20:05:51,508:INFO:Fitting Model
2025-05-19 20:05:51,709:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:05:51,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.
2025-05-19 20:05:51,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:05:51,710:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:05:51,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,783:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:51,783:INFO:create_model() successfully completed......................................
2025-05-19 20:05:51,955:INFO:_master_model_container: 14
2025-05-19 20:05:51,955:INFO:_display_container: 2
2025-05-19 20:05:51,956:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:51,956:INFO:compare_models() successfully completed......................................
2025-05-19 20:24:57,322:INFO:Initializing tune_model()
2025-05-19 20:24:57,322:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:24:57,322:INFO:Checking exceptions
2025-05-19 20:24:57,360:INFO:Copying training dataset
2025-05-19 20:24:57,366:INFO:Checking base model
2025-05-19 20:24:57,366:INFO:Base model : Decision Tree Classifier
2025-05-19 20:24:57,370:INFO:Declaring metric variables
2025-05-19 20:24:57,376:INFO:Defining Hyperparameters
2025-05-19 20:24:57,568:INFO:Tuning with n_jobs=-1
2025-05-19 20:24:57,569:INFO:Initializing RandomizedSearchCV
2025-05-19 20:25:20,475:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 20:25:20,476:INFO:Hyperparameter search completed
2025-05-19 20:25:20,477:INFO:SubProcess create_model() called ==================================
2025-05-19 20:25:20,478:INFO:Initializing create_model()
2025-05-19 20:25:20,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000259961ED3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 20:25:20,479:INFO:Checking exceptions
2025-05-19 20:25:20,480:INFO:Importing libraries
2025-05-19 20:25:20,480:INFO:Copying training dataset
2025-05-19 20:25:20,493:INFO:Defining folds
2025-05-19 20:25:20,494:INFO:Declaring metric variables
2025-05-19 20:25:20,503:INFO:Importing untrained model
2025-05-19 20:25:20,504:INFO:Declaring custom model
2025-05-19 20:25:20,513:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:25:20,531:INFO:Starting cross validation
2025-05-19 20:25:20,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:25:21,529:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:25:22,058:INFO:Calculating mean and std
2025-05-19 20:25:22,060:INFO:Creating metrics dataframe
2025-05-19 20:25:22,069:INFO:Finalizing model
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2025-05-19 20:25:22,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:25:22,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:25:22,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:25:22,221:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:25:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,266:INFO:Uploading results into container
2025-05-19 20:25:22,267:INFO:Uploading model into container now
2025-05-19 20:25:22,268:INFO:_master_model_container: 15
2025-05-19 20:25:22,268:INFO:_display_container: 3
2025-05-19 20:25:22,269:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:22,270:INFO:create_model() successfully completed......................................
2025-05-19 20:25:22,391:INFO:SubProcess create_model() end ==================================
2025-05-19 20:25:22,391:INFO:choose_better activated
2025-05-19 20:25:22,394:INFO:SubProcess create_model() called ==================================
2025-05-19 20:25:22,395:INFO:Initializing create_model()
2025-05-19 20:25:22,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:25:22,395:INFO:Checking exceptions
2025-05-19 20:25:22,397:INFO:Importing libraries
2025-05-19 20:25:22,397:INFO:Copying training dataset
2025-05-19 20:25:22,401:INFO:Defining folds
2025-05-19 20:25:22,401:INFO:Declaring metric variables
2025-05-19 20:25:22,401:INFO:Importing untrained model
2025-05-19 20:25:22,401:INFO:Declaring custom model
2025-05-19 20:25:22,402:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:25:22,403:INFO:Starting cross validation
2025-05-19 20:25:22,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:25:23,485:INFO:Calculating mean and std
2025-05-19 20:25:23,486:INFO:Creating metrics dataframe
2025-05-19 20:25:23,492:INFO:Finalizing model
2025-05-19 20:25:23,630:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:25:23,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.
2025-05-19 20:25:23,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:25:23,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:25:23,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,670:INFO:Uploading results into container
2025-05-19 20:25:23,670:INFO:Uploading model into container now
2025-05-19 20:25:23,671:INFO:_master_model_container: 16
2025-05-19 20:25:23,671:INFO:_display_container: 4
2025-05-19 20:25:23,672:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:23,672:INFO:create_model() successfully completed......................................
2025-05-19 20:25:23,768:INFO:SubProcess create_model() end ==================================
2025-05-19 20:25:23,769:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-05-19 20:25:23,769:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-05-19 20:25:23,770:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 20:25:23,770:INFO:choose_better completed
2025-05-19 20:25:23,771:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:25:23,783:INFO:_master_model_container: 16
2025-05-19 20:25:23,784:INFO:_display_container: 3
2025-05-19 20:25:23,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:23,784:INFO:tune_model() successfully completed......................................
2025-05-19 20:25:23,896:INFO:Initializing plot_model()
2025-05-19 20:25:23,897:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:25:23,897:INFO:Checking exceptions
2025-05-19 20:25:23,901:INFO:Preloading libraries
2025-05-19 20:25:23,902:INFO:Copying training dataset
2025-05-19 20:25:23,902:INFO:Plot type: pr
2025-05-19 20:25:24,069:INFO:Fitting Model
2025-05-19 20:25:24,110:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:25:24,111:INFO:Scoring test/hold-out set
2025-05-19 20:25:24,335:INFO:Visual Rendered Successfully
2025-05-19 20:25:24,413:INFO:plot_model() successfully completed......................................
2025-05-19 20:25:24,414:INFO:Initializing plot_model()
2025-05-19 20:25:24,414:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:25:24,414:INFO:Checking exceptions
2025-05-19 20:25:24,418:INFO:Preloading libraries
2025-05-19 20:25:24,418:INFO:Copying training dataset
2025-05-19 20:25:24,418:INFO:Plot type: confusion_matrix
2025-05-19 20:25:24,562:INFO:Fitting Model
2025-05-19 20:25:24,562:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:25:24,563:INFO:Scoring test/hold-out set
2025-05-19 20:25:24,727:INFO:Visual Rendered Successfully
2025-05-19 20:25:24,816:INFO:plot_model() successfully completed......................................
2025-05-19 20:27:33,335:INFO:Initializing create_model()
2025-05-19 20:27:33,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:27:33,336:INFO:Checking exceptions
2025-05-19 20:27:33,365:INFO:Importing libraries
2025-05-19 20:27:33,365:INFO:Copying training dataset
2025-05-19 20:27:33,379:INFO:Defining folds
2025-05-19 20:27:33,379:INFO:Declaring metric variables
2025-05-19 20:27:33,384:INFO:Importing untrained model
2025-05-19 20:27:33,389:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:27:33,402:INFO:Starting cross validation
2025-05-19 20:27:33,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:27:34,170:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,182:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,183:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,222:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,308:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,351:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,527:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,587:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,987:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:35,038:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:27:35,172:INFO:Calculating mean and std
2025-05-19 20:27:35,173:INFO:Creating metrics dataframe
2025-05-19 20:27:35,178:INFO:Finalizing model
2025-05-19 20:27:35,300:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-05-19 20:27:35,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:27:35,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:27:35,302:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:27:35,302:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:27:35,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,350:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:35,480:INFO:Uploading results into container
2025-05-19 20:27:35,482:INFO:Uploading model into container now
2025-05-19 20:27:35,494:INFO:_master_model_container: 17
2025-05-19 20:27:35,494:INFO:_display_container: 4
2025-05-19 20:27:35,495:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:27:35,495:INFO:create_model() successfully completed......................................
2025-05-19 20:29:26,910:INFO:Initializing tune_model()
2025-05-19 20:29:26,910:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:29:26,911:INFO:Checking exceptions
2025-05-19 20:29:26,946:INFO:Copying training dataset
2025-05-19 20:29:26,953:INFO:Checking base model
2025-05-19 20:29:26,953:INFO:Base model : Ada Boost Classifier
2025-05-19 20:29:26,959:INFO:Declaring metric variables
2025-05-19 20:29:26,965:INFO:Defining Hyperparameters
2025-05-19 20:29:27,126:INFO:Tuning with n_jobs=-1
2025-05-19 20:29:27,126:INFO:Initializing RandomizedSearchCV
2025-05-19 20:29:44,282:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:29:44,284:INFO:Hyperparameter search completed
2025-05-19 20:29:44,284:INFO:SubProcess create_model() called ==================================
2025-05-19 20:29:44,285:INFO:Initializing create_model()
2025-05-19 20:29:44,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025997B18DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:29:44,286:INFO:Checking exceptions
2025-05-19 20:29:44,286:INFO:Importing libraries
2025-05-19 20:29:44,287:INFO:Copying training dataset
2025-05-19 20:29:44,295:INFO:Defining folds
2025-05-19 20:29:44,295:INFO:Declaring metric variables
2025-05-19 20:29:44,301:INFO:Importing untrained model
2025-05-19 20:29:44,301:INFO:Declaring custom model
2025-05-19 20:29:44,309:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:44,328:INFO:Starting cross validation
2025-05-19 20:29:44,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:46,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:46,952:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:46,991:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:47,142:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,105:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,226:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,228:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,241:INFO:Calculating mean and std
2025-05-19 20:29:48,242:INFO:Creating metrics dataframe
2025-05-19 20:29:48,248:INFO:Finalizing model
2025-05-19 20:29:48,383:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:48,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2025-05-19 20:29:48,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,823:INFO:Uploading results into container
2025-05-19 20:29:48,824:INFO:Uploading model into container now
2025-05-19 20:29:48,825:INFO:_master_model_container: 18
2025-05-19 20:29:48,825:INFO:_display_container: 5
2025-05-19 20:29:48,825:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:29:48,825:INFO:create_model() successfully completed......................................
2025-05-19 20:29:48,913:INFO:SubProcess create_model() end ==================================
2025-05-19 20:29:48,913:INFO:choose_better activated
2025-05-19 20:29:48,916:INFO:SubProcess create_model() called ==================================
2025-05-19 20:29:48,917:INFO:Initializing create_model()
2025-05-19 20:29:48,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:29:48,917:INFO:Checking exceptions
2025-05-19 20:29:48,918:INFO:Importing libraries
2025-05-19 20:29:48,918:INFO:Copying training dataset
2025-05-19 20:29:48,923:INFO:Defining folds
2025-05-19 20:29:48,923:INFO:Declaring metric variables
2025-05-19 20:29:48,923:INFO:Importing untrained model
2025-05-19 20:29:48,923:INFO:Declaring custom model
2025-05-19 20:29:48,924:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:48,924:INFO:Starting cross validation
2025-05-19 20:29:48,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:49,426:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,445:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,567:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,864:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,904:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,995:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,162:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,220:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,239:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:50,457:INFO:Calculating mean and std
2025-05-19 20:29:50,457:INFO:Creating metrics dataframe
2025-05-19 20:29:50,459:INFO:Finalizing model
2025-05-19 20:29:50,592:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:50,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2025-05-19 20:29:50,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:29:50,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:29:50,593:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:50,593:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:50,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:50,594:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,628:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,749:INFO:Uploading results into container
2025-05-19 20:29:50,750:INFO:Uploading model into container now
2025-05-19 20:29:50,750:INFO:_master_model_container: 19
2025-05-19 20:29:50,750:INFO:_display_container: 6
2025-05-19 20:29:50,750:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:50,750:INFO:create_model() successfully completed......................................
2025-05-19 20:29:50,832:INFO:SubProcess create_model() end ==================================
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for F1 is 0.3167
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for F1 is 0.15
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:29:50,833:INFO:choose_better completed
2025-05-19 20:29:50,834:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:29:50,846:INFO:_master_model_container: 19
2025-05-19 20:29:50,846:INFO:_display_container: 5
2025-05-19 20:29:50,846:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:50,847:INFO:tune_model() successfully completed......................................
2025-05-19 20:29:50,934:INFO:Initializing plot_model()
2025-05-19 20:29:50,934:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:29:50,934:INFO:Checking exceptions
2025-05-19 20:29:50,942:INFO:Preloading libraries
2025-05-19 20:29:50,948:INFO:Copying training dataset
2025-05-19 20:29:50,948:INFO:Plot type: pr
2025-05-19 20:29:51,141:INFO:Fitting Model
2025-05-19 20:29:51,142:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:29:51,143:INFO:Scoring test/hold-out set
2025-05-19 20:29:51,423:INFO:Visual Rendered Successfully
2025-05-19 20:29:51,513:INFO:plot_model() successfully completed......................................
2025-05-19 20:29:51,514:INFO:Initializing plot_model()
2025-05-19 20:29:51,514:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:29:51,514:INFO:Checking exceptions
2025-05-19 20:29:51,519:INFO:Preloading libraries
2025-05-19 20:29:51,527:INFO:Copying training dataset
2025-05-19 20:29:51,527:INFO:Plot type: confusion_matrix
2025-05-19 20:29:51,684:INFO:Fitting Model
2025-05-19 20:29:51,684:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:29:51,684:INFO:Scoring test/hold-out set
2025-05-19 20:29:51,923:INFO:Visual Rendered Successfully
2025-05-19 20:29:52,049:INFO:plot_model() successfully completed......................................
2025-05-19 20:29:52,049:INFO:Initializing create_model()
2025-05-19 20:29:52,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:29:52,050:INFO:Checking exceptions
2025-05-19 20:29:52,077:INFO:Importing libraries
2025-05-19 20:29:52,078:INFO:Copying training dataset
2025-05-19 20:29:52,090:INFO:Defining folds
2025-05-19 20:29:52,091:INFO:Declaring metric variables
2025-05-19 20:29:52,107:INFO:Importing untrained model
2025-05-19 20:29:52,114:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:52,127:INFO:Starting cross validation
2025-05-19 20:29:52,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:52,864:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,873:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,897:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,032:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,034:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,220:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,281:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,524:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,573:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,595:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:53,795:INFO:Calculating mean and std
2025-05-19 20:29:53,797:INFO:Creating metrics dataframe
2025-05-19 20:29:53,805:INFO:Finalizing model
2025-05-19 20:29:53,986:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:53,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.
2025-05-19 20:29:53,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,114:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:54,268:INFO:Uploading results into container
2025-05-19 20:29:54,269:INFO:Uploading model into container now
2025-05-19 20:29:54,286:INFO:_master_model_container: 20
2025-05-19 20:29:54,286:INFO:_display_container: 6
2025-05-19 20:29:54,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:54,287:INFO:create_model() successfully completed......................................
2025-05-19 20:30:02,724:INFO:Initializing create_model()
2025-05-19 20:30:02,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:02,724:INFO:Checking exceptions
2025-05-19 20:30:02,747:INFO:Importing libraries
2025-05-19 20:30:02,748:INFO:Copying training dataset
2025-05-19 20:30:02,758:INFO:Defining folds
2025-05-19 20:30:02,759:INFO:Declaring metric variables
2025-05-19 20:30:02,766:INFO:Importing untrained model
2025-05-19 20:30:02,774:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:02,787:INFO:Starting cross validation
2025-05-19 20:30:02,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:03,603:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,605:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,607:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,622:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,749:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,790:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,048:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,149:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,309:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,341:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,471:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:04,609:INFO:Calculating mean and std
2025-05-19 20:30:04,611:INFO:Creating metrics dataframe
2025-05-19 20:30:04,618:INFO:Finalizing model
2025-05-19 20:30:04,782:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:04,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-05-19 20:30:04,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:04,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,847:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,977:INFO:Uploading results into container
2025-05-19 20:30:04,978:INFO:Uploading model into container now
2025-05-19 20:30:04,993:INFO:_master_model_container: 21
2025-05-19 20:30:04,993:INFO:_display_container: 7
2025-05-19 20:30:04,994:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:04,994:INFO:create_model() successfully completed......................................
2025-05-19 20:30:05,099:INFO:Initializing tune_model()
2025-05-19 20:30:05,100:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:30:05,100:INFO:Checking exceptions
2025-05-19 20:30:05,121:INFO:Copying training dataset
2025-05-19 20:30:05,126:INFO:Checking base model
2025-05-19 20:30:05,127:INFO:Base model : Ada Boost Classifier
2025-05-19 20:30:05,132:INFO:Declaring metric variables
2025-05-19 20:30:05,139:INFO:Defining Hyperparameters
2025-05-19 20:30:05,246:INFO:Tuning with n_jobs=-1
2025-05-19 20:30:05,246:INFO:Initializing RandomizedSearchCV
2025-05-19 20:30:31,104:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:30:31,106:INFO:Hyperparameter search completed
2025-05-19 20:30:31,106:INFO:SubProcess create_model() called ==================================
2025-05-19 20:30:31,108:INFO:Initializing create_model()
2025-05-19 20:30:31,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000259F40470D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:30:31,108:INFO:Checking exceptions
2025-05-19 20:30:31,109:INFO:Importing libraries
2025-05-19 20:30:31,109:INFO:Copying training dataset
2025-05-19 20:30:31,126:INFO:Defining folds
2025-05-19 20:30:31,126:INFO:Declaring metric variables
2025-05-19 20:30:31,134:INFO:Importing untrained model
2025-05-19 20:30:31,134:INFO:Declaring custom model
2025-05-19 20:30:31,142:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:31,173:INFO:Starting cross validation
2025-05-19 20:30:31,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:33,634:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,143:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,425:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,356:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,480:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,552:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,561:INFO:Calculating mean and std
2025-05-19 20:30:35,563:INFO:Creating metrics dataframe
2025-05-19 20:30:35,574:INFO:Finalizing model
2025-05-19 20:30:35,841:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000063 seconds.
2025-05-19 20:30:35,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:35,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:35,843:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:36,517:INFO:Uploading results into container
2025-05-19 20:30:36,518:INFO:Uploading model into container now
2025-05-19 20:30:36,519:INFO:_master_model_container: 22
2025-05-19 20:30:36,519:INFO:_display_container: 8
2025-05-19 20:30:36,520:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:30:36,520:INFO:create_model() successfully completed......................................
2025-05-19 20:30:36,648:INFO:SubProcess create_model() end ==================================
2025-05-19 20:30:36,649:INFO:choose_better activated
2025-05-19 20:30:36,656:INFO:SubProcess create_model() called ==================================
2025-05-19 20:30:36,656:INFO:Initializing create_model()
2025-05-19 20:30:36,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:36,657:INFO:Checking exceptions
2025-05-19 20:30:36,660:INFO:Importing libraries
2025-05-19 20:30:36,660:INFO:Copying training dataset
2025-05-19 20:30:36,669:INFO:Defining folds
2025-05-19 20:30:36,670:INFO:Declaring metric variables
2025-05-19 20:30:36,670:INFO:Importing untrained model
2025-05-19 20:30:36,670:INFO:Declaring custom model
2025-05-19 20:30:36,671:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:36,671:INFO:Starting cross validation
2025-05-19 20:30:36,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:37,760:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:37,763:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:37,793:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,328:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,354:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,808:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,851:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,950:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,054:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,072:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,179:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:39,366:INFO:Calculating mean and std
2025-05-19 20:30:39,367:INFO:Creating metrics dataframe
2025-05-19 20:30:39,373:INFO:Finalizing model
2025-05-19 20:30:39,531:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:39,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.
2025-05-19 20:30:39,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:39,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:39,534:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,578:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,708:INFO:Uploading results into container
2025-05-19 20:30:39,708:INFO:Uploading model into container now
2025-05-19 20:30:39,709:INFO:_master_model_container: 23
2025-05-19 20:30:39,709:INFO:_display_container: 9
2025-05-19 20:30:39,709:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:39,709:INFO:create_model() successfully completed......................................
2025-05-19 20:30:39,787:INFO:SubProcess create_model() end ==================================
2025-05-19 20:30:39,788:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for F1 is 0.3167
2025-05-19 20:30:39,788:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for F1 is 0.15
2025-05-19 20:30:39,789:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:30:39,789:INFO:choose_better completed
2025-05-19 20:30:39,789:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:30:39,800:INFO:_master_model_container: 23
2025-05-19 20:30:39,800:INFO:_display_container: 8
2025-05-19 20:30:39,801:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:39,801:INFO:tune_model() successfully completed......................................
2025-05-19 20:30:39,942:INFO:Initializing plot_model()
2025-05-19 20:30:39,942:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:30:39,942:INFO:Checking exceptions
2025-05-19 20:30:39,948:INFO:Preloading libraries
2025-05-19 20:30:39,954:INFO:Copying training dataset
2025-05-19 20:30:39,954:INFO:Plot type: pr
2025-05-19 20:30:40,121:INFO:Fitting Model
2025-05-19 20:30:40,121:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:30:40,121:INFO:Scoring test/hold-out set
2025-05-19 20:30:40,382:INFO:Visual Rendered Successfully
2025-05-19 20:30:40,460:INFO:plot_model() successfully completed......................................
2025-05-19 20:30:40,461:INFO:Initializing plot_model()
2025-05-19 20:30:40,461:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:30:40,461:INFO:Checking exceptions
2025-05-19 20:30:40,467:INFO:Preloading libraries
2025-05-19 20:30:40,473:INFO:Copying training dataset
2025-05-19 20:30:40,473:INFO:Plot type: confusion_matrix
2025-05-19 20:30:40,615:INFO:Fitting Model
2025-05-19 20:30:40,615:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:30:40,616:INFO:Scoring test/hold-out set
2025-05-19 20:30:40,787:INFO:Visual Rendered Successfully
2025-05-19 20:30:40,871:INFO:plot_model() successfully completed......................................
2025-05-19 20:30:43,373:INFO:Initializing create_model()
2025-05-19 20:30:43,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:43,374:INFO:Checking exceptions
2025-05-19 20:30:43,396:INFO:Importing libraries
2025-05-19 20:30:43,396:INFO:Copying training dataset
2025-05-19 20:30:43,402:INFO:Defining folds
2025-05-19 20:30:43,403:INFO:Declaring metric variables
2025-05-19 20:30:43,410:INFO:Importing untrained model
2025-05-19 20:30:43,420:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:43,430:INFO:Starting cross validation
2025-05-19 20:30:43,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:43,983:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:43,991:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,010:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,022:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,169:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,206:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,316:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,320:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,669:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,677:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,721:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:44,922:INFO:Calculating mean and std
2025-05-19 20:30:44,924:INFO:Creating metrics dataframe
2025-05-19 20:30:44,930:INFO:Finalizing model
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.
2025-05-19 20:30:45,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:45,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,120:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:45,247:INFO:Uploading results into container
2025-05-19 20:30:45,248:INFO:Uploading model into container now
2025-05-19 20:30:45,261:INFO:_master_model_container: 24
2025-05-19 20:30:45,262:INFO:_display_container: 9
2025-05-19 20:30:45,263:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:45,263:INFO:create_model() successfully completed......................................
2025-05-19 20:30:45,353:INFO:Initializing tune_model()
2025-05-19 20:30:45,354:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:30:45,354:INFO:Checking exceptions
2025-05-19 20:30:45,373:INFO:Copying training dataset
2025-05-19 20:30:45,378:INFO:Checking base model
2025-05-19 20:30:45,379:INFO:Base model : Ada Boost Classifier
2025-05-19 20:30:45,387:INFO:Declaring metric variables
2025-05-19 20:30:45,393:INFO:Defining Hyperparameters
2025-05-19 20:30:45,501:INFO:Tuning with n_jobs=-1
2025-05-19 20:30:45,501:INFO:Initializing RandomizedSearchCV
2025-05-19 20:30:46,639:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,640:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,650:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,664:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,868:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,032:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,284:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,501:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,041:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,298:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,630:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,729:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:49,453:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,682:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,828:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,832:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,000:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,055:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,194:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,203:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,865:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,041:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,531:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,543:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,707:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,876:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,888:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:53,121:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,071:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,109:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,135:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,262:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,537:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,072:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,171:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,266:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,283:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,455:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,715:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,591:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,865:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,342:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,551:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,632:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,063:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,276:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,407:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,714:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,716:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,775:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,509:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,573:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,712:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,950:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:00,518:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:00,675:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,150:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,456:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,769:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,944:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:02,296:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:02,736:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,070:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,297:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,622:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,803:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,863:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,076:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,221:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,901:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,021:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,042:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,263:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,469:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,615:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,925:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,091:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,466:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,589:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,946:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:07,149:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,170:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,297:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,316:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,378:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,398:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,402:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:31:08,403:INFO:Hyperparameter search completed
2025-05-19 20:31:08,403:INFO:SubProcess create_model() called ==================================
2025-05-19 20:31:08,404:INFO:Initializing create_model()
2025-05-19 20:31:08,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599A7C4D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:31:08,404:INFO:Checking exceptions
2025-05-19 20:31:08,404:INFO:Importing libraries
2025-05-19 20:31:08,405:INFO:Copying training dataset
2025-05-19 20:31:08,414:INFO:Defining folds
2025-05-19 20:31:08,414:INFO:Declaring metric variables
2025-05-19 20:31:08,419:INFO:Importing untrained model
2025-05-19 20:31:08,419:INFO:Declaring custom model
2025-05-19 20:31:08,424:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:31:08,434:INFO:Starting cross validation
2025-05-19 20:31:08,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:31:10,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:10,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:10,731:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,244:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,551:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,580:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,592:INFO:Calculating mean and std
2025-05-19 20:31:11,598:INFO:Creating metrics dataframe
2025-05-19 20:31:11,616:INFO:Finalizing model
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000062 seconds.
2025-05-19 20:31:11,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:31:11,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:12,229:INFO:Uploading results into container
2025-05-19 20:31:12,232:INFO:Uploading model into container now
2025-05-19 20:31:12,233:INFO:_master_model_container: 25
2025-05-19 20:31:12,233:INFO:_display_container: 10
2025-05-19 20:31:12,234:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:31:12,234:INFO:create_model() successfully completed......................................
2025-05-19 20:31:12,333:INFO:SubProcess create_model() end ==================================
2025-05-19 20:31:12,333:INFO:choose_better activated
2025-05-19 20:31:12,337:INFO:SubProcess create_model() called ==================================
2025-05-19 20:31:12,338:INFO:Initializing create_model()
2025-05-19 20:31:12,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:31:12,338:INFO:Checking exceptions
2025-05-19 20:31:12,340:INFO:Importing libraries
2025-05-19 20:31:12,340:INFO:Copying training dataset
2025-05-19 20:31:12,347:INFO:Defining folds
2025-05-19 20:31:12,348:INFO:Declaring metric variables
2025-05-19 20:31:12,348:INFO:Importing untrained model
2025-05-19 20:31:12,348:INFO:Declaring custom model
2025-05-19 20:31:12,350:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:31:12,351:INFO:Starting cross validation
2025-05-19 20:31:12,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:31:13,008:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,029:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,036:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,098:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,399:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,540:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,635:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,883:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,923:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,979:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:14,200:INFO:Calculating mean and std
2025-05-19 20:31:14,201:INFO:Creating metrics dataframe
2025-05-19 20:31:14,204:INFO:Finalizing model
2025-05-19 20:31:14,363:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:31:14,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2025-05-19 20:31:14,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:31:14,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:31:14,365:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:31:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,409:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:14,561:INFO:Uploading results into container
2025-05-19 20:31:14,562:INFO:Uploading model into container now
2025-05-19 20:31:14,563:INFO:_master_model_container: 26
2025-05-19 20:31:14,563:INFO:_display_container: 11
2025-05-19 20:31:14,563:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:31:14,563:INFO:create_model() successfully completed......................................
2025-05-19 20:31:14,652:INFO:SubProcess create_model() end ==================================
2025-05-19 20:31:14,652:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for Prec. is 0.4167
2025-05-19 20:31:14,653:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for Prec. is 0.3
2025-05-19 20:31:14,653:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:31:14,653:INFO:choose_better completed
2025-05-19 20:31:14,653:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:31:14,665:INFO:_master_model_container: 26
2025-05-19 20:31:14,666:INFO:_display_container: 10
2025-05-19 20:31:14,666:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:31:14,666:INFO:tune_model() successfully completed......................................
2025-05-19 20:31:14,763:INFO:Initializing plot_model()
2025-05-19 20:31:14,763:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:31:14,763:INFO:Checking exceptions
2025-05-19 20:31:14,768:INFO:Preloading libraries
2025-05-19 20:31:14,774:INFO:Copying training dataset
2025-05-19 20:31:14,774:INFO:Plot type: pr
2025-05-19 20:31:14,924:INFO:Fitting Model
2025-05-19 20:31:14,925:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:31:14,925:INFO:Scoring test/hold-out set
2025-05-19 20:31:15,194:INFO:Visual Rendered Successfully
2025-05-19 20:31:15,281:INFO:plot_model() successfully completed......................................
2025-05-19 20:31:15,281:INFO:Initializing plot_model()
2025-05-19 20:31:15,281:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:31:15,281:INFO:Checking exceptions
2025-05-19 20:31:15,287:INFO:Preloading libraries
2025-05-19 20:31:15,293:INFO:Copying training dataset
2025-05-19 20:31:15,294:INFO:Plot type: confusion_matrix
2025-05-19 20:31:15,478:INFO:Fitting Model
2025-05-19 20:31:15,480:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:31:15,480:INFO:Scoring test/hold-out set
2025-05-19 20:31:15,678:INFO:Visual Rendered Successfully
2025-05-19 20:31:15,769:INFO:plot_model() successfully completed......................................
2025-05-19 20:31:48,952:INFO:Initializing interpret_model()
2025-05-19 20:31:48,952:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-19 20:31:48,952:INFO:Checking exceptions
2025-05-19 20:31:48,952:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-19 21:27:38,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 21:27:38,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 21:27:38,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 21:27:38,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 22:08:31,510:INFO:PyCaret ClassificationExperiment
2025-05-19 22:08:31,510:INFO:Logging name: clf-default-name
2025-05-19 22:08:31,510:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 22:08:31,510:INFO:version 3.3.2
2025-05-19 22:08:31,510:INFO:Initializing setup()
2025-05-19 22:08:31,510:INFO:self.USI: a631
2025-05-19 22:08:31,511:INFO:self._variable_keys: {'exp_id', 'is_multiclass', 'target_param', 'seed', 'logging_param', 'X', 'fix_imbalance', 'USI', 'y', 'n_jobs_param', 'html_param', 'y_test', 'pipeline', '_ml_usecase', 'memory', 'exp_name_log', 'X_test', 'gpu_n_jobs_param', 'data', 'fold_generator', 'idx', 'y_train', 'X_train', '_available_plots', 'gpu_param', 'log_plots_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-05-19 22:08:31,511:INFO:Checking environment
2025-05-19 22:08:31,511:INFO:python_version: 3.11.0
2025-05-19 22:08:31,511:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-19 22:08:31,511:INFO:machine: AMD64
2025-05-19 22:08:31,511:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-19 22:08:31,516:INFO:Memory: svmem(total=12759322624, available=1548935168, percent=87.9, used=11210387456, free=1548935168)
2025-05-19 22:08:31,516:INFO:Physical Core: 4
2025-05-19 22:08:31,516:INFO:Logical Core: 8
2025-05-19 22:08:31,516:INFO:Checking libraries
2025-05-19 22:08:31,516:INFO:System:
2025-05-19 22:08:31,516:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-19 22:08:31,516:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-19 22:08:31,516:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-19 22:08:31,516:INFO:PyCaret required dependencies:
2025-05-19 22:08:31,574:INFO:                 pip: 22.3
2025-05-19 22:08:31,574:INFO:          setuptools: 65.5.0
2025-05-19 22:08:31,574:INFO:             pycaret: 3.3.2
2025-05-19 22:08:31,574:INFO:             IPython: 9.2.0
2025-05-19 22:08:31,574:INFO:          ipywidgets: 8.1.7
2025-05-19 22:08:31,574:INFO:                tqdm: 4.67.1
2025-05-19 22:08:31,574:INFO:               numpy: 1.26.4
2025-05-19 22:08:31,574:INFO:              pandas: 2.1.4
2025-05-19 22:08:31,574:INFO:              jinja2: 3.1.6
2025-05-19 22:08:31,575:INFO:               scipy: 1.11.4
2025-05-19 22:08:31,575:INFO:              joblib: 1.3.2
2025-05-19 22:08:31,575:INFO:             sklearn: 1.4.2
2025-05-19 22:08:31,575:INFO:                pyod: 2.0.5
2025-05-19 22:08:31,575:INFO:            imblearn: 0.13.0
2025-05-19 22:08:31,575:INFO:   category_encoders: 2.7.0
2025-05-19 22:08:31,575:INFO:            lightgbm: 4.6.0
2025-05-19 22:08:31,575:INFO:               numba: 0.61.2
2025-05-19 22:08:31,575:INFO:            requests: 2.32.3
2025-05-19 22:08:31,575:INFO:          matplotlib: 3.7.5
2025-05-19 22:08:31,575:INFO:          scikitplot: 0.3.7
2025-05-19 22:08:31,575:INFO:         yellowbrick: 1.5
2025-05-19 22:08:31,575:INFO:              plotly: 5.24.1
2025-05-19 22:08:31,575:INFO:    plotly-resampler: Not installed
2025-05-19 22:08:31,575:INFO:             kaleido: 0.2.1
2025-05-19 22:08:31,575:INFO:           schemdraw: 0.15
2025-05-19 22:08:31,575:INFO:         statsmodels: 0.14.4
2025-05-19 22:08:31,575:INFO:              sktime: 0.26.0
2025-05-19 22:08:31,575:INFO:               tbats: 1.1.3
2025-05-19 22:08:31,575:INFO:            pmdarima: 2.0.4
2025-05-19 22:08:31,575:INFO:              psutil: 7.0.0
2025-05-19 22:08:31,575:INFO:          markupsafe: 3.0.2
2025-05-19 22:08:31,575:INFO:             pickle5: Not installed
2025-05-19 22:08:31,575:INFO:         cloudpickle: 3.1.1
2025-05-19 22:08:31,575:INFO:         deprecation: 2.1.0
2025-05-19 22:08:31,576:INFO:              xxhash: 3.5.0
2025-05-19 22:08:31,576:INFO:           wurlitzer: Not installed
2025-05-19 22:08:31,576:INFO:PyCaret optional dependencies:
2025-05-19 22:08:31,594:INFO:                shap: Not installed
2025-05-19 22:08:31,594:INFO:           interpret: Not installed
2025-05-19 22:08:31,594:INFO:                umap: Not installed
2025-05-19 22:08:31,594:INFO:     ydata_profiling: Not installed
2025-05-19 22:08:31,594:INFO:  explainerdashboard: Not installed
2025-05-19 22:08:31,594:INFO:             autoviz: Not installed
2025-05-19 22:08:31,594:INFO:           fairlearn: Not installed
2025-05-19 22:08:31,594:INFO:          deepchecks: Not installed
2025-05-19 22:08:31,594:INFO:             xgboost: Not installed
2025-05-19 22:08:31,594:INFO:            catboost: Not installed
2025-05-19 22:08:31,594:INFO:              kmodes: Not installed
2025-05-19 22:08:31,595:INFO:             mlxtend: Not installed
2025-05-19 22:08:31,595:INFO:       statsforecast: Not installed
2025-05-19 22:08:31,595:INFO:        tune_sklearn: Not installed
2025-05-19 22:08:31,595:INFO:                 ray: Not installed
2025-05-19 22:08:31,595:INFO:            hyperopt: Not installed
2025-05-19 22:08:31,595:INFO:              optuna: Not installed
2025-05-19 22:08:31,595:INFO:               skopt: Not installed
2025-05-19 22:08:31,595:INFO:              mlflow: Not installed
2025-05-19 22:08:31,595:INFO:              gradio: Not installed
2025-05-19 22:08:31,595:INFO:             fastapi: Not installed
2025-05-19 22:08:31,595:INFO:             uvicorn: Not installed
2025-05-19 22:08:31,595:INFO:              m2cgen: Not installed
2025-05-19 22:08:31,595:INFO:           evidently: Not installed
2025-05-19 22:08:31,595:INFO:               fugue: Not installed
2025-05-19 22:08:31,595:INFO:           streamlit: Not installed
2025-05-19 22:08:31,595:INFO:             prophet: Not installed
2025-05-19 22:08:31,595:INFO:None
2025-05-19 22:08:31,595:INFO:Set up data.
2025-05-19 22:08:31,615:INFO:Set up folding strategy.
2025-05-19 22:08:31,615:INFO:Set up train/test split.
2025-05-19 22:08:31,638:INFO:Set up index.
2025-05-19 22:08:31,639:INFO:Assigning column types.
2025-05-19 22:08:31,644:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 22:08:31,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:08:31,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:08:31,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:31,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:31,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:08:31,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:08:31,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:31,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:31,842:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 22:08:31,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:08:31,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:31,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:08:32,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,035:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 22:08:32,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,202:INFO:Preparing preprocessing pipeline...
2025-05-19 22:08:32,205:INFO:Set up simple imputation.
2025-05-19 22:08:32,210:INFO:Set up encoding of categorical features.
2025-05-19 22:08:32,211:INFO:Set up removing multicollinearity.
2025-05-19 22:08:32,211:INFO:Set up column transformation.
2025-05-19 22:08:32,211:INFO:Set up feature normalization.
2025-05-19 22:08:32,211:INFO:Set up feature selection.
2025-05-19 22:08:32,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:08:32,950:INFO:Finished creating preprocessing pipeline.
2025-05-19 22:08:32,992:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'numero_productos',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal',
                                             'tasa_cierre', 'indice_digital'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 22:08:32,992:INFO:Creating final display dataframe.
2025-05-19 22:09:27,042:INFO:PyCaret ClassificationExperiment
2025-05-19 22:09:27,043:INFO:Logging name: clf-default-name
2025-05-19 22:09:27,043:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 22:09:27,043:INFO:version 3.3.2
2025-05-19 22:09:27,043:INFO:Initializing setup()
2025-05-19 22:09:27,043:INFO:self.USI: 641f
2025-05-19 22:09:27,043:INFO:self._variable_keys: {'exp_id', 'is_multiclass', 'target_param', 'seed', 'logging_param', 'X', 'fix_imbalance', 'USI', 'y', 'n_jobs_param', 'html_param', 'y_test', 'pipeline', '_ml_usecase', 'memory', 'exp_name_log', 'X_test', 'gpu_n_jobs_param', 'data', 'fold_generator', 'idx', 'y_train', 'X_train', '_available_plots', 'gpu_param', 'log_plots_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-05-19 22:09:27,043:INFO:Checking environment
2025-05-19 22:09:27,043:INFO:python_version: 3.11.0
2025-05-19 22:09:27,043:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-19 22:09:27,043:INFO:machine: AMD64
2025-05-19 22:09:27,043:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-19 22:09:27,053:INFO:Memory: svmem(total=12759322624, available=1517199360, percent=88.1, used=11242123264, free=1517199360)
2025-05-19 22:09:27,053:INFO:Physical Core: 4
2025-05-19 22:09:27,053:INFO:Logical Core: 8
2025-05-19 22:09:27,054:INFO:Checking libraries
2025-05-19 22:09:27,054:INFO:System:
2025-05-19 22:09:27,054:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-19 22:09:27,054:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-19 22:09:27,054:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-19 22:09:27,054:INFO:PyCaret required dependencies:
2025-05-19 22:09:27,054:INFO:                 pip: 22.3
2025-05-19 22:09:27,054:INFO:          setuptools: 65.5.0
2025-05-19 22:09:27,054:INFO:             pycaret: 3.3.2
2025-05-19 22:09:27,054:INFO:             IPython: 9.2.0
2025-05-19 22:09:27,054:INFO:          ipywidgets: 8.1.7
2025-05-19 22:09:27,055:INFO:                tqdm: 4.67.1
2025-05-19 22:09:27,055:INFO:               numpy: 1.26.4
2025-05-19 22:09:27,055:INFO:              pandas: 2.1.4
2025-05-19 22:09:27,055:INFO:              jinja2: 3.1.6
2025-05-19 22:09:27,055:INFO:               scipy: 1.11.4
2025-05-19 22:09:27,055:INFO:              joblib: 1.3.2
2025-05-19 22:09:27,055:INFO:             sklearn: 1.4.2
2025-05-19 22:09:27,055:INFO:                pyod: 2.0.5
2025-05-19 22:09:27,055:INFO:            imblearn: 0.13.0
2025-05-19 22:09:27,055:INFO:   category_encoders: 2.7.0
2025-05-19 22:09:27,056:INFO:            lightgbm: 4.6.0
2025-05-19 22:09:27,056:INFO:               numba: 0.61.2
2025-05-19 22:09:27,056:INFO:            requests: 2.32.3
2025-05-19 22:09:27,056:INFO:          matplotlib: 3.7.5
2025-05-19 22:09:27,056:INFO:          scikitplot: 0.3.7
2025-05-19 22:09:27,056:INFO:         yellowbrick: 1.5
2025-05-19 22:09:27,056:INFO:              plotly: 5.24.1
2025-05-19 22:09:27,056:INFO:    plotly-resampler: Not installed
2025-05-19 22:09:27,056:INFO:             kaleido: 0.2.1
2025-05-19 22:09:27,056:INFO:           schemdraw: 0.15
2025-05-19 22:09:27,056:INFO:         statsmodels: 0.14.4
2025-05-19 22:09:27,056:INFO:              sktime: 0.26.0
2025-05-19 22:09:27,056:INFO:               tbats: 1.1.3
2025-05-19 22:09:27,057:INFO:            pmdarima: 2.0.4
2025-05-19 22:09:27,057:INFO:              psutil: 7.0.0
2025-05-19 22:09:27,057:INFO:          markupsafe: 3.0.2
2025-05-19 22:09:27,057:INFO:             pickle5: Not installed
2025-05-19 22:09:27,057:INFO:         cloudpickle: 3.1.1
2025-05-19 22:09:27,057:INFO:         deprecation: 2.1.0
2025-05-19 22:09:27,057:INFO:              xxhash: 3.5.0
2025-05-19 22:09:27,057:INFO:           wurlitzer: Not installed
2025-05-19 22:09:27,057:INFO:PyCaret optional dependencies:
2025-05-19 22:09:27,057:INFO:                shap: Not installed
2025-05-19 22:09:27,057:INFO:           interpret: Not installed
2025-05-19 22:09:27,057:INFO:                umap: Not installed
2025-05-19 22:09:27,057:INFO:     ydata_profiling: Not installed
2025-05-19 22:09:27,058:INFO:  explainerdashboard: Not installed
2025-05-19 22:09:27,058:INFO:             autoviz: Not installed
2025-05-19 22:09:27,058:INFO:           fairlearn: Not installed
2025-05-19 22:09:27,058:INFO:          deepchecks: Not installed
2025-05-19 22:09:27,058:INFO:             xgboost: Not installed
2025-05-19 22:09:27,058:INFO:            catboost: Not installed
2025-05-19 22:09:27,058:INFO:              kmodes: Not installed
2025-05-19 22:09:27,058:INFO:             mlxtend: Not installed
2025-05-19 22:09:27,058:INFO:       statsforecast: Not installed
2025-05-19 22:09:27,058:INFO:        tune_sklearn: Not installed
2025-05-19 22:09:27,058:INFO:                 ray: Not installed
2025-05-19 22:09:27,058:INFO:            hyperopt: Not installed
2025-05-19 22:09:27,058:INFO:              optuna: Not installed
2025-05-19 22:09:27,058:INFO:               skopt: Not installed
2025-05-19 22:09:27,058:INFO:              mlflow: Not installed
2025-05-19 22:09:27,058:INFO:              gradio: Not installed
2025-05-19 22:09:27,058:INFO:             fastapi: Not installed
2025-05-19 22:09:27,058:INFO:             uvicorn: Not installed
2025-05-19 22:09:27,059:INFO:              m2cgen: Not installed
2025-05-19 22:09:27,059:INFO:           evidently: Not installed
2025-05-19 22:09:27,059:INFO:               fugue: Not installed
2025-05-19 22:09:27,059:INFO:           streamlit: Not installed
2025-05-19 22:09:27,059:INFO:             prophet: Not installed
2025-05-19 22:09:27,059:INFO:None
2025-05-19 22:09:27,059:INFO:Set up data.
2025-05-19 22:09:27,073:INFO:Set up folding strategy.
2025-05-19 22:09:27,074:INFO:Set up train/test split.
2025-05-19 22:09:27,084:INFO:Set up index.
2025-05-19 22:09:27,085:INFO:Assigning column types.
2025-05-19 22:09:27,088:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 22:09:27,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,136:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,275:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 22:09:27,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,406:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:09:27,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,436:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 22:09:27,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,621:INFO:Preparing preprocessing pipeline...
2025-05-19 22:09:27,622:INFO:Set up simple imputation.
2025-05-19 22:09:27,627:INFO:Set up encoding of categorical features.
2025-05-19 22:09:27,627:INFO:Set up removing multicollinearity.
2025-05-19 22:09:27,627:INFO:Set up column transformation.
2025-05-19 22:09:27,627:INFO:Set up feature normalization.
2025-05-19 22:09:27,627:INFO:Set up feature selection.
2025-05-19 22:09:27,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:27,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:09:28,234:INFO:Finished creating preprocessing pipeline.
2025-05-19 22:09:28,259:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'numero_productos',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal',
                                             'indice_digital'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 22:09:28,259:INFO:Creating final display dataframe.
2025-05-19 22:10:26,584:INFO:PyCaret ClassificationExperiment
2025-05-19 22:10:26,585:INFO:Logging name: clf-default-name
2025-05-19 22:10:26,585:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 22:10:26,585:INFO:version 3.3.2
2025-05-19 22:10:26,585:INFO:Initializing setup()
2025-05-19 22:10:26,585:INFO:self.USI: 279d
2025-05-19 22:10:26,585:INFO:self._variable_keys: {'exp_id', 'is_multiclass', 'target_param', 'seed', 'logging_param', 'X', 'fix_imbalance', 'USI', 'y', 'n_jobs_param', 'html_param', 'y_test', 'pipeline', '_ml_usecase', 'memory', 'exp_name_log', 'X_test', 'gpu_n_jobs_param', 'data', 'fold_generator', 'idx', 'y_train', 'X_train', '_available_plots', 'gpu_param', 'log_plots_param', 'fold_shuffle_param', 'fold_groups_param'}
2025-05-19 22:10:26,585:INFO:Checking environment
2025-05-19 22:10:26,585:INFO:python_version: 3.11.0
2025-05-19 22:10:26,585:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-19 22:10:26,585:INFO:machine: AMD64
2025-05-19 22:10:26,586:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-19 22:10:26,591:INFO:Memory: svmem(total=12759322624, available=1619570688, percent=87.3, used=11139751936, free=1619570688)
2025-05-19 22:10:26,591:INFO:Physical Core: 4
2025-05-19 22:10:26,591:INFO:Logical Core: 8
2025-05-19 22:10:26,591:INFO:Checking libraries
2025-05-19 22:10:26,592:INFO:System:
2025-05-19 22:10:26,592:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-19 22:10:26,592:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-19 22:10:26,592:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-19 22:10:26,592:INFO:PyCaret required dependencies:
2025-05-19 22:10:26,592:INFO:                 pip: 22.3
2025-05-19 22:10:26,592:INFO:          setuptools: 65.5.0
2025-05-19 22:10:26,592:INFO:             pycaret: 3.3.2
2025-05-19 22:10:26,592:INFO:             IPython: 9.2.0
2025-05-19 22:10:26,592:INFO:          ipywidgets: 8.1.7
2025-05-19 22:10:26,592:INFO:                tqdm: 4.67.1
2025-05-19 22:10:26,592:INFO:               numpy: 1.26.4
2025-05-19 22:10:26,592:INFO:              pandas: 2.1.4
2025-05-19 22:10:26,592:INFO:              jinja2: 3.1.6
2025-05-19 22:10:26,592:INFO:               scipy: 1.11.4
2025-05-19 22:10:26,592:INFO:              joblib: 1.3.2
2025-05-19 22:10:26,592:INFO:             sklearn: 1.4.2
2025-05-19 22:10:26,593:INFO:                pyod: 2.0.5
2025-05-19 22:10:26,593:INFO:            imblearn: 0.13.0
2025-05-19 22:10:26,593:INFO:   category_encoders: 2.7.0
2025-05-19 22:10:26,593:INFO:            lightgbm: 4.6.0
2025-05-19 22:10:26,593:INFO:               numba: 0.61.2
2025-05-19 22:10:26,593:INFO:            requests: 2.32.3
2025-05-19 22:10:26,593:INFO:          matplotlib: 3.7.5
2025-05-19 22:10:26,593:INFO:          scikitplot: 0.3.7
2025-05-19 22:10:26,593:INFO:         yellowbrick: 1.5
2025-05-19 22:10:26,593:INFO:              plotly: 5.24.1
2025-05-19 22:10:26,593:INFO:    plotly-resampler: Not installed
2025-05-19 22:10:26,593:INFO:             kaleido: 0.2.1
2025-05-19 22:10:26,593:INFO:           schemdraw: 0.15
2025-05-19 22:10:26,593:INFO:         statsmodels: 0.14.4
2025-05-19 22:10:26,593:INFO:              sktime: 0.26.0
2025-05-19 22:10:26,593:INFO:               tbats: 1.1.3
2025-05-19 22:10:26,593:INFO:            pmdarima: 2.0.4
2025-05-19 22:10:26,593:INFO:              psutil: 7.0.0
2025-05-19 22:10:26,593:INFO:          markupsafe: 3.0.2
2025-05-19 22:10:26,593:INFO:             pickle5: Not installed
2025-05-19 22:10:26,593:INFO:         cloudpickle: 3.1.1
2025-05-19 22:10:26,593:INFO:         deprecation: 2.1.0
2025-05-19 22:10:26,593:INFO:              xxhash: 3.5.0
2025-05-19 22:10:26,593:INFO:           wurlitzer: Not installed
2025-05-19 22:10:26,594:INFO:PyCaret optional dependencies:
2025-05-19 22:10:26,594:INFO:                shap: Not installed
2025-05-19 22:10:26,594:INFO:           interpret: Not installed
2025-05-19 22:10:26,594:INFO:                umap: Not installed
2025-05-19 22:10:26,594:INFO:     ydata_profiling: Not installed
2025-05-19 22:10:26,594:INFO:  explainerdashboard: Not installed
2025-05-19 22:10:26,594:INFO:             autoviz: Not installed
2025-05-19 22:10:26,594:INFO:           fairlearn: Not installed
2025-05-19 22:10:26,594:INFO:          deepchecks: Not installed
2025-05-19 22:10:26,594:INFO:             xgboost: Not installed
2025-05-19 22:10:26,594:INFO:            catboost: Not installed
2025-05-19 22:10:26,594:INFO:              kmodes: Not installed
2025-05-19 22:10:26,594:INFO:             mlxtend: Not installed
2025-05-19 22:10:26,594:INFO:       statsforecast: Not installed
2025-05-19 22:10:26,594:INFO:        tune_sklearn: Not installed
2025-05-19 22:10:26,594:INFO:                 ray: Not installed
2025-05-19 22:10:26,594:INFO:            hyperopt: Not installed
2025-05-19 22:10:26,594:INFO:              optuna: Not installed
2025-05-19 22:10:26,594:INFO:               skopt: Not installed
2025-05-19 22:10:26,594:INFO:              mlflow: Not installed
2025-05-19 22:10:26,594:INFO:              gradio: Not installed
2025-05-19 22:10:26,594:INFO:             fastapi: Not installed
2025-05-19 22:10:26,594:INFO:             uvicorn: Not installed
2025-05-19 22:10:26,595:INFO:              m2cgen: Not installed
2025-05-19 22:10:26,595:INFO:           evidently: Not installed
2025-05-19 22:10:26,595:INFO:               fugue: Not installed
2025-05-19 22:10:26,595:INFO:           streamlit: Not installed
2025-05-19 22:10:26,595:INFO:             prophet: Not installed
2025-05-19 22:10:26,595:INFO:None
2025-05-19 22:10:26,595:INFO:Set up data.
2025-05-19 22:10:26,608:INFO:Set up folding strategy.
2025-05-19 22:10:26,608:INFO:Set up train/test split.
2025-05-19 22:10:26,619:INFO:Set up index.
2025-05-19 22:10:26,619:INFO:Assigning column types.
2025-05-19 22:10:26,624:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 22:10:26,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:10:26,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:10:26,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:26,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:26,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 22:10:26,799:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:10:26,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:26,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:26,848:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 22:10:26,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:10:26,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:26,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 22:10:27,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 22:10:27,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,420:INFO:Preparing preprocessing pipeline...
2025-05-19 22:10:27,421:INFO:Set up simple imputation.
2025-05-19 22:10:27,426:INFO:Set up encoding of categorical features.
2025-05-19 22:10:27,426:INFO:Set up removing multicollinearity.
2025-05-19 22:10:27,426:INFO:Set up column transformation.
2025-05-19 22:10:27,427:INFO:Set up feature normalization.
2025-05-19 22:10:27,427:INFO:Set up feature selection.
2025-05-19 22:10:27,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:27,998:INFO:Finished creating preprocessing pipeline.
2025-05-19 22:10:28,028:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'numero_productos',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal',
                                             'indice_digital'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 22:10:28,028:INFO:Creating final display dataframe.
2025-05-19 22:10:28,645:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target    cerrara_cuenta
2                   Target type            Binary
3           Original data shape        (5000, 18)
4        Transformed data shape         (5000, 3)
5   Transformed train set shape         (3500, 3)
6    Transformed test set shape         (1500, 3)
7               Ignore features                 4
8              Numeric features                 6
9          Categorical features                 6
10     Rows with missing values              1.7%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Transformation              True
20        Transformation method       yeo-johnson
21                    Normalize              True
22             Normalize method            zscore
23            Feature selection              True
24     Feature selection method           classic
25  Feature selection estimator          lightgbm
26  Number of features selected               0.2
27               Fold Generator   StratifiedKFold
28                  Fold Number                10
29                     CPU Jobs                -1
30                      Use GPU             False
31               Log Experiment             False
32              Experiment Name  clf-default-name
33                          USI              279d
2025-05-19 22:10:28,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:28,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:28,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:28,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 22:10:28,871:INFO:setup() successfully completed in 2.29s...............
2025-05-19 22:11:22,031:INFO:Initializing compare_models()
2025-05-19 22:11:22,032:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:11:22,032:INFO:Checking exceptions
2025-05-19 22:11:22,039:INFO:Preparing display monitor
2025-05-19 22:11:22,077:INFO:Initializing Logistic Regression
2025-05-19 22:11:22,078:INFO:Total runtime is 1.6589959462483723e-05 minutes
2025-05-19 22:11:22,085:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:22,085:INFO:Initializing create_model()
2025-05-19 22:11:22,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:22,086:INFO:Checking exceptions
2025-05-19 22:11:22,086:INFO:Importing libraries
2025-05-19 22:11:22,086:INFO:Copying training dataset
2025-05-19 22:11:22,097:INFO:Defining folds
2025-05-19 22:11:22,097:INFO:Declaring metric variables
2025-05-19 22:11:22,105:INFO:Importing untrained model
2025-05-19 22:11:22,110:INFO:Logistic Regression Imported successfully
2025-05-19 22:11:22,122:INFO:Starting cross validation
2025-05-19 22:11:22,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:35,231:INFO:Calculating mean and std
2025-05-19 22:11:35,233:INFO:Creating metrics dataframe
2025-05-19 22:11:35,237:INFO:Uploading results into container
2025-05-19 22:11:35,238:INFO:Uploading model into container now
2025-05-19 22:11:35,239:INFO:_master_model_container: 1
2025-05-19 22:11:35,239:INFO:_display_container: 2
2025-05-19 22:11:35,240:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:11:35,240:INFO:create_model() successfully completed......................................
2025-05-19 22:11:35,397:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:35,397:INFO:Creating metrics dataframe
2025-05-19 22:11:35,406:INFO:Initializing K Neighbors Classifier
2025-05-19 22:11:35,406:INFO:Total runtime is 0.22213818629582724 minutes
2025-05-19 22:11:35,410:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:35,411:INFO:Initializing create_model()
2025-05-19 22:11:35,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:35,411:INFO:Checking exceptions
2025-05-19 22:11:35,411:INFO:Importing libraries
2025-05-19 22:11:35,411:INFO:Copying training dataset
2025-05-19 22:11:35,420:INFO:Defining folds
2025-05-19 22:11:35,420:INFO:Declaring metric variables
2025-05-19 22:11:35,424:INFO:Importing untrained model
2025-05-19 22:11:35,431:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:11:35,439:INFO:Starting cross validation
2025-05-19 22:11:35,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:37,929:INFO:Calculating mean and std
2025-05-19 22:11:37,933:INFO:Creating metrics dataframe
2025-05-19 22:11:37,938:INFO:Uploading results into container
2025-05-19 22:11:37,939:INFO:Uploading model into container now
2025-05-19 22:11:37,940:INFO:_master_model_container: 2
2025-05-19 22:11:37,940:INFO:_display_container: 2
2025-05-19 22:11:37,940:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:11:37,941:INFO:create_model() successfully completed......................................
2025-05-19 22:11:38,077:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:38,077:INFO:Creating metrics dataframe
2025-05-19 22:11:38,090:INFO:Initializing Naive Bayes
2025-05-19 22:11:38,090:INFO:Total runtime is 0.2668799042701721 minutes
2025-05-19 22:11:38,098:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:38,099:INFO:Initializing create_model()
2025-05-19 22:11:38,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:38,099:INFO:Checking exceptions
2025-05-19 22:11:38,099:INFO:Importing libraries
2025-05-19 22:11:38,099:INFO:Copying training dataset
2025-05-19 22:11:38,116:INFO:Defining folds
2025-05-19 22:11:38,117:INFO:Declaring metric variables
2025-05-19 22:11:38,123:INFO:Importing untrained model
2025-05-19 22:11:38,131:INFO:Naive Bayes Imported successfully
2025-05-19 22:11:38,144:INFO:Starting cross validation
2025-05-19 22:11:38,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:41,141:INFO:Calculating mean and std
2025-05-19 22:11:41,144:INFO:Creating metrics dataframe
2025-05-19 22:11:41,149:INFO:Uploading results into container
2025-05-19 22:11:41,151:INFO:Uploading model into container now
2025-05-19 22:11:41,152:INFO:_master_model_container: 3
2025-05-19 22:11:41,152:INFO:_display_container: 2
2025-05-19 22:11:41,153:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:11:41,153:INFO:create_model() successfully completed......................................
2025-05-19 22:11:41,297:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:41,297:INFO:Creating metrics dataframe
2025-05-19 22:11:41,306:INFO:Initializing Decision Tree Classifier
2025-05-19 22:11:41,307:INFO:Total runtime is 0.32049731016159055 minutes
2025-05-19 22:11:41,313:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:41,314:INFO:Initializing create_model()
2025-05-19 22:11:41,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:41,314:INFO:Checking exceptions
2025-05-19 22:11:41,314:INFO:Importing libraries
2025-05-19 22:11:41,315:INFO:Copying training dataset
2025-05-19 22:11:41,324:INFO:Defining folds
2025-05-19 22:11:41,324:INFO:Declaring metric variables
2025-05-19 22:11:41,331:INFO:Importing untrained model
2025-05-19 22:11:41,340:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:11:41,351:INFO:Starting cross validation
2025-05-19 22:11:41,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:43,724:INFO:Calculating mean and std
2025-05-19 22:11:43,727:INFO:Creating metrics dataframe
2025-05-19 22:11:43,729:INFO:Uploading results into container
2025-05-19 22:11:43,731:INFO:Uploading model into container now
2025-05-19 22:11:43,732:INFO:_master_model_container: 4
2025-05-19 22:11:43,733:INFO:_display_container: 2
2025-05-19 22:11:43,734:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:11:43,734:INFO:create_model() successfully completed......................................
2025-05-19 22:11:43,915:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:43,915:INFO:Creating metrics dataframe
2025-05-19 22:11:43,927:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:11:43,927:INFO:Total runtime is 0.36416095892588296 minutes
2025-05-19 22:11:43,935:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:43,935:INFO:Initializing create_model()
2025-05-19 22:11:43,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:43,936:INFO:Checking exceptions
2025-05-19 22:11:43,936:INFO:Importing libraries
2025-05-19 22:11:43,936:INFO:Copying training dataset
2025-05-19 22:11:43,946:INFO:Defining folds
2025-05-19 22:11:43,946:INFO:Declaring metric variables
2025-05-19 22:11:43,951:INFO:Importing untrained model
2025-05-19 22:11:43,957:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:11:43,973:INFO:Starting cross validation
2025-05-19 22:11:43,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:46,278:INFO:Calculating mean and std
2025-05-19 22:11:46,281:INFO:Creating metrics dataframe
2025-05-19 22:11:46,286:INFO:Uploading results into container
2025-05-19 22:11:46,287:INFO:Uploading model into container now
2025-05-19 22:11:46,288:INFO:_master_model_container: 5
2025-05-19 22:11:46,288:INFO:_display_container: 2
2025-05-19 22:11:46,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:11:46,289:INFO:create_model() successfully completed......................................
2025-05-19 22:11:46,456:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:46,456:INFO:Creating metrics dataframe
2025-05-19 22:11:46,467:INFO:Initializing Ridge Classifier
2025-05-19 22:11:46,467:INFO:Total runtime is 0.40649207433064777 minutes
2025-05-19 22:11:46,472:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:46,472:INFO:Initializing create_model()
2025-05-19 22:11:46,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:46,473:INFO:Checking exceptions
2025-05-19 22:11:46,473:INFO:Importing libraries
2025-05-19 22:11:46,473:INFO:Copying training dataset
2025-05-19 22:11:46,483:INFO:Defining folds
2025-05-19 22:11:46,483:INFO:Declaring metric variables
2025-05-19 22:11:46,491:INFO:Importing untrained model
2025-05-19 22:11:46,499:INFO:Ridge Classifier Imported successfully
2025-05-19 22:11:46,512:INFO:Starting cross validation
2025-05-19 22:11:46,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:49,765:INFO:Calculating mean and std
2025-05-19 22:11:49,768:INFO:Creating metrics dataframe
2025-05-19 22:11:49,772:INFO:Uploading results into container
2025-05-19 22:11:49,773:INFO:Uploading model into container now
2025-05-19 22:11:49,776:INFO:_master_model_container: 6
2025-05-19 22:11:49,776:INFO:_display_container: 2
2025-05-19 22:11:49,778:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:11:49,778:INFO:create_model() successfully completed......................................
2025-05-19 22:11:49,990:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:49,990:INFO:Creating metrics dataframe
2025-05-19 22:11:50,015:INFO:Initializing Random Forest Classifier
2025-05-19 22:11:50,015:INFO:Total runtime is 0.46563430229822794 minutes
2025-05-19 22:11:50,025:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:50,026:INFO:Initializing create_model()
2025-05-19 22:11:50,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:50,026:INFO:Checking exceptions
2025-05-19 22:11:50,026:INFO:Importing libraries
2025-05-19 22:11:50,027:INFO:Copying training dataset
2025-05-19 22:11:50,048:INFO:Defining folds
2025-05-19 22:11:50,048:INFO:Declaring metric variables
2025-05-19 22:11:50,058:INFO:Importing untrained model
2025-05-19 22:11:50,074:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:11:50,093:INFO:Starting cross validation
2025-05-19 22:11:50,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:53,424:INFO:Calculating mean and std
2025-05-19 22:11:53,427:INFO:Creating metrics dataframe
2025-05-19 22:11:53,436:INFO:Uploading results into container
2025-05-19 22:11:53,437:INFO:Uploading model into container now
2025-05-19 22:11:53,437:INFO:_master_model_container: 7
2025-05-19 22:11:53,438:INFO:_display_container: 2
2025-05-19 22:11:53,439:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 22:11:53,439:INFO:create_model() successfully completed......................................
2025-05-19 22:11:53,658:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:53,658:INFO:Creating metrics dataframe
2025-05-19 22:11:53,690:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 22:11:53,690:INFO:Total runtime is 0.5268752574920654 minutes
2025-05-19 22:11:53,704:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:53,704:INFO:Initializing create_model()
2025-05-19 22:11:53,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:53,705:INFO:Checking exceptions
2025-05-19 22:11:53,705:INFO:Importing libraries
2025-05-19 22:11:53,705:INFO:Copying training dataset
2025-05-19 22:11:53,723:INFO:Defining folds
2025-05-19 22:11:53,723:INFO:Declaring metric variables
2025-05-19 22:11:53,736:INFO:Importing untrained model
2025-05-19 22:11:53,746:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 22:11:53,766:INFO:Starting cross validation
2025-05-19 22:11:53,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:55,159:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,159:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,159:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,159:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,186:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,186:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,187:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,190:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,886:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:55,969:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:11:56,093:INFO:Calculating mean and std
2025-05-19 22:11:56,095:INFO:Creating metrics dataframe
2025-05-19 22:11:56,100:INFO:Uploading results into container
2025-05-19 22:11:56,102:INFO:Uploading model into container now
2025-05-19 22:11:56,102:INFO:_master_model_container: 8
2025-05-19 22:11:56,102:INFO:_display_container: 2
2025-05-19 22:11:56,102:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 22:11:56,102:INFO:create_model() successfully completed......................................
2025-05-19 22:11:56,241:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:56,242:INFO:Creating metrics dataframe
2025-05-19 22:11:56,253:INFO:Initializing Ada Boost Classifier
2025-05-19 22:11:56,253:INFO:Total runtime is 0.5695934295654297 minutes
2025-05-19 22:11:56,258:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:56,258:INFO:Initializing create_model()
2025-05-19 22:11:56,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:56,259:INFO:Checking exceptions
2025-05-19 22:11:56,259:INFO:Importing libraries
2025-05-19 22:11:56,259:INFO:Copying training dataset
2025-05-19 22:11:56,268:INFO:Defining folds
2025-05-19 22:11:56,268:INFO:Declaring metric variables
2025-05-19 22:11:56,274:INFO:Importing untrained model
2025-05-19 22:11:56,280:INFO:Ada Boost Classifier Imported successfully
2025-05-19 22:11:56,289:INFO:Starting cross validation
2025-05-19 22:11:56,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:11:57,311:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,332:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,424:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,532:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,721:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,888:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:57,981:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:58,353:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:58,857:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:58,867:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:11:59,021:INFO:Calculating mean and std
2025-05-19 22:11:59,023:INFO:Creating metrics dataframe
2025-05-19 22:11:59,028:INFO:Uploading results into container
2025-05-19 22:11:59,029:INFO:Uploading model into container now
2025-05-19 22:11:59,030:INFO:_master_model_container: 9
2025-05-19 22:11:59,030:INFO:_display_container: 2
2025-05-19 22:11:59,031:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 22:11:59,031:INFO:create_model() successfully completed......................................
2025-05-19 22:11:59,219:INFO:SubProcess create_model() end ==================================
2025-05-19 22:11:59,219:INFO:Creating metrics dataframe
2025-05-19 22:11:59,262:INFO:Initializing Gradient Boosting Classifier
2025-05-19 22:11:59,262:INFO:Total runtime is 0.6197472055753072 minutes
2025-05-19 22:11:59,276:INFO:SubProcess create_model() called ==================================
2025-05-19 22:11:59,277:INFO:Initializing create_model()
2025-05-19 22:11:59,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:11:59,277:INFO:Checking exceptions
2025-05-19 22:11:59,278:INFO:Importing libraries
2025-05-19 22:11:59,278:INFO:Copying training dataset
2025-05-19 22:11:59,315:INFO:Defining folds
2025-05-19 22:11:59,317:INFO:Declaring metric variables
2025-05-19 22:11:59,337:INFO:Importing untrained model
2025-05-19 22:11:59,352:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 22:11:59,376:INFO:Starting cross validation
2025-05-19 22:11:59,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:02,351:INFO:Calculating mean and std
2025-05-19 22:12:02,354:INFO:Creating metrics dataframe
2025-05-19 22:12:02,361:INFO:Uploading results into container
2025-05-19 22:12:02,364:INFO:Uploading model into container now
2025-05-19 22:12:02,367:INFO:_master_model_container: 10
2025-05-19 22:12:02,367:INFO:_display_container: 2
2025-05-19 22:12:02,369:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 22:12:02,369:INFO:create_model() successfully completed......................................
2025-05-19 22:12:02,576:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:02,576:INFO:Creating metrics dataframe
2025-05-19 22:12:02,597:INFO:Initializing Linear Discriminant Analysis
2025-05-19 22:12:02,598:INFO:Total runtime is 0.6753472526868184 minutes
2025-05-19 22:12:02,604:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:02,605:INFO:Initializing create_model()
2025-05-19 22:12:02,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:02,605:INFO:Checking exceptions
2025-05-19 22:12:02,605:INFO:Importing libraries
2025-05-19 22:12:02,605:INFO:Copying training dataset
2025-05-19 22:12:02,619:INFO:Defining folds
2025-05-19 22:12:02,619:INFO:Declaring metric variables
2025-05-19 22:12:02,627:INFO:Importing untrained model
2025-05-19 22:12:02,641:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 22:12:02,664:INFO:Starting cross validation
2025-05-19 22:12:02,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:05,763:INFO:Calculating mean and std
2025-05-19 22:12:05,765:INFO:Creating metrics dataframe
2025-05-19 22:12:05,768:INFO:Uploading results into container
2025-05-19 22:12:05,769:INFO:Uploading model into container now
2025-05-19 22:12:05,770:INFO:_master_model_container: 11
2025-05-19 22:12:05,771:INFO:_display_container: 2
2025-05-19 22:12:05,772:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 22:12:05,772:INFO:create_model() successfully completed......................................
2025-05-19 22:12:05,913:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:05,913:INFO:Creating metrics dataframe
2025-05-19 22:12:05,925:INFO:Initializing Extra Trees Classifier
2025-05-19 22:12:05,925:INFO:Total runtime is 0.7307952086130778 minutes
2025-05-19 22:12:05,930:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:05,931:INFO:Initializing create_model()
2025-05-19 22:12:05,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:05,931:INFO:Checking exceptions
2025-05-19 22:12:05,931:INFO:Importing libraries
2025-05-19 22:12:05,931:INFO:Copying training dataset
2025-05-19 22:12:05,940:INFO:Defining folds
2025-05-19 22:12:05,940:INFO:Declaring metric variables
2025-05-19 22:12:05,945:INFO:Importing untrained model
2025-05-19 22:12:05,952:INFO:Extra Trees Classifier Imported successfully
2025-05-19 22:12:05,961:INFO:Starting cross validation
2025-05-19 22:12:05,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:08,813:INFO:Calculating mean and std
2025-05-19 22:12:08,815:INFO:Creating metrics dataframe
2025-05-19 22:12:08,818:INFO:Uploading results into container
2025-05-19 22:12:08,819:INFO:Uploading model into container now
2025-05-19 22:12:08,820:INFO:_master_model_container: 12
2025-05-19 22:12:08,820:INFO:_display_container: 2
2025-05-19 22:12:08,820:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 22:12:08,820:INFO:create_model() successfully completed......................................
2025-05-19 22:12:08,943:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:08,943:INFO:Creating metrics dataframe
2025-05-19 22:12:08,962:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 22:12:08,963:INFO:Total runtime is 0.781429390112559 minutes
2025-05-19 22:12:08,970:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:08,971:INFO:Initializing create_model()
2025-05-19 22:12:08,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:08,971:INFO:Checking exceptions
2025-05-19 22:12:08,972:INFO:Importing libraries
2025-05-19 22:12:08,972:INFO:Copying training dataset
2025-05-19 22:12:08,982:INFO:Defining folds
2025-05-19 22:12:08,982:INFO:Declaring metric variables
2025-05-19 22:12:08,988:INFO:Importing untrained model
2025-05-19 22:12:08,994:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 22:12:09,006:INFO:Starting cross validation
2025-05-19 22:12:09,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:11,618:INFO:Calculating mean and std
2025-05-19 22:12:11,621:INFO:Creating metrics dataframe
2025-05-19 22:12:11,625:INFO:Uploading results into container
2025-05-19 22:12:11,626:INFO:Uploading model into container now
2025-05-19 22:12:11,626:INFO:_master_model_container: 13
2025-05-19 22:12:11,627:INFO:_display_container: 2
2025-05-19 22:12:11,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 22:12:11,629:INFO:create_model() successfully completed......................................
2025-05-19 22:12:11,779:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:11,779:INFO:Creating metrics dataframe
2025-05-19 22:12:11,795:INFO:Initializing Dummy Classifier
2025-05-19 22:12:11,795:INFO:Total runtime is 0.8286208152770995 minutes
2025-05-19 22:12:11,799:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:11,799:INFO:Initializing create_model()
2025-05-19 22:12:11,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DDAE7F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:11,800:INFO:Checking exceptions
2025-05-19 22:12:11,800:INFO:Importing libraries
2025-05-19 22:12:11,800:INFO:Copying training dataset
2025-05-19 22:12:11,808:INFO:Defining folds
2025-05-19 22:12:11,808:INFO:Declaring metric variables
2025-05-19 22:12:11,814:INFO:Importing untrained model
2025-05-19 22:12:11,817:INFO:Dummy Classifier Imported successfully
2025-05-19 22:12:11,826:INFO:Starting cross validation
2025-05-19 22:12:11,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:13,216:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,244:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,305:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,322:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,566:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,632:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,771:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:13,810:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:14,402:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:14,450:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:12:14,465:INFO:Calculating mean and std
2025-05-19 22:12:14,468:INFO:Creating metrics dataframe
2025-05-19 22:12:14,472:INFO:Uploading results into container
2025-05-19 22:12:14,473:INFO:Uploading model into container now
2025-05-19 22:12:14,475:INFO:_master_model_container: 14
2025-05-19 22:12:14,475:INFO:_display_container: 2
2025-05-19 22:12:14,476:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 22:12:14,476:INFO:create_model() successfully completed......................................
2025-05-19 22:12:14,644:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:14,644:INFO:Creating metrics dataframe
2025-05-19 22:12:14,668:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 22:12:14,684:INFO:Initializing create_model()
2025-05-19 22:12:14,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:14,684:INFO:Checking exceptions
2025-05-19 22:12:14,687:INFO:Importing libraries
2025-05-19 22:12:14,687:INFO:Copying training dataset
2025-05-19 22:12:14,699:INFO:Defining folds
2025-05-19 22:12:14,699:INFO:Declaring metric variables
2025-05-19 22:12:14,699:INFO:Importing untrained model
2025-05-19 22:12:14,699:INFO:Declaring custom model
2025-05-19 22:12:14,700:INFO:Logistic Regression Imported successfully
2025-05-19 22:12:14,713:INFO:Cross validation set to False
2025-05-19 22:12:14,714:INFO:Fitting Model
2025-05-19 22:12:15,149:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-19 22:12:15,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.
2025-05-19 22:12:15,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 22:12:15,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 22:12:15,152:INFO:[LightGBM] [Info] Total Bins 487
2025-05-19 22:12:15,152:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-19 22:12:15,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-19 22:12:15,153:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-19 22:12:15,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:12:15,225:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:12:15,226:INFO:create_model() successfully completed......................................
2025-05-19 22:12:15,406:INFO:_master_model_container: 14
2025-05-19 22:12:15,406:INFO:_display_container: 2
2025-05-19 22:12:15,406:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:12:15,406:INFO:compare_models() successfully completed......................................
2025-05-19 22:12:42,282:INFO:Initializing compare_models()
2025-05-19 22:12:42,282:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:12:42,282:INFO:Checking exceptions
2025-05-19 22:12:42,285:INFO:Preparing display monitor
2025-05-19 22:12:42,316:INFO:Initializing Logistic Regression
2025-05-19 22:12:42,316:INFO:Total runtime is 0.0 minutes
2025-05-19 22:12:42,322:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:42,323:INFO:Initializing create_model()
2025-05-19 22:12:42,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:42,323:INFO:Checking exceptions
2025-05-19 22:12:42,323:INFO:Importing libraries
2025-05-19 22:12:42,324:INFO:Copying training dataset
2025-05-19 22:12:42,330:INFO:Defining folds
2025-05-19 22:12:42,330:INFO:Declaring metric variables
2025-05-19 22:12:42,335:INFO:Importing untrained model
2025-05-19 22:12:42,341:INFO:Logistic Regression Imported successfully
2025-05-19 22:12:42,350:INFO:Starting cross validation
2025-05-19 22:12:42,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:44,410:INFO:Calculating mean and std
2025-05-19 22:12:44,413:INFO:Creating metrics dataframe
2025-05-19 22:12:44,416:INFO:Uploading results into container
2025-05-19 22:12:44,417:INFO:Uploading model into container now
2025-05-19 22:12:44,418:INFO:_master_model_container: 15
2025-05-19 22:12:44,419:INFO:_display_container: 3
2025-05-19 22:12:44,420:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:12:44,421:INFO:create_model() successfully completed......................................
2025-05-19 22:12:44,565:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:44,565:INFO:Creating metrics dataframe
2025-05-19 22:12:44,574:INFO:Initializing K Neighbors Classifier
2025-05-19 22:12:44,575:INFO:Total runtime is 0.03764219284057617 minutes
2025-05-19 22:12:44,579:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:44,579:INFO:Initializing create_model()
2025-05-19 22:12:44,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:44,579:INFO:Checking exceptions
2025-05-19 22:12:44,580:INFO:Importing libraries
2025-05-19 22:12:44,580:INFO:Copying training dataset
2025-05-19 22:12:44,589:INFO:Defining folds
2025-05-19 22:12:44,589:INFO:Declaring metric variables
2025-05-19 22:12:44,596:INFO:Importing untrained model
2025-05-19 22:12:44,601:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:12:44,611:INFO:Starting cross validation
2025-05-19 22:12:44,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:46,984:INFO:Calculating mean and std
2025-05-19 22:12:46,986:INFO:Creating metrics dataframe
2025-05-19 22:12:46,990:INFO:Uploading results into container
2025-05-19 22:12:46,990:INFO:Uploading model into container now
2025-05-19 22:12:46,991:INFO:_master_model_container: 16
2025-05-19 22:12:46,992:INFO:_display_container: 3
2025-05-19 22:12:46,992:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:12:46,993:INFO:create_model() successfully completed......................................
2025-05-19 22:12:47,128:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:47,128:INFO:Creating metrics dataframe
2025-05-19 22:12:47,137:INFO:Initializing Naive Bayes
2025-05-19 22:12:47,138:INFO:Total runtime is 0.08034789164861042 minutes
2025-05-19 22:12:47,142:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:47,142:INFO:Initializing create_model()
2025-05-19 22:12:47,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:47,143:INFO:Checking exceptions
2025-05-19 22:12:47,143:INFO:Importing libraries
2025-05-19 22:12:47,143:INFO:Copying training dataset
2025-05-19 22:12:47,151:INFO:Defining folds
2025-05-19 22:12:47,151:INFO:Declaring metric variables
2025-05-19 22:12:47,156:INFO:Importing untrained model
2025-05-19 22:12:47,164:INFO:Naive Bayes Imported successfully
2025-05-19 22:12:47,172:INFO:Starting cross validation
2025-05-19 22:12:47,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:49,264:INFO:Calculating mean and std
2025-05-19 22:12:49,266:INFO:Creating metrics dataframe
2025-05-19 22:12:49,271:INFO:Uploading results into container
2025-05-19 22:12:49,272:INFO:Uploading model into container now
2025-05-19 22:12:49,273:INFO:_master_model_container: 17
2025-05-19 22:12:49,274:INFO:_display_container: 3
2025-05-19 22:12:49,274:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:12:49,274:INFO:create_model() successfully completed......................................
2025-05-19 22:12:49,415:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:49,415:INFO:Creating metrics dataframe
2025-05-19 22:12:49,425:INFO:Initializing Decision Tree Classifier
2025-05-19 22:12:49,426:INFO:Total runtime is 0.11849196751912433 minutes
2025-05-19 22:12:49,430:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:49,430:INFO:Initializing create_model()
2025-05-19 22:12:49,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:49,431:INFO:Checking exceptions
2025-05-19 22:12:49,431:INFO:Importing libraries
2025-05-19 22:12:49,431:INFO:Copying training dataset
2025-05-19 22:12:49,440:INFO:Defining folds
2025-05-19 22:12:49,441:INFO:Declaring metric variables
2025-05-19 22:12:49,447:INFO:Importing untrained model
2025-05-19 22:12:49,452:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:12:49,464:INFO:Starting cross validation
2025-05-19 22:12:49,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:51,701:INFO:Calculating mean and std
2025-05-19 22:12:51,703:INFO:Creating metrics dataframe
2025-05-19 22:12:51,706:INFO:Uploading results into container
2025-05-19 22:12:51,708:INFO:Uploading model into container now
2025-05-19 22:12:51,708:INFO:_master_model_container: 18
2025-05-19 22:12:51,708:INFO:_display_container: 3
2025-05-19 22:12:51,709:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:12:51,709:INFO:create_model() successfully completed......................................
2025-05-19 22:12:51,845:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:51,846:INFO:Creating metrics dataframe
2025-05-19 22:12:51,861:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:12:51,861:INFO:Total runtime is 0.15908187230428059 minutes
2025-05-19 22:12:51,866:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:51,866:INFO:Initializing create_model()
2025-05-19 22:12:51,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:51,866:INFO:Checking exceptions
2025-05-19 22:12:51,867:INFO:Importing libraries
2025-05-19 22:12:51,867:INFO:Copying training dataset
2025-05-19 22:12:51,878:INFO:Defining folds
2025-05-19 22:12:51,879:INFO:Declaring metric variables
2025-05-19 22:12:51,884:INFO:Importing untrained model
2025-05-19 22:12:51,893:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:12:51,940:INFO:Starting cross validation
2025-05-19 22:12:51,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:54,092:INFO:Calculating mean and std
2025-05-19 22:12:54,094:INFO:Creating metrics dataframe
2025-05-19 22:12:54,097:INFO:Uploading results into container
2025-05-19 22:12:54,098:INFO:Uploading model into container now
2025-05-19 22:12:54,099:INFO:_master_model_container: 19
2025-05-19 22:12:54,099:INFO:_display_container: 3
2025-05-19 22:12:54,099:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:12:54,099:INFO:create_model() successfully completed......................................
2025-05-19 22:12:54,248:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:54,249:INFO:Creating metrics dataframe
2025-05-19 22:12:54,261:INFO:Initializing Ridge Classifier
2025-05-19 22:12:54,261:INFO:Total runtime is 0.1990748842557271 minutes
2025-05-19 22:12:54,266:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:54,266:INFO:Initializing create_model()
2025-05-19 22:12:54,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:54,267:INFO:Checking exceptions
2025-05-19 22:12:54,267:INFO:Importing libraries
2025-05-19 22:12:54,267:INFO:Copying training dataset
2025-05-19 22:12:54,277:INFO:Defining folds
2025-05-19 22:12:54,277:INFO:Declaring metric variables
2025-05-19 22:12:54,283:INFO:Importing untrained model
2025-05-19 22:12:54,290:INFO:Ridge Classifier Imported successfully
2025-05-19 22:12:54,303:INFO:Starting cross validation
2025-05-19 22:12:54,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:12:56,967:INFO:Calculating mean and std
2025-05-19 22:12:56,969:INFO:Creating metrics dataframe
2025-05-19 22:12:56,974:INFO:Uploading results into container
2025-05-19 22:12:56,975:INFO:Uploading model into container now
2025-05-19 22:12:56,976:INFO:_master_model_container: 20
2025-05-19 22:12:56,977:INFO:_display_container: 3
2025-05-19 22:12:56,977:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:12:56,978:INFO:create_model() successfully completed......................................
2025-05-19 22:12:57,134:INFO:SubProcess create_model() end ==================================
2025-05-19 22:12:57,134:INFO:Creating metrics dataframe
2025-05-19 22:12:57,147:INFO:Initializing Random Forest Classifier
2025-05-19 22:12:57,147:INFO:Total runtime is 0.24718323151270546 minutes
2025-05-19 22:12:57,152:INFO:SubProcess create_model() called ==================================
2025-05-19 22:12:57,153:INFO:Initializing create_model()
2025-05-19 22:12:57,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:12:57,153:INFO:Checking exceptions
2025-05-19 22:12:57,154:INFO:Importing libraries
2025-05-19 22:12:57,154:INFO:Copying training dataset
2025-05-19 22:12:57,165:INFO:Defining folds
2025-05-19 22:12:57,165:INFO:Declaring metric variables
2025-05-19 22:12:57,172:INFO:Importing untrained model
2025-05-19 22:12:57,180:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:12:57,193:INFO:Starting cross validation
2025-05-19 22:12:57,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:01,105:INFO:Calculating mean and std
2025-05-19 22:13:01,108:INFO:Creating metrics dataframe
2025-05-19 22:13:01,114:INFO:Uploading results into container
2025-05-19 22:13:01,115:INFO:Uploading model into container now
2025-05-19 22:13:01,116:INFO:_master_model_container: 21
2025-05-19 22:13:01,116:INFO:_display_container: 3
2025-05-19 22:13:01,117:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 22:13:01,118:INFO:create_model() successfully completed......................................
2025-05-19 22:13:01,391:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:01,392:INFO:Creating metrics dataframe
2025-05-19 22:13:01,407:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 22:13:01,407:INFO:Total runtime is 0.3181850035985311 minutes
2025-05-19 22:13:01,413:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:01,413:INFO:Initializing create_model()
2025-05-19 22:13:01,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:01,413:INFO:Checking exceptions
2025-05-19 22:13:01,414:INFO:Importing libraries
2025-05-19 22:13:01,414:INFO:Copying training dataset
2025-05-19 22:13:01,428:INFO:Defining folds
2025-05-19 22:13:01,428:INFO:Declaring metric variables
2025-05-19 22:13:01,434:INFO:Importing untrained model
2025-05-19 22:13:01,442:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 22:13:01,458:INFO:Starting cross validation
2025-05-19 22:13:01,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:03,240:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:03,251:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:03,322:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:03,687:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:03,784:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,047:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,075:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,166:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,718:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,718:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:13:04,862:INFO:Calculating mean and std
2025-05-19 22:13:04,865:INFO:Creating metrics dataframe
2025-05-19 22:13:04,870:INFO:Uploading results into container
2025-05-19 22:13:04,872:INFO:Uploading model into container now
2025-05-19 22:13:04,873:INFO:_master_model_container: 22
2025-05-19 22:13:04,873:INFO:_display_container: 3
2025-05-19 22:13:04,874:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 22:13:04,874:INFO:create_model() successfully completed......................................
2025-05-19 22:13:05,023:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:05,024:INFO:Creating metrics dataframe
2025-05-19 22:13:05,041:INFO:Initializing Ada Boost Classifier
2025-05-19 22:13:05,041:INFO:Total runtime is 0.37874627113342285 minutes
2025-05-19 22:13:05,046:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:05,046:INFO:Initializing create_model()
2025-05-19 22:13:05,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:05,046:INFO:Checking exceptions
2025-05-19 22:13:05,047:INFO:Importing libraries
2025-05-19 22:13:05,047:INFO:Copying training dataset
2025-05-19 22:13:05,056:INFO:Defining folds
2025-05-19 22:13:05,057:INFO:Declaring metric variables
2025-05-19 22:13:05,064:INFO:Importing untrained model
2025-05-19 22:13:05,071:INFO:Ada Boost Classifier Imported successfully
2025-05-19 22:13:05,083:INFO:Starting cross validation
2025-05-19 22:13:05,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:06,542:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,549:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,578:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,580:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,614:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,786:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,816:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:06,816:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:07,410:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:07,431:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:13:07,548:INFO:Calculating mean and std
2025-05-19 22:13:07,550:INFO:Creating metrics dataframe
2025-05-19 22:13:07,553:INFO:Uploading results into container
2025-05-19 22:13:07,554:INFO:Uploading model into container now
2025-05-19 22:13:07,555:INFO:_master_model_container: 23
2025-05-19 22:13:07,555:INFO:_display_container: 3
2025-05-19 22:13:07,556:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 22:13:07,556:INFO:create_model() successfully completed......................................
2025-05-19 22:13:07,704:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:07,705:INFO:Creating metrics dataframe
2025-05-19 22:13:07,724:INFO:Initializing Gradient Boosting Classifier
2025-05-19 22:13:07,724:INFO:Total runtime is 0.4234585165977478 minutes
2025-05-19 22:13:07,729:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:07,730:INFO:Initializing create_model()
2025-05-19 22:13:07,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:07,730:INFO:Checking exceptions
2025-05-19 22:13:07,730:INFO:Importing libraries
2025-05-19 22:13:07,730:INFO:Copying training dataset
2025-05-19 22:13:07,744:INFO:Defining folds
2025-05-19 22:13:07,744:INFO:Declaring metric variables
2025-05-19 22:13:07,752:INFO:Importing untrained model
2025-05-19 22:13:07,758:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 22:13:07,768:INFO:Starting cross validation
2025-05-19 22:13:07,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:10,545:INFO:Calculating mean and std
2025-05-19 22:13:10,546:INFO:Creating metrics dataframe
2025-05-19 22:13:10,549:INFO:Uploading results into container
2025-05-19 22:13:10,550:INFO:Uploading model into container now
2025-05-19 22:13:10,551:INFO:_master_model_container: 24
2025-05-19 22:13:10,552:INFO:_display_container: 3
2025-05-19 22:13:10,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 22:13:10,554:INFO:create_model() successfully completed......................................
2025-05-19 22:13:10,716:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:10,716:INFO:Creating metrics dataframe
2025-05-19 22:13:10,741:INFO:Initializing Linear Discriminant Analysis
2025-05-19 22:13:10,741:INFO:Total runtime is 0.47373586893081665 minutes
2025-05-19 22:13:10,745:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:10,746:INFO:Initializing create_model()
2025-05-19 22:13:10,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:10,746:INFO:Checking exceptions
2025-05-19 22:13:10,746:INFO:Importing libraries
2025-05-19 22:13:10,746:INFO:Copying training dataset
2025-05-19 22:13:10,756:INFO:Defining folds
2025-05-19 22:13:10,756:INFO:Declaring metric variables
2025-05-19 22:13:10,760:INFO:Importing untrained model
2025-05-19 22:13:10,768:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 22:13:10,779:INFO:Starting cross validation
2025-05-19 22:13:10,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:12,767:INFO:Calculating mean and std
2025-05-19 22:13:12,770:INFO:Creating metrics dataframe
2025-05-19 22:13:12,773:INFO:Uploading results into container
2025-05-19 22:13:12,774:INFO:Uploading model into container now
2025-05-19 22:13:12,775:INFO:_master_model_container: 25
2025-05-19 22:13:12,775:INFO:_display_container: 3
2025-05-19 22:13:12,776:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 22:13:12,776:INFO:create_model() successfully completed......................................
2025-05-19 22:13:12,924:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:12,924:INFO:Creating metrics dataframe
2025-05-19 22:13:12,938:INFO:Initializing Extra Trees Classifier
2025-05-19 22:13:12,938:INFO:Total runtime is 0.5103631178538005 minutes
2025-05-19 22:13:12,943:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:12,943:INFO:Initializing create_model()
2025-05-19 22:13:12,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:12,944:INFO:Checking exceptions
2025-05-19 22:13:12,944:INFO:Importing libraries
2025-05-19 22:13:12,944:INFO:Copying training dataset
2025-05-19 22:13:12,953:INFO:Defining folds
2025-05-19 22:13:12,954:INFO:Declaring metric variables
2025-05-19 22:13:12,959:INFO:Importing untrained model
2025-05-19 22:13:12,966:INFO:Extra Trees Classifier Imported successfully
2025-05-19 22:13:12,979:INFO:Starting cross validation
2025-05-19 22:13:12,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:16,037:INFO:Calculating mean and std
2025-05-19 22:13:16,039:INFO:Creating metrics dataframe
2025-05-19 22:13:16,041:INFO:Uploading results into container
2025-05-19 22:13:16,042:INFO:Uploading model into container now
2025-05-19 22:13:16,042:INFO:_master_model_container: 26
2025-05-19 22:13:16,042:INFO:_display_container: 3
2025-05-19 22:13:16,043:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 22:13:16,043:INFO:create_model() successfully completed......................................
2025-05-19 22:13:16,173:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:16,173:INFO:Creating metrics dataframe
2025-05-19 22:13:16,191:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 22:13:16,191:INFO:Total runtime is 0.564573605855306 minutes
2025-05-19 22:13:16,194:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:16,194:INFO:Initializing create_model()
2025-05-19 22:13:16,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:16,195:INFO:Checking exceptions
2025-05-19 22:13:16,195:INFO:Importing libraries
2025-05-19 22:13:16,195:INFO:Copying training dataset
2025-05-19 22:13:16,204:INFO:Defining folds
2025-05-19 22:13:16,205:INFO:Declaring metric variables
2025-05-19 22:13:16,208:INFO:Importing untrained model
2025-05-19 22:13:16,215:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 22:13:16,225:INFO:Starting cross validation
2025-05-19 22:13:16,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:18,875:INFO:Calculating mean and std
2025-05-19 22:13:18,878:INFO:Creating metrics dataframe
2025-05-19 22:13:18,884:INFO:Uploading results into container
2025-05-19 22:13:18,885:INFO:Uploading model into container now
2025-05-19 22:13:18,886:INFO:_master_model_container: 27
2025-05-19 22:13:18,886:INFO:_display_container: 3
2025-05-19 22:13:18,888:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 22:13:18,889:INFO:create_model() successfully completed......................................
2025-05-19 22:13:19,042:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:19,042:INFO:Creating metrics dataframe
2025-05-19 22:13:19,069:INFO:Initializing Dummy Classifier
2025-05-19 22:13:19,069:INFO:Total runtime is 0.612543268998464 minutes
2025-05-19 22:13:19,075:INFO:SubProcess create_model() called ==================================
2025-05-19 22:13:19,076:INFO:Initializing create_model()
2025-05-19 22:13:19,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD53A9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:19,076:INFO:Checking exceptions
2025-05-19 22:13:19,077:INFO:Importing libraries
2025-05-19 22:13:19,077:INFO:Copying training dataset
2025-05-19 22:13:19,089:INFO:Defining folds
2025-05-19 22:13:19,089:INFO:Declaring metric variables
2025-05-19 22:13:19,096:INFO:Importing untrained model
2025-05-19 22:13:19,105:INFO:Dummy Classifier Imported successfully
2025-05-19 22:13:19,115:INFO:Starting cross validation
2025-05-19 22:13:19,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:13:20,439:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,444:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,445:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,449:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,648:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,654:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,683:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:20,796:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:21,291:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:21,324:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:13:21,344:INFO:Calculating mean and std
2025-05-19 22:13:21,346:INFO:Creating metrics dataframe
2025-05-19 22:13:21,350:INFO:Uploading results into container
2025-05-19 22:13:21,351:INFO:Uploading model into container now
2025-05-19 22:13:21,353:INFO:_master_model_container: 28
2025-05-19 22:13:21,353:INFO:_display_container: 3
2025-05-19 22:13:21,354:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 22:13:21,354:INFO:create_model() successfully completed......................................
2025-05-19 22:13:21,509:INFO:SubProcess create_model() end ==================================
2025-05-19 22:13:21,510:INFO:Creating metrics dataframe
2025-05-19 22:13:21,532:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 22:13:21,551:INFO:Initializing create_model()
2025-05-19 22:13:21,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:13:21,552:INFO:Checking exceptions
2025-05-19 22:13:21,555:INFO:Importing libraries
2025-05-19 22:13:21,555:INFO:Copying training dataset
2025-05-19 22:13:21,564:INFO:Defining folds
2025-05-19 22:13:21,564:INFO:Declaring metric variables
2025-05-19 22:13:21,565:INFO:Importing untrained model
2025-05-19 22:13:21,565:INFO:Declaring custom model
2025-05-19 22:13:21,567:INFO:Logistic Regression Imported successfully
2025-05-19 22:13:21,578:INFO:Cross validation set to False
2025-05-19 22:13:21,578:INFO:Fitting Model
2025-05-19 22:13:22,093:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-19 22:13:22,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.
2025-05-19 22:13:22,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 22:13:22,096:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 22:13:22,096:INFO:[LightGBM] [Info] Total Bins 487
2025-05-19 22:13:22,096:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-19 22:13:22,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-19 22:13:22,097:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-19 22:13:22,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:13:22,184:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:13:22,184:INFO:create_model() successfully completed......................................
2025-05-19 22:13:22,376:INFO:_master_model_container: 28
2025-05-19 22:13:22,376:INFO:_display_container: 3
2025-05-19 22:13:22,377:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:13:22,377:INFO:compare_models() successfully completed......................................
2025-05-19 22:14:12,909:INFO:Initializing compare_models()
2025-05-19 22:14:12,910:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:14:12,910:INFO:Checking exceptions
2025-05-19 22:14:12,914:INFO:Preparing display monitor
2025-05-19 22:14:12,949:INFO:Initializing Logistic Regression
2025-05-19 22:14:12,950:INFO:Total runtime is 1.661380132039388e-05 minutes
2025-05-19 22:14:12,954:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:12,954:INFO:Initializing create_model()
2025-05-19 22:14:12,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:12,955:INFO:Checking exceptions
2025-05-19 22:14:12,955:INFO:Importing libraries
2025-05-19 22:14:12,955:INFO:Copying training dataset
2025-05-19 22:14:12,967:INFO:Defining folds
2025-05-19 22:14:12,967:INFO:Declaring metric variables
2025-05-19 22:14:12,973:INFO:Importing untrained model
2025-05-19 22:14:12,980:INFO:Logistic Regression Imported successfully
2025-05-19 22:14:12,991:INFO:Starting cross validation
2025-05-19 22:14:13,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:14,842:INFO:Calculating mean and std
2025-05-19 22:14:14,847:INFO:Creating metrics dataframe
2025-05-19 22:14:14,851:INFO:Uploading results into container
2025-05-19 22:14:14,853:INFO:Uploading model into container now
2025-05-19 22:14:14,854:INFO:_master_model_container: 29
2025-05-19 22:14:14,854:INFO:_display_container: 4
2025-05-19 22:14:14,854:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:14:14,855:INFO:create_model() successfully completed......................................
2025-05-19 22:14:14,975:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:14,975:INFO:Creating metrics dataframe
2025-05-19 22:14:14,984:INFO:Initializing K Neighbors Classifier
2025-05-19 22:14:14,984:INFO:Total runtime is 0.033915038903554275 minutes
2025-05-19 22:14:14,989:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:14,989:INFO:Initializing create_model()
2025-05-19 22:14:14,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:14,989:INFO:Checking exceptions
2025-05-19 22:14:14,989:INFO:Importing libraries
2025-05-19 22:14:14,990:INFO:Copying training dataset
2025-05-19 22:14:15,003:INFO:Defining folds
2025-05-19 22:14:15,003:INFO:Declaring metric variables
2025-05-19 22:14:15,007:INFO:Importing untrained model
2025-05-19 22:14:15,012:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:14:15,025:INFO:Starting cross validation
2025-05-19 22:14:15,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:16,848:INFO:Calculating mean and std
2025-05-19 22:14:16,849:INFO:Creating metrics dataframe
2025-05-19 22:14:16,851:INFO:Uploading results into container
2025-05-19 22:14:16,852:INFO:Uploading model into container now
2025-05-19 22:14:16,852:INFO:_master_model_container: 30
2025-05-19 22:14:16,852:INFO:_display_container: 4
2025-05-19 22:14:16,853:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:14:16,853:INFO:create_model() successfully completed......................................
2025-05-19 22:14:16,970:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:16,970:INFO:Creating metrics dataframe
2025-05-19 22:14:16,978:INFO:Initializing Naive Bayes
2025-05-19 22:14:16,978:INFO:Total runtime is 0.06714469194412231 minutes
2025-05-19 22:14:16,982:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:16,982:INFO:Initializing create_model()
2025-05-19 22:14:16,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:16,983:INFO:Checking exceptions
2025-05-19 22:14:16,983:INFO:Importing libraries
2025-05-19 22:14:16,983:INFO:Copying training dataset
2025-05-19 22:14:16,989:INFO:Defining folds
2025-05-19 22:14:16,989:INFO:Declaring metric variables
2025-05-19 22:14:16,993:INFO:Importing untrained model
2025-05-19 22:14:16,999:INFO:Naive Bayes Imported successfully
2025-05-19 22:14:17,009:INFO:Starting cross validation
2025-05-19 22:14:17,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:19,149:INFO:Calculating mean and std
2025-05-19 22:14:19,151:INFO:Creating metrics dataframe
2025-05-19 22:14:19,154:INFO:Uploading results into container
2025-05-19 22:14:19,155:INFO:Uploading model into container now
2025-05-19 22:14:19,156:INFO:_master_model_container: 31
2025-05-19 22:14:19,156:INFO:_display_container: 4
2025-05-19 22:14:19,157:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:14:19,157:INFO:create_model() successfully completed......................................
2025-05-19 22:14:19,291:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:19,291:INFO:Creating metrics dataframe
2025-05-19 22:14:19,300:INFO:Initializing Decision Tree Classifier
2025-05-19 22:14:19,300:INFO:Total runtime is 0.10585043827692667 minutes
2025-05-19 22:14:19,304:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:19,304:INFO:Initializing create_model()
2025-05-19 22:14:19,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:19,304:INFO:Checking exceptions
2025-05-19 22:14:19,304:INFO:Importing libraries
2025-05-19 22:14:19,305:INFO:Copying training dataset
2025-05-19 22:14:19,313:INFO:Defining folds
2025-05-19 22:14:19,313:INFO:Declaring metric variables
2025-05-19 22:14:19,317:INFO:Importing untrained model
2025-05-19 22:14:19,323:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:14:19,332:INFO:Starting cross validation
2025-05-19 22:14:19,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:21,425:INFO:Calculating mean and std
2025-05-19 22:14:21,428:INFO:Creating metrics dataframe
2025-05-19 22:14:21,431:INFO:Uploading results into container
2025-05-19 22:14:21,432:INFO:Uploading model into container now
2025-05-19 22:14:21,433:INFO:_master_model_container: 32
2025-05-19 22:14:21,433:INFO:_display_container: 4
2025-05-19 22:14:21,434:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:14:21,434:INFO:create_model() successfully completed......................................
2025-05-19 22:14:21,589:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:21,590:INFO:Creating metrics dataframe
2025-05-19 22:14:21,600:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:14:21,600:INFO:Total runtime is 0.1441880186398824 minutes
2025-05-19 22:14:21,604:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:21,605:INFO:Initializing create_model()
2025-05-19 22:14:21,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:21,605:INFO:Checking exceptions
2025-05-19 22:14:21,605:INFO:Importing libraries
2025-05-19 22:14:21,605:INFO:Copying training dataset
2025-05-19 22:14:21,614:INFO:Defining folds
2025-05-19 22:14:21,614:INFO:Declaring metric variables
2025-05-19 22:14:21,618:INFO:Importing untrained model
2025-05-19 22:14:21,625:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:14:21,634:INFO:Starting cross validation
2025-05-19 22:14:21,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:23,977:INFO:Calculating mean and std
2025-05-19 22:14:23,978:INFO:Creating metrics dataframe
2025-05-19 22:14:23,981:INFO:Uploading results into container
2025-05-19 22:14:23,982:INFO:Uploading model into container now
2025-05-19 22:14:23,983:INFO:_master_model_container: 33
2025-05-19 22:14:23,983:INFO:_display_container: 4
2025-05-19 22:14:23,985:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:14:23,986:INFO:create_model() successfully completed......................................
2025-05-19 22:14:24,137:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:24,138:INFO:Creating metrics dataframe
2025-05-19 22:14:24,148:INFO:Initializing Ridge Classifier
2025-05-19 22:14:24,148:INFO:Total runtime is 0.18664017120997112 minutes
2025-05-19 22:14:24,152:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:24,153:INFO:Initializing create_model()
2025-05-19 22:14:24,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:24,153:INFO:Checking exceptions
2025-05-19 22:14:24,154:INFO:Importing libraries
2025-05-19 22:14:24,154:INFO:Copying training dataset
2025-05-19 22:14:24,162:INFO:Defining folds
2025-05-19 22:14:24,162:INFO:Declaring metric variables
2025-05-19 22:14:24,170:INFO:Importing untrained model
2025-05-19 22:14:24,195:INFO:Ridge Classifier Imported successfully
2025-05-19 22:14:24,208:INFO:Starting cross validation
2025-05-19 22:14:24,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:26,391:INFO:Calculating mean and std
2025-05-19 22:14:26,395:INFO:Creating metrics dataframe
2025-05-19 22:14:26,400:INFO:Uploading results into container
2025-05-19 22:14:26,402:INFO:Uploading model into container now
2025-05-19 22:14:26,404:INFO:_master_model_container: 34
2025-05-19 22:14:26,404:INFO:_display_container: 4
2025-05-19 22:14:26,406:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:14:26,407:INFO:create_model() successfully completed......................................
2025-05-19 22:14:26,555:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:26,555:INFO:Creating metrics dataframe
2025-05-19 22:14:26,567:INFO:Initializing Random Forest Classifier
2025-05-19 22:14:26,567:INFO:Total runtime is 0.22696921825408936 minutes
2025-05-19 22:14:26,571:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:26,571:INFO:Initializing create_model()
2025-05-19 22:14:26,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:26,572:INFO:Checking exceptions
2025-05-19 22:14:26,572:INFO:Importing libraries
2025-05-19 22:14:26,572:INFO:Copying training dataset
2025-05-19 22:14:26,581:INFO:Defining folds
2025-05-19 22:14:26,581:INFO:Declaring metric variables
2025-05-19 22:14:26,585:INFO:Importing untrained model
2025-05-19 22:14:26,593:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:14:26,602:INFO:Starting cross validation
2025-05-19 22:14:26,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:30,480:INFO:Calculating mean and std
2025-05-19 22:14:30,483:INFO:Creating metrics dataframe
2025-05-19 22:14:30,488:INFO:Uploading results into container
2025-05-19 22:14:30,490:INFO:Uploading model into container now
2025-05-19 22:14:30,492:INFO:_master_model_container: 35
2025-05-19 22:14:30,492:INFO:_display_container: 4
2025-05-19 22:14:30,493:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 22:14:30,493:INFO:create_model() successfully completed......................................
2025-05-19 22:14:30,672:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:30,672:INFO:Creating metrics dataframe
2025-05-19 22:14:30,691:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 22:14:30,691:INFO:Total runtime is 0.29569329420725504 minutes
2025-05-19 22:14:30,696:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:30,696:INFO:Initializing create_model()
2025-05-19 22:14:30,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:30,697:INFO:Checking exceptions
2025-05-19 22:14:30,697:INFO:Importing libraries
2025-05-19 22:14:30,697:INFO:Copying training dataset
2025-05-19 22:14:30,708:INFO:Defining folds
2025-05-19 22:14:30,708:INFO:Declaring metric variables
2025-05-19 22:14:30,715:INFO:Importing untrained model
2025-05-19 22:14:30,722:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 22:14:30,737:INFO:Starting cross validation
2025-05-19 22:14:30,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:32,613:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:32,650:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:32,692:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:32,900:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,142:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,317:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,348:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,640:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,753:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:14:33,878:INFO:Calculating mean and std
2025-05-19 22:14:33,880:INFO:Creating metrics dataframe
2025-05-19 22:14:33,884:INFO:Uploading results into container
2025-05-19 22:14:33,885:INFO:Uploading model into container now
2025-05-19 22:14:33,886:INFO:_master_model_container: 36
2025-05-19 22:14:33,886:INFO:_display_container: 4
2025-05-19 22:14:33,887:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 22:14:33,887:INFO:create_model() successfully completed......................................
2025-05-19 22:14:34,026:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:34,026:INFO:Creating metrics dataframe
2025-05-19 22:14:34,036:INFO:Initializing Ada Boost Classifier
2025-05-19 22:14:34,036:INFO:Total runtime is 0.35145157972971597 minutes
2025-05-19 22:14:34,041:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:34,041:INFO:Initializing create_model()
2025-05-19 22:14:34,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:34,042:INFO:Checking exceptions
2025-05-19 22:14:34,042:INFO:Importing libraries
2025-05-19 22:14:34,042:INFO:Copying training dataset
2025-05-19 22:14:34,052:INFO:Defining folds
2025-05-19 22:14:34,052:INFO:Declaring metric variables
2025-05-19 22:14:34,057:INFO:Importing untrained model
2025-05-19 22:14:34,064:INFO:Ada Boost Classifier Imported successfully
2025-05-19 22:14:34,075:INFO:Starting cross validation
2025-05-19 22:14:34,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:35,437:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,456:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,466:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,476:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,611:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,671:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,693:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:35,799:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:36,184:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:36,248:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:14:36,389:INFO:Calculating mean and std
2025-05-19 22:14:36,391:INFO:Creating metrics dataframe
2025-05-19 22:14:36,395:INFO:Uploading results into container
2025-05-19 22:14:36,395:INFO:Uploading model into container now
2025-05-19 22:14:36,396:INFO:_master_model_container: 37
2025-05-19 22:14:36,396:INFO:_display_container: 4
2025-05-19 22:14:36,397:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 22:14:36,397:INFO:create_model() successfully completed......................................
2025-05-19 22:14:36,527:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:36,527:INFO:Creating metrics dataframe
2025-05-19 22:14:36,537:INFO:Initializing Gradient Boosting Classifier
2025-05-19 22:14:36,537:INFO:Total runtime is 0.39313384294509884 minutes
2025-05-19 22:14:36,541:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:36,542:INFO:Initializing create_model()
2025-05-19 22:14:36,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:36,542:INFO:Checking exceptions
2025-05-19 22:14:36,542:INFO:Importing libraries
2025-05-19 22:14:36,542:INFO:Copying training dataset
2025-05-19 22:14:36,550:INFO:Defining folds
2025-05-19 22:14:36,550:INFO:Declaring metric variables
2025-05-19 22:14:36,558:INFO:Importing untrained model
2025-05-19 22:14:36,563:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 22:14:36,571:INFO:Starting cross validation
2025-05-19 22:14:36,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:39,242:INFO:Calculating mean and std
2025-05-19 22:14:39,244:INFO:Creating metrics dataframe
2025-05-19 22:14:39,246:INFO:Uploading results into container
2025-05-19 22:14:39,247:INFO:Uploading model into container now
2025-05-19 22:14:39,248:INFO:_master_model_container: 38
2025-05-19 22:14:39,248:INFO:_display_container: 4
2025-05-19 22:14:39,248:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 22:14:39,248:INFO:create_model() successfully completed......................................
2025-05-19 22:14:39,370:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:39,370:INFO:Creating metrics dataframe
2025-05-19 22:14:39,381:INFO:Initializing Linear Discriminant Analysis
2025-05-19 22:14:39,381:INFO:Total runtime is 0.44052731990814203 minutes
2025-05-19 22:14:39,384:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:39,384:INFO:Initializing create_model()
2025-05-19 22:14:39,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:39,384:INFO:Checking exceptions
2025-05-19 22:14:39,385:INFO:Importing libraries
2025-05-19 22:14:39,385:INFO:Copying training dataset
2025-05-19 22:14:39,392:INFO:Defining folds
2025-05-19 22:14:39,393:INFO:Declaring metric variables
2025-05-19 22:14:39,397:INFO:Importing untrained model
2025-05-19 22:14:39,401:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 22:14:39,412:INFO:Starting cross validation
2025-05-19 22:14:39,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:41,425:INFO:Calculating mean and std
2025-05-19 22:14:41,427:INFO:Creating metrics dataframe
2025-05-19 22:14:41,430:INFO:Uploading results into container
2025-05-19 22:14:41,431:INFO:Uploading model into container now
2025-05-19 22:14:41,432:INFO:_master_model_container: 39
2025-05-19 22:14:41,433:INFO:_display_container: 4
2025-05-19 22:14:41,433:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 22:14:41,434:INFO:create_model() successfully completed......................................
2025-05-19 22:14:41,581:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:41,581:INFO:Creating metrics dataframe
2025-05-19 22:14:41,593:INFO:Initializing Extra Trees Classifier
2025-05-19 22:14:41,593:INFO:Total runtime is 0.4773942629496256 minutes
2025-05-19 22:14:41,597:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:41,597:INFO:Initializing create_model()
2025-05-19 22:14:41,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:41,597:INFO:Checking exceptions
2025-05-19 22:14:41,598:INFO:Importing libraries
2025-05-19 22:14:41,598:INFO:Copying training dataset
2025-05-19 22:14:41,607:INFO:Defining folds
2025-05-19 22:14:41,607:INFO:Declaring metric variables
2025-05-19 22:14:41,611:INFO:Importing untrained model
2025-05-19 22:14:41,617:INFO:Extra Trees Classifier Imported successfully
2025-05-19 22:14:41,628:INFO:Starting cross validation
2025-05-19 22:14:41,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:44,622:INFO:Calculating mean and std
2025-05-19 22:14:44,624:INFO:Creating metrics dataframe
2025-05-19 22:14:44,626:INFO:Uploading results into container
2025-05-19 22:14:44,626:INFO:Uploading model into container now
2025-05-19 22:14:44,627:INFO:_master_model_container: 40
2025-05-19 22:14:44,627:INFO:_display_container: 4
2025-05-19 22:14:44,627:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 22:14:44,628:INFO:create_model() successfully completed......................................
2025-05-19 22:14:44,754:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:44,754:INFO:Creating metrics dataframe
2025-05-19 22:14:44,766:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 22:14:44,766:INFO:Total runtime is 0.5302820642789204 minutes
2025-05-19 22:14:44,770:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:44,771:INFO:Initializing create_model()
2025-05-19 22:14:44,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:44,771:INFO:Checking exceptions
2025-05-19 22:14:44,771:INFO:Importing libraries
2025-05-19 22:14:44,772:INFO:Copying training dataset
2025-05-19 22:14:44,780:INFO:Defining folds
2025-05-19 22:14:44,780:INFO:Declaring metric variables
2025-05-19 22:14:44,784:INFO:Importing untrained model
2025-05-19 22:14:44,789:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 22:14:44,799:INFO:Starting cross validation
2025-05-19 22:14:44,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:47,606:INFO:Calculating mean and std
2025-05-19 22:14:47,610:INFO:Creating metrics dataframe
2025-05-19 22:14:47,615:INFO:Uploading results into container
2025-05-19 22:14:47,617:INFO:Uploading model into container now
2025-05-19 22:14:47,618:INFO:_master_model_container: 41
2025-05-19 22:14:47,618:INFO:_display_container: 4
2025-05-19 22:14:47,623:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 22:14:47,623:INFO:create_model() successfully completed......................................
2025-05-19 22:14:47,796:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:47,796:INFO:Creating metrics dataframe
2025-05-19 22:14:47,827:INFO:Initializing Dummy Classifier
2025-05-19 22:14:47,827:INFO:Total runtime is 0.5812954068183899 minutes
2025-05-19 22:14:47,832:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:47,832:INFO:Initializing create_model()
2025-05-19 22:14:47,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DA4AB390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:47,833:INFO:Checking exceptions
2025-05-19 22:14:47,833:INFO:Importing libraries
2025-05-19 22:14:47,833:INFO:Copying training dataset
2025-05-19 22:14:47,848:INFO:Defining folds
2025-05-19 22:14:47,848:INFO:Declaring metric variables
2025-05-19 22:14:47,857:INFO:Importing untrained model
2025-05-19 22:14:47,865:INFO:Dummy Classifier Imported successfully
2025-05-19 22:14:47,880:INFO:Starting cross validation
2025-05-19 22:14:47,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:49,345:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,364:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,454:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,512:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,608:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,639:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:49,640:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:50,017:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:50,029:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:14:50,044:INFO:Calculating mean and std
2025-05-19 22:14:50,048:INFO:Creating metrics dataframe
2025-05-19 22:14:50,055:INFO:Uploading results into container
2025-05-19 22:14:50,057:INFO:Uploading model into container now
2025-05-19 22:14:50,058:INFO:_master_model_container: 42
2025-05-19 22:14:50,059:INFO:_display_container: 4
2025-05-19 22:14:50,059:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 22:14:50,059:INFO:create_model() successfully completed......................................
2025-05-19 22:14:50,185:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:50,185:INFO:Creating metrics dataframe
2025-05-19 22:14:50,197:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 22:14:50,210:INFO:Initializing create_model()
2025-05-19 22:14:50,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:50,210:INFO:Checking exceptions
2025-05-19 22:14:50,212:INFO:Importing libraries
2025-05-19 22:14:50,212:INFO:Copying training dataset
2025-05-19 22:14:50,218:INFO:Defining folds
2025-05-19 22:14:50,219:INFO:Declaring metric variables
2025-05-19 22:14:50,219:INFO:Importing untrained model
2025-05-19 22:14:50,219:INFO:Declaring custom model
2025-05-19 22:14:50,219:INFO:Logistic Regression Imported successfully
2025-05-19 22:14:50,229:INFO:Cross validation set to False
2025-05-19 22:14:50,229:INFO:Fitting Model
2025-05-19 22:14:50,580:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-19 22:14:50,581:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.
2025-05-19 22:14:50,581:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 22:14:50,581:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 22:14:50,581:INFO:[LightGBM] [Info] Total Bins 487
2025-05-19 22:14:50,581:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-19 22:14:50,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-19 22:14:50,582:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-19 22:14:50,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:14:50,641:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:14:50,642:INFO:create_model() successfully completed......................................
2025-05-19 22:14:50,791:INFO:_master_model_container: 42
2025-05-19 22:14:50,792:INFO:_display_container: 4
2025-05-19 22:14:50,792:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:14:50,793:INFO:compare_models() successfully completed......................................
2025-05-19 22:14:53,432:INFO:Initializing compare_models()
2025-05-19 22:14:53,433:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:14:53,433:INFO:Checking exceptions
2025-05-19 22:14:53,436:INFO:Preparing display monitor
2025-05-19 22:14:53,468:INFO:Initializing Logistic Regression
2025-05-19 22:14:53,469:INFO:Total runtime is 1.661380132039388e-05 minutes
2025-05-19 22:14:53,474:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:53,474:INFO:Initializing create_model()
2025-05-19 22:14:53,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:53,474:INFO:Checking exceptions
2025-05-19 22:14:53,475:INFO:Importing libraries
2025-05-19 22:14:53,475:INFO:Copying training dataset
2025-05-19 22:14:53,486:INFO:Defining folds
2025-05-19 22:14:53,486:INFO:Declaring metric variables
2025-05-19 22:14:53,511:INFO:Importing untrained model
2025-05-19 22:14:53,519:INFO:Logistic Regression Imported successfully
2025-05-19 22:14:53,539:INFO:Starting cross validation
2025-05-19 22:14:53,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:55,776:INFO:Calculating mean and std
2025-05-19 22:14:55,778:INFO:Creating metrics dataframe
2025-05-19 22:14:55,780:INFO:Uploading results into container
2025-05-19 22:14:55,781:INFO:Uploading model into container now
2025-05-19 22:14:55,782:INFO:_master_model_container: 43
2025-05-19 22:14:55,783:INFO:_display_container: 5
2025-05-19 22:14:55,783:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:14:55,784:INFO:create_model() successfully completed......................................
2025-05-19 22:14:55,925:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:55,925:INFO:Creating metrics dataframe
2025-05-19 22:14:55,934:INFO:Initializing K Neighbors Classifier
2025-05-19 22:14:55,934:INFO:Total runtime is 0.04109852711359659 minutes
2025-05-19 22:14:55,939:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:55,940:INFO:Initializing create_model()
2025-05-19 22:14:55,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:55,941:INFO:Checking exceptions
2025-05-19 22:14:55,941:INFO:Importing libraries
2025-05-19 22:14:55,941:INFO:Copying training dataset
2025-05-19 22:14:55,950:INFO:Defining folds
2025-05-19 22:14:55,950:INFO:Declaring metric variables
2025-05-19 22:14:55,957:INFO:Importing untrained model
2025-05-19 22:14:55,964:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:14:55,976:INFO:Starting cross validation
2025-05-19 22:14:55,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:14:58,517:INFO:Calculating mean and std
2025-05-19 22:14:58,519:INFO:Creating metrics dataframe
2025-05-19 22:14:58,522:INFO:Uploading results into container
2025-05-19 22:14:58,522:INFO:Uploading model into container now
2025-05-19 22:14:58,523:INFO:_master_model_container: 44
2025-05-19 22:14:58,523:INFO:_display_container: 5
2025-05-19 22:14:58,524:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:14:58,524:INFO:create_model() successfully completed......................................
2025-05-19 22:14:58,671:INFO:SubProcess create_model() end ==================================
2025-05-19 22:14:58,671:INFO:Creating metrics dataframe
2025-05-19 22:14:58,680:INFO:Initializing Naive Bayes
2025-05-19 22:14:58,681:INFO:Total runtime is 0.0868824561436971 minutes
2025-05-19 22:14:58,685:INFO:SubProcess create_model() called ==================================
2025-05-19 22:14:58,686:INFO:Initializing create_model()
2025-05-19 22:14:58,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:14:58,687:INFO:Checking exceptions
2025-05-19 22:14:58,687:INFO:Importing libraries
2025-05-19 22:14:58,687:INFO:Copying training dataset
2025-05-19 22:14:58,696:INFO:Defining folds
2025-05-19 22:14:58,696:INFO:Declaring metric variables
2025-05-19 22:14:58,700:INFO:Importing untrained model
2025-05-19 22:14:58,708:INFO:Naive Bayes Imported successfully
2025-05-19 22:14:58,717:INFO:Starting cross validation
2025-05-19 22:14:58,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:01,187:INFO:Calculating mean and std
2025-05-19 22:15:01,189:INFO:Creating metrics dataframe
2025-05-19 22:15:01,193:INFO:Uploading results into container
2025-05-19 22:15:01,194:INFO:Uploading model into container now
2025-05-19 22:15:01,195:INFO:_master_model_container: 45
2025-05-19 22:15:01,195:INFO:_display_container: 5
2025-05-19 22:15:01,196:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:15:01,196:INFO:create_model() successfully completed......................................
2025-05-19 22:15:01,377:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:01,378:INFO:Creating metrics dataframe
2025-05-19 22:15:01,395:INFO:Initializing Decision Tree Classifier
2025-05-19 22:15:01,396:INFO:Total runtime is 0.1321380893389384 minutes
2025-05-19 22:15:01,403:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:01,403:INFO:Initializing create_model()
2025-05-19 22:15:01,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:01,404:INFO:Checking exceptions
2025-05-19 22:15:01,404:INFO:Importing libraries
2025-05-19 22:15:01,405:INFO:Copying training dataset
2025-05-19 22:15:01,428:INFO:Defining folds
2025-05-19 22:15:01,428:INFO:Declaring metric variables
2025-05-19 22:15:01,438:INFO:Importing untrained model
2025-05-19 22:15:01,445:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:15:01,460:INFO:Starting cross validation
2025-05-19 22:15:01,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:04,463:INFO:Calculating mean and std
2025-05-19 22:15:04,465:INFO:Creating metrics dataframe
2025-05-19 22:15:04,470:INFO:Uploading results into container
2025-05-19 22:15:04,472:INFO:Uploading model into container now
2025-05-19 22:15:04,473:INFO:_master_model_container: 46
2025-05-19 22:15:04,473:INFO:_display_container: 5
2025-05-19 22:15:04,475:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:15:04,475:INFO:create_model() successfully completed......................................
2025-05-19 22:15:04,609:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:04,610:INFO:Creating metrics dataframe
2025-05-19 22:15:04,618:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:15:04,618:INFO:Total runtime is 0.18582710027694702 minutes
2025-05-19 22:15:04,622:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:04,622:INFO:Initializing create_model()
2025-05-19 22:15:04,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:04,622:INFO:Checking exceptions
2025-05-19 22:15:04,623:INFO:Importing libraries
2025-05-19 22:15:04,623:INFO:Copying training dataset
2025-05-19 22:15:04,631:INFO:Defining folds
2025-05-19 22:15:04,631:INFO:Declaring metric variables
2025-05-19 22:15:04,635:INFO:Importing untrained model
2025-05-19 22:15:04,640:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:15:04,650:INFO:Starting cross validation
2025-05-19 22:15:04,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:06,830:INFO:Calculating mean and std
2025-05-19 22:15:06,832:INFO:Creating metrics dataframe
2025-05-19 22:15:06,835:INFO:Uploading results into container
2025-05-19 22:15:06,836:INFO:Uploading model into container now
2025-05-19 22:15:06,837:INFO:_master_model_container: 47
2025-05-19 22:15:06,837:INFO:_display_container: 5
2025-05-19 22:15:06,838:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:15:06,838:INFO:create_model() successfully completed......................................
2025-05-19 22:15:06,965:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:06,965:INFO:Creating metrics dataframe
2025-05-19 22:15:06,975:INFO:Initializing Ridge Classifier
2025-05-19 22:15:06,975:INFO:Total runtime is 0.22510952154795327 minutes
2025-05-19 22:15:06,979:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:06,979:INFO:Initializing create_model()
2025-05-19 22:15:06,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:06,980:INFO:Checking exceptions
2025-05-19 22:15:06,980:INFO:Importing libraries
2025-05-19 22:15:06,980:INFO:Copying training dataset
2025-05-19 22:15:06,988:INFO:Defining folds
2025-05-19 22:15:06,988:INFO:Declaring metric variables
2025-05-19 22:15:06,992:INFO:Importing untrained model
2025-05-19 22:15:06,998:INFO:Ridge Classifier Imported successfully
2025-05-19 22:15:07,007:INFO:Starting cross validation
2025-05-19 22:15:07,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:10,024:INFO:Calculating mean and std
2025-05-19 22:15:10,029:INFO:Creating metrics dataframe
2025-05-19 22:15:10,033:INFO:Uploading results into container
2025-05-19 22:15:10,036:INFO:Uploading model into container now
2025-05-19 22:15:10,038:INFO:_master_model_container: 48
2025-05-19 22:15:10,039:INFO:_display_container: 5
2025-05-19 22:15:10,039:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:15:10,040:INFO:create_model() successfully completed......................................
2025-05-19 22:15:10,216:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:10,216:INFO:Creating metrics dataframe
2025-05-19 22:15:10,281:INFO:Initializing Random Forest Classifier
2025-05-19 22:15:10,282:INFO:Total runtime is 0.2802278995513916 minutes
2025-05-19 22:15:10,290:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:10,290:INFO:Initializing create_model()
2025-05-19 22:15:10,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DD4BE350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:10,291:INFO:Checking exceptions
2025-05-19 22:15:10,291:INFO:Importing libraries
2025-05-19 22:15:10,291:INFO:Copying training dataset
2025-05-19 22:15:10,308:INFO:Defining folds
2025-05-19 22:15:10,308:INFO:Declaring metric variables
2025-05-19 22:15:10,313:INFO:Importing untrained model
2025-05-19 22:15:10,321:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:15:10,331:INFO:Starting cross validation
2025-05-19 22:15:10,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:18,266:INFO:Initializing compare_models()
2025-05-19 22:15:18,266:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:15:18,267:INFO:Checking exceptions
2025-05-19 22:15:18,271:INFO:Preparing display monitor
2025-05-19 22:15:18,306:INFO:Initializing Logistic Regression
2025-05-19 22:15:18,306:INFO:Total runtime is 0.0 minutes
2025-05-19 22:15:18,310:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:18,310:INFO:Initializing create_model()
2025-05-19 22:15:18,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:18,311:INFO:Checking exceptions
2025-05-19 22:15:18,311:INFO:Importing libraries
2025-05-19 22:15:18,311:INFO:Copying training dataset
2025-05-19 22:15:18,323:INFO:Defining folds
2025-05-19 22:15:18,323:INFO:Declaring metric variables
2025-05-19 22:15:18,330:INFO:Importing untrained model
2025-05-19 22:15:18,342:INFO:Logistic Regression Imported successfully
2025-05-19 22:15:18,359:INFO:Starting cross validation
2025-05-19 22:15:18,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:31,935:INFO:Calculating mean and std
2025-05-19 22:15:31,938:INFO:Creating metrics dataframe
2025-05-19 22:15:31,943:INFO:Uploading results into container
2025-05-19 22:15:31,945:INFO:Uploading model into container now
2025-05-19 22:15:31,946:INFO:_master_model_container: 49
2025-05-19 22:15:31,946:INFO:_display_container: 5
2025-05-19 22:15:31,948:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:15:31,948:INFO:create_model() successfully completed......................................
2025-05-19 22:15:32,207:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:32,207:INFO:Creating metrics dataframe
2025-05-19 22:15:32,218:INFO:Initializing K Neighbors Classifier
2025-05-19 22:15:32,218:INFO:Total runtime is 0.23187042872111002 minutes
2025-05-19 22:15:32,225:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:32,226:INFO:Initializing create_model()
2025-05-19 22:15:32,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:32,226:INFO:Checking exceptions
2025-05-19 22:15:32,227:INFO:Importing libraries
2025-05-19 22:15:32,227:INFO:Copying training dataset
2025-05-19 22:15:32,241:INFO:Defining folds
2025-05-19 22:15:32,242:INFO:Declaring metric variables
2025-05-19 22:15:32,250:INFO:Importing untrained model
2025-05-19 22:15:32,258:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:15:32,296:INFO:Starting cross validation
2025-05-19 22:15:32,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:36,090:INFO:Calculating mean and std
2025-05-19 22:15:36,092:INFO:Creating metrics dataframe
2025-05-19 22:15:36,097:INFO:Uploading results into container
2025-05-19 22:15:36,101:INFO:Uploading model into container now
2025-05-19 22:15:36,102:INFO:_master_model_container: 50
2025-05-19 22:15:36,102:INFO:_display_container: 5
2025-05-19 22:15:36,103:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:15:36,104:INFO:create_model() successfully completed......................................
2025-05-19 22:15:36,341:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:36,342:INFO:Creating metrics dataframe
2025-05-19 22:15:36,358:INFO:Initializing Naive Bayes
2025-05-19 22:15:36,358:INFO:Total runtime is 0.3008744835853577 minutes
2025-05-19 22:15:36,366:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:36,367:INFO:Initializing create_model()
2025-05-19 22:15:36,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:36,367:INFO:Checking exceptions
2025-05-19 22:15:36,368:INFO:Importing libraries
2025-05-19 22:15:36,368:INFO:Copying training dataset
2025-05-19 22:15:36,380:INFO:Defining folds
2025-05-19 22:15:36,380:INFO:Declaring metric variables
2025-05-19 22:15:36,387:INFO:Importing untrained model
2025-05-19 22:15:36,395:INFO:Naive Bayes Imported successfully
2025-05-19 22:15:36,409:INFO:Starting cross validation
2025-05-19 22:15:36,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:39,709:INFO:Calculating mean and std
2025-05-19 22:15:39,711:INFO:Creating metrics dataframe
2025-05-19 22:15:39,716:INFO:Uploading results into container
2025-05-19 22:15:39,718:INFO:Uploading model into container now
2025-05-19 22:15:39,720:INFO:_master_model_container: 51
2025-05-19 22:15:39,720:INFO:_display_container: 5
2025-05-19 22:15:39,720:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:15:39,721:INFO:create_model() successfully completed......................................
2025-05-19 22:15:39,937:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:39,938:INFO:Creating metrics dataframe
2025-05-19 22:15:39,956:INFO:Initializing Decision Tree Classifier
2025-05-19 22:15:39,956:INFO:Total runtime is 0.3608293096224467 minutes
2025-05-19 22:15:39,963:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:39,963:INFO:Initializing create_model()
2025-05-19 22:15:39,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:39,964:INFO:Checking exceptions
2025-05-19 22:15:39,964:INFO:Importing libraries
2025-05-19 22:15:39,964:INFO:Copying training dataset
2025-05-19 22:15:39,977:INFO:Defining folds
2025-05-19 22:15:39,978:INFO:Declaring metric variables
2025-05-19 22:15:39,986:INFO:Importing untrained model
2025-05-19 22:15:39,993:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:15:40,005:INFO:Starting cross validation
2025-05-19 22:15:40,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:43,485:INFO:Calculating mean and std
2025-05-19 22:15:43,489:INFO:Creating metrics dataframe
2025-05-19 22:15:43,502:INFO:Uploading results into container
2025-05-19 22:15:43,504:INFO:Uploading model into container now
2025-05-19 22:15:43,505:INFO:_master_model_container: 52
2025-05-19 22:15:43,505:INFO:_display_container: 5
2025-05-19 22:15:43,506:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:15:43,506:INFO:create_model() successfully completed......................................
2025-05-19 22:15:43,819:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:43,819:INFO:Creating metrics dataframe
2025-05-19 22:15:43,841:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:15:43,841:INFO:Total runtime is 0.4255928119023641 minutes
2025-05-19 22:15:43,851:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:43,852:INFO:Initializing create_model()
2025-05-19 22:15:43,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:43,852:INFO:Checking exceptions
2025-05-19 22:15:43,852:INFO:Importing libraries
2025-05-19 22:15:43,853:INFO:Copying training dataset
2025-05-19 22:15:43,875:INFO:Defining folds
2025-05-19 22:15:43,875:INFO:Declaring metric variables
2025-05-19 22:15:43,886:INFO:Importing untrained model
2025-05-19 22:15:43,898:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:15:43,916:INFO:Starting cross validation
2025-05-19 22:15:43,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:46,813:INFO:Calculating mean and std
2025-05-19 22:15:46,816:INFO:Creating metrics dataframe
2025-05-19 22:15:46,820:INFO:Uploading results into container
2025-05-19 22:15:46,821:INFO:Uploading model into container now
2025-05-19 22:15:46,822:INFO:_master_model_container: 53
2025-05-19 22:15:46,822:INFO:_display_container: 5
2025-05-19 22:15:46,824:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:15:46,824:INFO:create_model() successfully completed......................................
2025-05-19 22:15:47,027:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:47,027:INFO:Creating metrics dataframe
2025-05-19 22:15:47,045:INFO:Initializing Ridge Classifier
2025-05-19 22:15:47,045:INFO:Total runtime is 0.4789827903111776 minutes
2025-05-19 22:15:47,054:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:47,054:INFO:Initializing create_model()
2025-05-19 22:15:47,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:47,055:INFO:Checking exceptions
2025-05-19 22:15:47,055:INFO:Importing libraries
2025-05-19 22:15:47,055:INFO:Copying training dataset
2025-05-19 22:15:47,072:INFO:Defining folds
2025-05-19 22:15:47,073:INFO:Declaring metric variables
2025-05-19 22:15:47,083:INFO:Importing untrained model
2025-05-19 22:15:47,091:INFO:Ridge Classifier Imported successfully
2025-05-19 22:15:47,107:INFO:Starting cross validation
2025-05-19 22:15:47,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:50,860:INFO:Calculating mean and std
2025-05-19 22:15:50,868:INFO:Creating metrics dataframe
2025-05-19 22:15:50,880:INFO:Uploading results into container
2025-05-19 22:15:50,881:INFO:Uploading model into container now
2025-05-19 22:15:50,882:INFO:_master_model_container: 54
2025-05-19 22:15:50,883:INFO:_display_container: 5
2025-05-19 22:15:50,884:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:15:50,884:INFO:create_model() successfully completed......................................
2025-05-19 22:15:51,337:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:51,338:INFO:Creating metrics dataframe
2025-05-19 22:15:51,365:INFO:Initializing Random Forest Classifier
2025-05-19 22:15:51,366:INFO:Total runtime is 0.550995934009552 minutes
2025-05-19 22:15:51,378:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:51,379:INFO:Initializing create_model()
2025-05-19 22:15:51,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:51,380:INFO:Checking exceptions
2025-05-19 22:15:51,380:INFO:Importing libraries
2025-05-19 22:15:51,381:INFO:Copying training dataset
2025-05-19 22:15:51,414:INFO:Defining folds
2025-05-19 22:15:51,415:INFO:Declaring metric variables
2025-05-19 22:15:51,426:INFO:Importing untrained model
2025-05-19 22:15:51,441:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:15:51,463:INFO:Starting cross validation
2025-05-19 22:15:51,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:55,913:INFO:Calculating mean and std
2025-05-19 22:15:55,915:INFO:Creating metrics dataframe
2025-05-19 22:15:55,918:INFO:Uploading results into container
2025-05-19 22:15:55,919:INFO:Uploading model into container now
2025-05-19 22:15:55,920:INFO:_master_model_container: 55
2025-05-19 22:15:55,920:INFO:_display_container: 5
2025-05-19 22:15:55,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 22:15:55,922:INFO:create_model() successfully completed......................................
2025-05-19 22:15:56,083:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:56,083:INFO:Creating metrics dataframe
2025-05-19 22:15:56,094:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 22:15:56,094:INFO:Total runtime is 0.6297937870025635 minutes
2025-05-19 22:15:56,100:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:56,101:INFO:Initializing create_model()
2025-05-19 22:15:56,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:56,101:INFO:Checking exceptions
2025-05-19 22:15:56,101:INFO:Importing libraries
2025-05-19 22:15:56,101:INFO:Copying training dataset
2025-05-19 22:15:56,110:INFO:Defining folds
2025-05-19 22:15:56,110:INFO:Declaring metric variables
2025-05-19 22:15:56,118:INFO:Importing untrained model
2025-05-19 22:15:56,123:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 22:15:56,134:INFO:Starting cross validation
2025-05-19 22:15:56,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:15:57,666:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:57,667:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:57,682:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:57,771:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:57,924:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:57,992:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:58,087:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:58,157:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:58,673:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:58,710:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:15:58,842:INFO:Calculating mean and std
2025-05-19 22:15:58,844:INFO:Creating metrics dataframe
2025-05-19 22:15:58,849:INFO:Uploading results into container
2025-05-19 22:15:58,852:INFO:Uploading model into container now
2025-05-19 22:15:58,853:INFO:_master_model_container: 56
2025-05-19 22:15:58,853:INFO:_display_container: 5
2025-05-19 22:15:58,854:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 22:15:58,854:INFO:create_model() successfully completed......................................
2025-05-19 22:15:59,048:INFO:SubProcess create_model() end ==================================
2025-05-19 22:15:59,048:INFO:Creating metrics dataframe
2025-05-19 22:15:59,062:INFO:Initializing Ada Boost Classifier
2025-05-19 22:15:59,063:INFO:Total runtime is 0.6792784969011942 minutes
2025-05-19 22:15:59,069:INFO:SubProcess create_model() called ==================================
2025-05-19 22:15:59,069:INFO:Initializing create_model()
2025-05-19 22:15:59,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:15:59,069:INFO:Checking exceptions
2025-05-19 22:15:59,070:INFO:Importing libraries
2025-05-19 22:15:59,070:INFO:Copying training dataset
2025-05-19 22:15:59,084:INFO:Defining folds
2025-05-19 22:15:59,084:INFO:Declaring metric variables
2025-05-19 22:15:59,092:INFO:Importing untrained model
2025-05-19 22:15:59,100:INFO:Ada Boost Classifier Imported successfully
2025-05-19 22:15:59,111:INFO:Starting cross validation
2025-05-19 22:15:59,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:00,929:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:00,931:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:00,933:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:00,940:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,156:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,320:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,394:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,433:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,976:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:01,980:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:16:02,132:INFO:Calculating mean and std
2025-05-19 22:16:02,134:INFO:Creating metrics dataframe
2025-05-19 22:16:02,139:INFO:Uploading results into container
2025-05-19 22:16:02,141:INFO:Uploading model into container now
2025-05-19 22:16:02,142:INFO:_master_model_container: 57
2025-05-19 22:16:02,142:INFO:_display_container: 5
2025-05-19 22:16:02,142:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 22:16:02,143:INFO:create_model() successfully completed......................................
2025-05-19 22:16:02,335:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:02,335:INFO:Creating metrics dataframe
2025-05-19 22:16:02,348:INFO:Initializing Gradient Boosting Classifier
2025-05-19 22:16:02,348:INFO:Total runtime is 0.7340393384297689 minutes
2025-05-19 22:16:02,354:INFO:SubProcess create_model() called ==================================
2025-05-19 22:16:02,354:INFO:Initializing create_model()
2025-05-19 22:16:02,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:02,355:INFO:Checking exceptions
2025-05-19 22:16:02,355:INFO:Importing libraries
2025-05-19 22:16:02,355:INFO:Copying training dataset
2025-05-19 22:16:02,370:INFO:Defining folds
2025-05-19 22:16:02,370:INFO:Declaring metric variables
2025-05-19 22:16:02,377:INFO:Importing untrained model
2025-05-19 22:16:02,387:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 22:16:02,404:INFO:Starting cross validation
2025-05-19 22:16:02,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:06,922:INFO:Calculating mean and std
2025-05-19 22:16:06,924:INFO:Creating metrics dataframe
2025-05-19 22:16:06,929:INFO:Uploading results into container
2025-05-19 22:16:06,931:INFO:Uploading model into container now
2025-05-19 22:16:06,932:INFO:_master_model_container: 58
2025-05-19 22:16:06,932:INFO:_display_container: 5
2025-05-19 22:16:06,933:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 22:16:06,933:INFO:create_model() successfully completed......................................
2025-05-19 22:16:07,125:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:07,125:INFO:Creating metrics dataframe
2025-05-19 22:16:07,138:INFO:Initializing Linear Discriminant Analysis
2025-05-19 22:16:07,138:INFO:Total runtime is 0.8138720194498698 minutes
2025-05-19 22:16:07,144:INFO:SubProcess create_model() called ==================================
2025-05-19 22:16:07,144:INFO:Initializing create_model()
2025-05-19 22:16:07,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:07,145:INFO:Checking exceptions
2025-05-19 22:16:07,145:INFO:Importing libraries
2025-05-19 22:16:07,145:INFO:Copying training dataset
2025-05-19 22:16:07,155:INFO:Defining folds
2025-05-19 22:16:07,156:INFO:Declaring metric variables
2025-05-19 22:16:07,162:INFO:Importing untrained model
2025-05-19 22:16:07,168:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 22:16:07,179:INFO:Starting cross validation
2025-05-19 22:16:07,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:09,680:INFO:Calculating mean and std
2025-05-19 22:16:09,682:INFO:Creating metrics dataframe
2025-05-19 22:16:09,688:INFO:Uploading results into container
2025-05-19 22:16:09,690:INFO:Uploading model into container now
2025-05-19 22:16:09,691:INFO:_master_model_container: 59
2025-05-19 22:16:09,692:INFO:_display_container: 5
2025-05-19 22:16:09,693:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 22:16:09,693:INFO:create_model() successfully completed......................................
2025-05-19 22:16:09,877:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:09,877:INFO:Creating metrics dataframe
2025-05-19 22:16:09,892:INFO:Initializing Extra Trees Classifier
2025-05-19 22:16:09,892:INFO:Total runtime is 0.8597641984621683 minutes
2025-05-19 22:16:09,899:INFO:SubProcess create_model() called ==================================
2025-05-19 22:16:09,899:INFO:Initializing create_model()
2025-05-19 22:16:09,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:09,899:INFO:Checking exceptions
2025-05-19 22:16:09,900:INFO:Importing libraries
2025-05-19 22:16:09,900:INFO:Copying training dataset
2025-05-19 22:16:09,909:INFO:Defining folds
2025-05-19 22:16:09,910:INFO:Declaring metric variables
2025-05-19 22:16:09,917:INFO:Importing untrained model
2025-05-19 22:16:09,923:INFO:Extra Trees Classifier Imported successfully
2025-05-19 22:16:09,934:INFO:Starting cross validation
2025-05-19 22:16:09,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:13,488:INFO:Calculating mean and std
2025-05-19 22:16:13,490:INFO:Creating metrics dataframe
2025-05-19 22:16:13,493:INFO:Uploading results into container
2025-05-19 22:16:13,495:INFO:Uploading model into container now
2025-05-19 22:16:13,497:INFO:_master_model_container: 60
2025-05-19 22:16:13,497:INFO:_display_container: 5
2025-05-19 22:16:13,499:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 22:16:13,499:INFO:create_model() successfully completed......................................
2025-05-19 22:16:13,689:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:13,689:INFO:Creating metrics dataframe
2025-05-19 22:16:13,709:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 22:16:13,710:INFO:Total runtime is 0.9234052181243896 minutes
2025-05-19 22:16:13,720:INFO:SubProcess create_model() called ==================================
2025-05-19 22:16:13,720:INFO:Initializing create_model()
2025-05-19 22:16:13,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:13,720:INFO:Checking exceptions
2025-05-19 22:16:13,721:INFO:Importing libraries
2025-05-19 22:16:13,721:INFO:Copying training dataset
2025-05-19 22:16:13,736:INFO:Defining folds
2025-05-19 22:16:13,736:INFO:Declaring metric variables
2025-05-19 22:16:13,743:INFO:Importing untrained model
2025-05-19 22:16:13,754:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 22:16:13,769:INFO:Starting cross validation
2025-05-19 22:16:13,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:17,600:INFO:Calculating mean and std
2025-05-19 22:16:17,603:INFO:Creating metrics dataframe
2025-05-19 22:16:17,609:INFO:Uploading results into container
2025-05-19 22:16:17,611:INFO:Uploading model into container now
2025-05-19 22:16:17,612:INFO:_master_model_container: 61
2025-05-19 22:16:17,612:INFO:_display_container: 5
2025-05-19 22:16:17,615:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 22:16:17,615:INFO:create_model() successfully completed......................................
2025-05-19 22:16:17,836:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:17,836:INFO:Creating metrics dataframe
2025-05-19 22:16:17,850:INFO:Initializing Dummy Classifier
2025-05-19 22:16:17,851:INFO:Total runtime is 0.9924132903416951 minutes
2025-05-19 22:16:17,856:INFO:SubProcess create_model() called ==================================
2025-05-19 22:16:17,856:INFO:Initializing create_model()
2025-05-19 22:16:17,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF14A310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:17,857:INFO:Checking exceptions
2025-05-19 22:16:17,857:INFO:Importing libraries
2025-05-19 22:16:17,857:INFO:Copying training dataset
2025-05-19 22:16:17,867:INFO:Defining folds
2025-05-19 22:16:17,867:INFO:Declaring metric variables
2025-05-19 22:16:17,874:INFO:Importing untrained model
2025-05-19 22:16:17,880:INFO:Dummy Classifier Imported successfully
2025-05-19 22:16:17,891:INFO:Starting cross validation
2025-05-19 22:16:17,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:16:20,252:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,252:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,264:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,292:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,482:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,542:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,700:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:20,753:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:21,108:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:21,139:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:16:21,156:INFO:Calculating mean and std
2025-05-19 22:16:21,157:INFO:Creating metrics dataframe
2025-05-19 22:16:21,160:INFO:Uploading results into container
2025-05-19 22:16:21,163:INFO:Uploading model into container now
2025-05-19 22:16:21,164:INFO:_master_model_container: 62
2025-05-19 22:16:21,164:INFO:_display_container: 5
2025-05-19 22:16:21,165:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 22:16:21,165:INFO:create_model() successfully completed......................................
2025-05-19 22:16:21,408:INFO:SubProcess create_model() end ==================================
2025-05-19 22:16:21,409:INFO:Creating metrics dataframe
2025-05-19 22:16:21,435:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 22:16:21,454:INFO:Initializing create_model()
2025-05-19 22:16:21,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:16:21,455:INFO:Checking exceptions
2025-05-19 22:16:21,458:INFO:Importing libraries
2025-05-19 22:16:21,459:INFO:Copying training dataset
2025-05-19 22:16:21,474:INFO:Defining folds
2025-05-19 22:16:21,474:INFO:Declaring metric variables
2025-05-19 22:16:21,475:INFO:Importing untrained model
2025-05-19 22:16:21,475:INFO:Declaring custom model
2025-05-19 22:16:21,477:INFO:Logistic Regression Imported successfully
2025-05-19 22:16:21,492:INFO:Cross validation set to False
2025-05-19 22:16:21,493:INFO:Fitting Model
2025-05-19 22:16:22,368:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-19 22:16:22,371:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.
2025-05-19 22:16:22,371:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 22:16:22,371:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 22:16:22,372:INFO:[LightGBM] [Info] Total Bins 487
2025-05-19 22:16:22,372:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-19 22:16:22,373:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-19 22:16:22,373:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-19 22:16:22,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:16:22,473:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:16:22,473:INFO:create_model() successfully completed......................................
2025-05-19 22:16:22,771:INFO:_master_model_container: 62
2025-05-19 22:16:22,771:INFO:_display_container: 5
2025-05-19 22:16:22,772:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:16:22,772:INFO:compare_models() successfully completed......................................
2025-05-19 22:20:28,906:INFO:Initializing compare_models()
2025-05-19 22:20:28,906:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 22:20:28,906:INFO:Checking exceptions
2025-05-19 22:20:28,910:INFO:Preparing display monitor
2025-05-19 22:20:28,981:INFO:Initializing Logistic Regression
2025-05-19 22:20:28,981:INFO:Total runtime is 0.0 minutes
2025-05-19 22:20:28,986:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:28,987:INFO:Initializing create_model()
2025-05-19 22:20:28,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:28,987:INFO:Checking exceptions
2025-05-19 22:20:28,987:INFO:Importing libraries
2025-05-19 22:20:28,987:INFO:Copying training dataset
2025-05-19 22:20:29,001:INFO:Defining folds
2025-05-19 22:20:29,001:INFO:Declaring metric variables
2025-05-19 22:20:29,007:INFO:Importing untrained model
2025-05-19 22:20:29,038:INFO:Logistic Regression Imported successfully
2025-05-19 22:20:29,048:INFO:Starting cross validation
2025-05-19 22:20:29,058:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:30,918:INFO:Calculating mean and std
2025-05-19 22:20:30,919:INFO:Creating metrics dataframe
2025-05-19 22:20:30,921:INFO:Uploading results into container
2025-05-19 22:20:30,922:INFO:Uploading model into container now
2025-05-19 22:20:30,922:INFO:_master_model_container: 63
2025-05-19 22:20:30,922:INFO:_display_container: 6
2025-05-19 22:20:30,923:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:20:30,924:INFO:create_model() successfully completed......................................
2025-05-19 22:20:31,104:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:31,104:INFO:Creating metrics dataframe
2025-05-19 22:20:31,112:INFO:Initializing K Neighbors Classifier
2025-05-19 22:20:31,113:INFO:Total runtime is 0.035546096165974934 minutes
2025-05-19 22:20:31,117:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:31,117:INFO:Initializing create_model()
2025-05-19 22:20:31,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:31,117:INFO:Checking exceptions
2025-05-19 22:20:31,117:INFO:Importing libraries
2025-05-19 22:20:31,117:INFO:Copying training dataset
2025-05-19 22:20:31,126:INFO:Defining folds
2025-05-19 22:20:31,127:INFO:Declaring metric variables
2025-05-19 22:20:31,132:INFO:Importing untrained model
2025-05-19 22:20:31,138:INFO:K Neighbors Classifier Imported successfully
2025-05-19 22:20:31,147:INFO:Starting cross validation
2025-05-19 22:20:31,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:33,472:INFO:Calculating mean and std
2025-05-19 22:20:33,474:INFO:Creating metrics dataframe
2025-05-19 22:20:33,478:INFO:Uploading results into container
2025-05-19 22:20:33,479:INFO:Uploading model into container now
2025-05-19 22:20:33,479:INFO:_master_model_container: 64
2025-05-19 22:20:33,479:INFO:_display_container: 6
2025-05-19 22:20:33,480:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 22:20:33,480:INFO:create_model() successfully completed......................................
2025-05-19 22:20:33,640:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:33,640:INFO:Creating metrics dataframe
2025-05-19 22:20:33,650:INFO:Initializing Naive Bayes
2025-05-19 22:20:33,650:INFO:Total runtime is 0.07781707048416138 minutes
2025-05-19 22:20:33,654:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:33,654:INFO:Initializing create_model()
2025-05-19 22:20:33,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:33,655:INFO:Checking exceptions
2025-05-19 22:20:33,655:INFO:Importing libraries
2025-05-19 22:20:33,655:INFO:Copying training dataset
2025-05-19 22:20:33,664:INFO:Defining folds
2025-05-19 22:20:33,664:INFO:Declaring metric variables
2025-05-19 22:20:33,668:INFO:Importing untrained model
2025-05-19 22:20:33,674:INFO:Naive Bayes Imported successfully
2025-05-19 22:20:33,684:INFO:Starting cross validation
2025-05-19 22:20:33,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:35,684:INFO:Calculating mean and std
2025-05-19 22:20:35,689:INFO:Creating metrics dataframe
2025-05-19 22:20:35,702:INFO:Uploading results into container
2025-05-19 22:20:35,705:INFO:Uploading model into container now
2025-05-19 22:20:35,708:INFO:_master_model_container: 65
2025-05-19 22:20:35,708:INFO:_display_container: 6
2025-05-19 22:20:35,709:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 22:20:35,709:INFO:create_model() successfully completed......................................
2025-05-19 22:20:35,867:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:35,867:INFO:Creating metrics dataframe
2025-05-19 22:20:35,877:INFO:Initializing Decision Tree Classifier
2025-05-19 22:20:35,877:INFO:Total runtime is 0.11493354241053264 minutes
2025-05-19 22:20:35,880:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:35,880:INFO:Initializing create_model()
2025-05-19 22:20:35,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:35,881:INFO:Checking exceptions
2025-05-19 22:20:35,881:INFO:Importing libraries
2025-05-19 22:20:35,881:INFO:Copying training dataset
2025-05-19 22:20:35,889:INFO:Defining folds
2025-05-19 22:20:35,889:INFO:Declaring metric variables
2025-05-19 22:20:35,893:INFO:Importing untrained model
2025-05-19 22:20:35,898:INFO:Decision Tree Classifier Imported successfully
2025-05-19 22:20:35,905:INFO:Starting cross validation
2025-05-19 22:20:35,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:38,002:INFO:Calculating mean and std
2025-05-19 22:20:38,004:INFO:Creating metrics dataframe
2025-05-19 22:20:38,006:INFO:Uploading results into container
2025-05-19 22:20:38,007:INFO:Uploading model into container now
2025-05-19 22:20:38,008:INFO:_master_model_container: 66
2025-05-19 22:20:38,008:INFO:_display_container: 6
2025-05-19 22:20:38,009:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 22:20:38,010:INFO:create_model() successfully completed......................................
2025-05-19 22:20:38,255:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:38,255:INFO:Creating metrics dataframe
2025-05-19 22:20:38,266:INFO:Initializing SVM - Linear Kernel
2025-05-19 22:20:38,267:INFO:Total runtime is 0.1547549525896708 minutes
2025-05-19 22:20:38,271:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:38,271:INFO:Initializing create_model()
2025-05-19 22:20:38,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:38,272:INFO:Checking exceptions
2025-05-19 22:20:38,272:INFO:Importing libraries
2025-05-19 22:20:38,272:INFO:Copying training dataset
2025-05-19 22:20:38,282:INFO:Defining folds
2025-05-19 22:20:38,282:INFO:Declaring metric variables
2025-05-19 22:20:38,288:INFO:Importing untrained model
2025-05-19 22:20:38,295:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 22:20:38,305:INFO:Starting cross validation
2025-05-19 22:20:38,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:40,209:INFO:Calculating mean and std
2025-05-19 22:20:40,211:INFO:Creating metrics dataframe
2025-05-19 22:20:40,215:INFO:Uploading results into container
2025-05-19 22:20:40,216:INFO:Uploading model into container now
2025-05-19 22:20:40,217:INFO:_master_model_container: 67
2025-05-19 22:20:40,217:INFO:_display_container: 6
2025-05-19 22:20:40,218:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 22:20:40,218:INFO:create_model() successfully completed......................................
2025-05-19 22:20:40,375:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:40,375:INFO:Creating metrics dataframe
2025-05-19 22:20:40,384:INFO:Initializing Ridge Classifier
2025-05-19 22:20:40,385:INFO:Total runtime is 0.19006662766138713 minutes
2025-05-19 22:20:40,389:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:40,389:INFO:Initializing create_model()
2025-05-19 22:20:40,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:40,389:INFO:Checking exceptions
2025-05-19 22:20:40,389:INFO:Importing libraries
2025-05-19 22:20:40,390:INFO:Copying training dataset
2025-05-19 22:20:40,399:INFO:Defining folds
2025-05-19 22:20:40,399:INFO:Declaring metric variables
2025-05-19 22:20:40,403:INFO:Importing untrained model
2025-05-19 22:20:40,409:INFO:Ridge Classifier Imported successfully
2025-05-19 22:20:40,419:INFO:Starting cross validation
2025-05-19 22:20:40,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:42,611:INFO:Calculating mean and std
2025-05-19 22:20:42,613:INFO:Creating metrics dataframe
2025-05-19 22:20:42,618:INFO:Uploading results into container
2025-05-19 22:20:42,618:INFO:Uploading model into container now
2025-05-19 22:20:42,619:INFO:_master_model_container: 68
2025-05-19 22:20:42,619:INFO:_display_container: 6
2025-05-19 22:20:42,620:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 22:20:42,621:INFO:create_model() successfully completed......................................
2025-05-19 22:20:42,805:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:42,806:INFO:Creating metrics dataframe
2025-05-19 22:20:42,822:INFO:Initializing Random Forest Classifier
2025-05-19 22:20:42,822:INFO:Total runtime is 0.23068821032842002 minutes
2025-05-19 22:20:42,827:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:42,828:INFO:Initializing create_model()
2025-05-19 22:20:42,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:42,829:INFO:Checking exceptions
2025-05-19 22:20:42,829:INFO:Importing libraries
2025-05-19 22:20:42,829:INFO:Copying training dataset
2025-05-19 22:20:42,839:INFO:Defining folds
2025-05-19 22:20:42,839:INFO:Declaring metric variables
2025-05-19 22:20:42,846:INFO:Importing untrained model
2025-05-19 22:20:42,851:INFO:Random Forest Classifier Imported successfully
2025-05-19 22:20:42,863:INFO:Starting cross validation
2025-05-19 22:20:42,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:46,036:INFO:Calculating mean and std
2025-05-19 22:20:46,038:INFO:Creating metrics dataframe
2025-05-19 22:20:46,041:INFO:Uploading results into container
2025-05-19 22:20:46,042:INFO:Uploading model into container now
2025-05-19 22:20:46,043:INFO:_master_model_container: 69
2025-05-19 22:20:46,043:INFO:_display_container: 6
2025-05-19 22:20:46,045:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 22:20:46,045:INFO:create_model() successfully completed......................................
2025-05-19 22:20:46,200:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:46,200:INFO:Creating metrics dataframe
2025-05-19 22:20:46,210:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 22:20:46,211:INFO:Total runtime is 0.28717165390650434 minutes
2025-05-19 22:20:46,215:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:46,215:INFO:Initializing create_model()
2025-05-19 22:20:46,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:46,216:INFO:Checking exceptions
2025-05-19 22:20:46,216:INFO:Importing libraries
2025-05-19 22:20:46,216:INFO:Copying training dataset
2025-05-19 22:20:46,224:INFO:Defining folds
2025-05-19 22:20:46,224:INFO:Declaring metric variables
2025-05-19 22:20:46,232:INFO:Importing untrained model
2025-05-19 22:20:46,236:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 22:20:46,246:INFO:Starting cross validation
2025-05-19 22:20:46,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:47,311:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,311:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,322:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,344:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,410:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,570:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,611:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:47,715:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:48,140:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:48,175:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 22:20:48,308:INFO:Calculating mean and std
2025-05-19 22:20:48,311:INFO:Creating metrics dataframe
2025-05-19 22:20:48,314:INFO:Uploading results into container
2025-05-19 22:20:48,315:INFO:Uploading model into container now
2025-05-19 22:20:48,316:INFO:_master_model_container: 70
2025-05-19 22:20:48,316:INFO:_display_container: 6
2025-05-19 22:20:48,317:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 22:20:48,317:INFO:create_model() successfully completed......................................
2025-05-19 22:20:48,563:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:48,563:INFO:Creating metrics dataframe
2025-05-19 22:20:48,580:INFO:Initializing Ada Boost Classifier
2025-05-19 22:20:48,580:INFO:Total runtime is 0.3266499161720276 minutes
2025-05-19 22:20:48,586:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:48,587:INFO:Initializing create_model()
2025-05-19 22:20:48,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:48,587:INFO:Checking exceptions
2025-05-19 22:20:48,587:INFO:Importing libraries
2025-05-19 22:20:48,587:INFO:Copying training dataset
2025-05-19 22:20:48,598:INFO:Defining folds
2025-05-19 22:20:48,599:INFO:Declaring metric variables
2025-05-19 22:20:48,605:INFO:Importing untrained model
2025-05-19 22:20:48,613:INFO:Ada Boost Classifier Imported successfully
2025-05-19 22:20:48,622:INFO:Starting cross validation
2025-05-19 22:20:48,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:49,918:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:49,944:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,111:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,284:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,380:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,460:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,506:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,803:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:50,885:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 22:20:51,008:INFO:Calculating mean and std
2025-05-19 22:20:51,010:INFO:Creating metrics dataframe
2025-05-19 22:20:51,013:INFO:Uploading results into container
2025-05-19 22:20:51,014:INFO:Uploading model into container now
2025-05-19 22:20:51,015:INFO:_master_model_container: 71
2025-05-19 22:20:51,015:INFO:_display_container: 6
2025-05-19 22:20:51,016:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 22:20:51,016:INFO:create_model() successfully completed......................................
2025-05-19 22:20:51,175:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:51,176:INFO:Creating metrics dataframe
2025-05-19 22:20:51,195:INFO:Initializing Gradient Boosting Classifier
2025-05-19 22:20:51,195:INFO:Total runtime is 0.37024121681849165 minutes
2025-05-19 22:20:51,199:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:51,199:INFO:Initializing create_model()
2025-05-19 22:20:51,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:51,200:INFO:Checking exceptions
2025-05-19 22:20:51,200:INFO:Importing libraries
2025-05-19 22:20:51,200:INFO:Copying training dataset
2025-05-19 22:20:51,208:INFO:Defining folds
2025-05-19 22:20:51,209:INFO:Declaring metric variables
2025-05-19 22:20:51,214:INFO:Importing untrained model
2025-05-19 22:20:51,221:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 22:20:51,233:INFO:Starting cross validation
2025-05-19 22:20:51,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:53,840:INFO:Calculating mean and std
2025-05-19 22:20:53,842:INFO:Creating metrics dataframe
2025-05-19 22:20:53,844:INFO:Uploading results into container
2025-05-19 22:20:53,845:INFO:Uploading model into container now
2025-05-19 22:20:53,846:INFO:_master_model_container: 72
2025-05-19 22:20:53,846:INFO:_display_container: 6
2025-05-19 22:20:53,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 22:20:53,847:INFO:create_model() successfully completed......................................
2025-05-19 22:20:53,989:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:53,989:INFO:Creating metrics dataframe
2025-05-19 22:20:54,000:INFO:Initializing Linear Discriminant Analysis
2025-05-19 22:20:54,000:INFO:Total runtime is 0.41698950131734214 minutes
2025-05-19 22:20:54,003:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:54,004:INFO:Initializing create_model()
2025-05-19 22:20:54,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:54,004:INFO:Checking exceptions
2025-05-19 22:20:54,004:INFO:Importing libraries
2025-05-19 22:20:54,004:INFO:Copying training dataset
2025-05-19 22:20:54,013:INFO:Defining folds
2025-05-19 22:20:54,013:INFO:Declaring metric variables
2025-05-19 22:20:54,017:INFO:Importing untrained model
2025-05-19 22:20:54,022:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 22:20:54,031:INFO:Starting cross validation
2025-05-19 22:20:54,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:55,959:INFO:Calculating mean and std
2025-05-19 22:20:55,965:INFO:Creating metrics dataframe
2025-05-19 22:20:55,976:INFO:Uploading results into container
2025-05-19 22:20:55,979:INFO:Uploading model into container now
2025-05-19 22:20:55,981:INFO:_master_model_container: 73
2025-05-19 22:20:55,982:INFO:_display_container: 6
2025-05-19 22:20:55,984:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 22:20:55,985:INFO:create_model() successfully completed......................................
2025-05-19 22:20:56,164:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:56,164:INFO:Creating metrics dataframe
2025-05-19 22:20:56,177:INFO:Initializing Extra Trees Classifier
2025-05-19 22:20:56,177:INFO:Total runtime is 0.45327957471211755 minutes
2025-05-19 22:20:56,182:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:56,183:INFO:Initializing create_model()
2025-05-19 22:20:56,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:56,183:INFO:Checking exceptions
2025-05-19 22:20:56,183:INFO:Importing libraries
2025-05-19 22:20:56,183:INFO:Copying training dataset
2025-05-19 22:20:56,194:INFO:Defining folds
2025-05-19 22:20:56,194:INFO:Declaring metric variables
2025-05-19 22:20:56,200:INFO:Importing untrained model
2025-05-19 22:20:56,205:INFO:Extra Trees Classifier Imported successfully
2025-05-19 22:20:56,219:INFO:Starting cross validation
2025-05-19 22:20:56,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:20:59,534:INFO:Calculating mean and std
2025-05-19 22:20:59,536:INFO:Creating metrics dataframe
2025-05-19 22:20:59,541:INFO:Uploading results into container
2025-05-19 22:20:59,543:INFO:Uploading model into container now
2025-05-19 22:20:59,544:INFO:_master_model_container: 74
2025-05-19 22:20:59,545:INFO:_display_container: 6
2025-05-19 22:20:59,546:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 22:20:59,546:INFO:create_model() successfully completed......................................
2025-05-19 22:20:59,720:INFO:SubProcess create_model() end ==================================
2025-05-19 22:20:59,720:INFO:Creating metrics dataframe
2025-05-19 22:20:59,735:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 22:20:59,735:INFO:Total runtime is 0.512578010559082 minutes
2025-05-19 22:20:59,741:INFO:SubProcess create_model() called ==================================
2025-05-19 22:20:59,742:INFO:Initializing create_model()
2025-05-19 22:20:59,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:20:59,742:INFO:Checking exceptions
2025-05-19 22:20:59,743:INFO:Importing libraries
2025-05-19 22:20:59,743:INFO:Copying training dataset
2025-05-19 22:20:59,753:INFO:Defining folds
2025-05-19 22:20:59,753:INFO:Declaring metric variables
2025-05-19 22:20:59,759:INFO:Importing untrained model
2025-05-19 22:20:59,766:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 22:20:59,780:INFO:Starting cross validation
2025-05-19 22:20:59,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:21:03,203:INFO:Calculating mean and std
2025-05-19 22:21:03,207:INFO:Creating metrics dataframe
2025-05-19 22:21:03,215:INFO:Uploading results into container
2025-05-19 22:21:03,216:INFO:Uploading model into container now
2025-05-19 22:21:03,217:INFO:_master_model_container: 75
2025-05-19 22:21:03,217:INFO:_display_container: 6
2025-05-19 22:21:03,219:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 22:21:03,219:INFO:create_model() successfully completed......................................
2025-05-19 22:21:03,453:INFO:SubProcess create_model() end ==================================
2025-05-19 22:21:03,453:INFO:Creating metrics dataframe
2025-05-19 22:21:03,477:INFO:Initializing Dummy Classifier
2025-05-19 22:21:03,478:INFO:Total runtime is 0.5749492406845093 minutes
2025-05-19 22:21:03,484:INFO:SubProcess create_model() called ==================================
2025-05-19 22:21:03,485:INFO:Initializing create_model()
2025-05-19 22:21:03,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000186DF824310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:21:03,485:INFO:Checking exceptions
2025-05-19 22:21:03,485:INFO:Importing libraries
2025-05-19 22:21:03,485:INFO:Copying training dataset
2025-05-19 22:21:03,497:INFO:Defining folds
2025-05-19 22:21:03,497:INFO:Declaring metric variables
2025-05-19 22:21:03,507:INFO:Importing untrained model
2025-05-19 22:21:03,518:INFO:Dummy Classifier Imported successfully
2025-05-19 22:21:03,534:INFO:Starting cross validation
2025-05-19 22:21:03,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 22:21:05,134:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,140:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,303:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,480:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,519:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,642:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:05,649:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:06,195:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:06,288:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 22:21:06,322:INFO:Calculating mean and std
2025-05-19 22:21:06,344:INFO:Creating metrics dataframe
2025-05-19 22:21:06,351:INFO:Uploading results into container
2025-05-19 22:21:06,352:INFO:Uploading model into container now
2025-05-19 22:21:06,354:INFO:_master_model_container: 76
2025-05-19 22:21:06,355:INFO:_display_container: 6
2025-05-19 22:21:06,355:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 22:21:06,356:INFO:create_model() successfully completed......................................
2025-05-19 22:21:06,716:INFO:SubProcess create_model() end ==================================
2025-05-19 22:21:06,717:INFO:Creating metrics dataframe
2025-05-19 22:21:06,748:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 22:21:06,773:INFO:Initializing create_model()
2025-05-19 22:21:06,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000186DD0C8B50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 22:21:06,777:INFO:Checking exceptions
2025-05-19 22:21:06,781:INFO:Importing libraries
2025-05-19 22:21:06,781:INFO:Copying training dataset
2025-05-19 22:21:06,819:INFO:Defining folds
2025-05-19 22:21:06,820:INFO:Declaring metric variables
2025-05-19 22:21:06,820:INFO:Importing untrained model
2025-05-19 22:21:06,820:INFO:Declaring custom model
2025-05-19 22:21:06,826:INFO:Logistic Regression Imported successfully
2025-05-19 22:21:06,852:INFO:Cross validation set to False
2025-05-19 22:21:06,852:INFO:Fitting Model
2025-05-19 22:21:07,350:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-19 22:21:07,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000786 seconds.
2025-05-19 22:21:07,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 22:21:07,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 22:21:07,353:INFO:[LightGBM] [Info] Total Bins 487
2025-05-19 22:21:07,353:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-19 22:21:07,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-19 22:21:07,353:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-19 22:21:07,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 22:21:07,453:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:21:07,453:INFO:create_model() successfully completed......................................
2025-05-19 22:21:07,764:INFO:_master_model_container: 76
2025-05-19 22:21:07,764:INFO:_display_container: 6
2025-05-19 22:21:07,765:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 22:21:07,766:INFO:compare_models() successfully completed......................................
2025-05-24 22:49:05,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 22:49:05,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 22:49:05,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 22:49:05,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 22:50:15,710:INFO:PyCaret ClassificationExperiment
2025-05-24 22:50:15,710:INFO:Logging name: clf-default-name
2025-05-24 22:50:15,710:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 22:50:15,710:INFO:version 3.3.2
2025-05-24 22:50:15,710:INFO:Initializing setup()
2025-05-24 22:50:15,710:INFO:self.USI: 164a
2025-05-24 22:50:15,711:INFO:self._variable_keys: {'gpu_n_jobs_param', 'html_param', 'fold_groups_param', 'logging_param', 'y', '_available_plots', 'X_train', 'fix_imbalance', 'target_param', 'log_plots_param', 'seed', 'y_test', 'is_multiclass', 'X_test', 'pipeline', 'data', 'gpu_param', '_ml_usecase', 'USI', 'n_jobs_param', 'idx', 'exp_id', 'memory', 'fold_shuffle_param', 'y_train', 'fold_generator', 'X', 'exp_name_log'}
2025-05-24 22:50:15,711:INFO:Checking environment
2025-05-24 22:50:15,711:INFO:python_version: 3.11.0
2025-05-24 22:50:15,711:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-24 22:50:15,711:INFO:machine: AMD64
2025-05-24 22:50:15,711:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-24 22:50:15,716:INFO:Memory: svmem(total=12759322624, available=1267707904, percent=90.1, used=11491614720, free=1267707904)
2025-05-24 22:50:15,716:INFO:Physical Core: 4
2025-05-24 22:50:15,716:INFO:Logical Core: 8
2025-05-24 22:50:15,717:INFO:Checking libraries
2025-05-24 22:50:15,717:INFO:System:
2025-05-24 22:50:15,717:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-24 22:50:15,717:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-24 22:50:15,717:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-24 22:50:15,717:INFO:PyCaret required dependencies:
2025-05-24 22:50:15,821:INFO:                 pip: 22.3
2025-05-24 22:50:15,821:INFO:          setuptools: 65.5.0
2025-05-24 22:50:15,821:INFO:             pycaret: 3.3.2
2025-05-24 22:50:15,821:INFO:             IPython: 9.2.0
2025-05-24 22:50:15,821:INFO:          ipywidgets: 8.1.7
2025-05-24 22:50:15,821:INFO:                tqdm: 4.67.1
2025-05-24 22:50:15,821:INFO:               numpy: 1.26.4
2025-05-24 22:50:15,821:INFO:              pandas: 2.1.4
2025-05-24 22:50:15,821:INFO:              jinja2: 3.1.6
2025-05-24 22:50:15,821:INFO:               scipy: 1.11.4
2025-05-24 22:50:15,822:INFO:              joblib: 1.3.2
2025-05-24 22:50:15,822:INFO:             sklearn: 1.4.2
2025-05-24 22:50:15,822:INFO:                pyod: 2.0.5
2025-05-24 22:50:15,822:INFO:            imblearn: 0.13.0
2025-05-24 22:50:16,122:INFO:   category_encoders: 2.7.0
2025-05-24 22:50:16,122:INFO:            lightgbm: 4.6.0
2025-05-24 22:50:16,122:INFO:               numba: 0.61.2
2025-05-24 22:50:16,122:INFO:            requests: 2.32.3
2025-05-24 22:50:16,122:INFO:          matplotlib: 3.7.5
2025-05-24 22:50:16,122:INFO:          scikitplot: 0.3.7
2025-05-24 22:50:16,122:INFO:         yellowbrick: 1.5
2025-05-24 22:50:16,122:INFO:              plotly: 5.24.1
2025-05-24 22:50:16,122:INFO:    plotly-resampler: Not installed
2025-05-24 22:50:16,122:INFO:             kaleido: 0.2.1
2025-05-24 22:50:16,123:INFO:           schemdraw: 0.15
2025-05-24 22:50:16,123:INFO:         statsmodels: 0.14.4
2025-05-24 22:50:16,123:INFO:              sktime: 0.26.0
2025-05-24 22:50:16,123:INFO:               tbats: 1.1.3
2025-05-24 22:50:16,123:INFO:            pmdarima: 2.0.4
2025-05-24 22:50:16,123:INFO:              psutil: 7.0.0
2025-05-24 22:50:16,123:INFO:          markupsafe: 3.0.2
2025-05-24 22:50:16,123:INFO:             pickle5: Not installed
2025-05-24 22:50:16,123:INFO:         cloudpickle: 3.1.1
2025-05-24 22:50:16,123:INFO:         deprecation: 2.1.0
2025-05-24 22:50:16,123:INFO:              xxhash: 3.5.0
2025-05-24 22:50:16,123:INFO:           wurlitzer: Not installed
2025-05-24 22:50:16,123:INFO:PyCaret optional dependencies:
2025-05-24 22:50:16,136:INFO:                shap: Not installed
2025-05-24 22:50:16,136:INFO:           interpret: Not installed
2025-05-24 22:50:16,136:INFO:                umap: Not installed
2025-05-24 22:50:16,136:INFO:     ydata_profiling: Not installed
2025-05-24 22:50:16,136:INFO:  explainerdashboard: Not installed
2025-05-24 22:50:16,136:INFO:             autoviz: Not installed
2025-05-24 22:50:16,137:INFO:           fairlearn: Not installed
2025-05-24 22:50:16,137:INFO:          deepchecks: Not installed
2025-05-24 22:50:16,137:INFO:             xgboost: Not installed
2025-05-24 22:50:16,137:INFO:            catboost: Not installed
2025-05-24 22:50:16,137:INFO:              kmodes: Not installed
2025-05-24 22:50:16,137:INFO:             mlxtend: Not installed
2025-05-24 22:50:16,137:INFO:       statsforecast: Not installed
2025-05-24 22:50:16,137:INFO:        tune_sklearn: Not installed
2025-05-24 22:50:16,137:INFO:                 ray: Not installed
2025-05-24 22:50:16,137:INFO:            hyperopt: Not installed
2025-05-24 22:50:16,137:INFO:              optuna: Not installed
2025-05-24 22:50:16,137:INFO:               skopt: Not installed
2025-05-24 22:50:16,137:INFO:              mlflow: Not installed
2025-05-24 22:50:16,137:INFO:              gradio: Not installed
2025-05-24 22:50:16,137:INFO:             fastapi: Not installed
2025-05-24 22:50:16,137:INFO:             uvicorn: Not installed
2025-05-24 22:50:16,138:INFO:              m2cgen: Not installed
2025-05-24 22:50:16,138:INFO:           evidently: Not installed
2025-05-24 22:50:16,138:INFO:               fugue: Not installed
2025-05-24 22:50:16,138:INFO:           streamlit: Not installed
2025-05-24 22:50:16,138:INFO:             prophet: Not installed
2025-05-24 22:50:16,138:INFO:None
2025-05-24 22:50:16,138:INFO:Set up data.
2025-05-24 22:50:16,156:INFO:Set up folding strategy.
2025-05-24 22:50:16,156:INFO:Set up train/test split.
2025-05-24 22:50:16,200:INFO:Set up index.
2025-05-24 22:50:16,202:INFO:Assigning column types.
2025-05-24 22:50:16,206:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 22:50:16,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,254:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,345:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 22:50:16,420:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,491:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 22:50:16,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,519:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 22:50:16,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,669:INFO:Preparing preprocessing pipeline...
2025-05-24 22:50:16,671:INFO:Set up simple imputation.
2025-05-24 22:50:16,675:INFO:Set up encoding of categorical features.
2025-05-24 22:50:16,675:INFO:Set up removing multicollinearity.
2025-05-24 22:50:16,675:INFO:Set up column transformation.
2025-05-24 22:50:16,675:INFO:Set up feature normalization.
2025-05-24 22:50:16,675:INFO:Set up feature selection.
2025-05-24 22:50:16,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:16,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:17,546:INFO:Finished creating preprocessing pipeline.
2025-05-24 22:50:17,568:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'numero_productos',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal',
                                             'indice_digital'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-24 22:50:17,568:INFO:Creating final display dataframe.
2025-05-24 22:50:17,822:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target    cerrara_cuenta
2                   Target type            Binary
3           Original data shape        (5000, 18)
4        Transformed data shape         (5000, 3)
5   Transformed train set shape         (3500, 3)
6    Transformed test set shape         (1500, 3)
7               Ignore features                 4
8              Numeric features                 6
9          Categorical features                 6
10     Rows with missing values              1.7%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Transformation              True
20        Transformation method       yeo-johnson
21                    Normalize              True
22             Normalize method            zscore
23            Feature selection              True
24     Feature selection method           classic
25  Feature selection estimator          lightgbm
26  Number of features selected               0.2
27               Fold Generator   StratifiedKFold
28                  Fold Number                10
29                     CPU Jobs                -1
30                      Use GPU             False
31               Log Experiment             False
32              Experiment Name  clf-default-name
33                          USI              164a
2025-05-24 22:50:17,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:17,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:18,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:18,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 22:50:18,040:INFO:setup() successfully completed in 2.35s...............
2025-05-24 22:50:24,107:INFO:Initializing compare_models()
2025-05-24 22:50:24,107:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-24 22:50:24,108:INFO:Checking exceptions
2025-05-24 22:50:24,117:INFO:Preparing display monitor
2025-05-24 22:50:24,157:INFO:Initializing Logistic Regression
2025-05-24 22:50:24,157:INFO:Total runtime is 0.0 minutes
2025-05-24 22:50:24,163:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:24,163:INFO:Initializing create_model()
2025-05-24 22:50:24,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:24,164:INFO:Checking exceptions
2025-05-24 22:50:24,164:INFO:Importing libraries
2025-05-24 22:50:24,164:INFO:Copying training dataset
2025-05-24 22:50:24,175:INFO:Defining folds
2025-05-24 22:50:24,175:INFO:Declaring metric variables
2025-05-24 22:50:24,181:INFO:Importing untrained model
2025-05-24 22:50:24,188:INFO:Logistic Regression Imported successfully
2025-05-24 22:50:24,235:INFO:Starting cross validation
2025-05-24 22:50:24,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:33,364:INFO:Calculating mean and std
2025-05-24 22:50:33,369:INFO:Creating metrics dataframe
2025-05-24 22:50:33,377:INFO:Uploading results into container
2025-05-24 22:50:33,379:INFO:Uploading model into container now
2025-05-24 22:50:33,381:INFO:_master_model_container: 1
2025-05-24 22:50:33,382:INFO:_display_container: 2
2025-05-24 22:50:33,383:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:50:33,384:INFO:create_model() successfully completed......................................
2025-05-24 22:50:33,495:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:33,495:INFO:Creating metrics dataframe
2025-05-24 22:50:33,504:INFO:Initializing K Neighbors Classifier
2025-05-24 22:50:33,504:INFO:Total runtime is 0.1557793656984965 minutes
2025-05-24 22:50:33,508:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:33,508:INFO:Initializing create_model()
2025-05-24 22:50:33,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:33,508:INFO:Checking exceptions
2025-05-24 22:50:33,508:INFO:Importing libraries
2025-05-24 22:50:33,508:INFO:Copying training dataset
2025-05-24 22:50:33,515:INFO:Defining folds
2025-05-24 22:50:33,515:INFO:Declaring metric variables
2025-05-24 22:50:33,520:INFO:Importing untrained model
2025-05-24 22:50:33,525:INFO:K Neighbors Classifier Imported successfully
2025-05-24 22:50:33,531:INFO:Starting cross validation
2025-05-24 22:50:33,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:35,314:INFO:Calculating mean and std
2025-05-24 22:50:35,318:INFO:Creating metrics dataframe
2025-05-24 22:50:35,329:INFO:Uploading results into container
2025-05-24 22:50:35,331:INFO:Uploading model into container now
2025-05-24 22:50:35,333:INFO:_master_model_container: 2
2025-05-24 22:50:35,333:INFO:_display_container: 2
2025-05-24 22:50:35,335:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-24 22:50:35,336:INFO:create_model() successfully completed......................................
2025-05-24 22:50:35,414:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:35,414:INFO:Creating metrics dataframe
2025-05-24 22:50:35,423:INFO:Initializing Naive Bayes
2025-05-24 22:50:35,423:INFO:Total runtime is 0.18776166439056396 minutes
2025-05-24 22:50:35,428:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:35,428:INFO:Initializing create_model()
2025-05-24 22:50:35,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:35,429:INFO:Checking exceptions
2025-05-24 22:50:35,429:INFO:Importing libraries
2025-05-24 22:50:35,429:INFO:Copying training dataset
2025-05-24 22:50:35,437:INFO:Defining folds
2025-05-24 22:50:35,437:INFO:Declaring metric variables
2025-05-24 22:50:35,447:INFO:Importing untrained model
2025-05-24 22:50:35,484:INFO:Naive Bayes Imported successfully
2025-05-24 22:50:35,493:INFO:Starting cross validation
2025-05-24 22:50:35,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:37,316:INFO:Calculating mean and std
2025-05-24 22:50:37,318:INFO:Creating metrics dataframe
2025-05-24 22:50:37,321:INFO:Uploading results into container
2025-05-24 22:50:37,322:INFO:Uploading model into container now
2025-05-24 22:50:37,323:INFO:_master_model_container: 3
2025-05-24 22:50:37,323:INFO:_display_container: 2
2025-05-24 22:50:37,323:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-24 22:50:37,323:INFO:create_model() successfully completed......................................
2025-05-24 22:50:37,401:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:37,401:INFO:Creating metrics dataframe
2025-05-24 22:50:37,410:INFO:Initializing Decision Tree Classifier
2025-05-24 22:50:37,410:INFO:Total runtime is 0.2208824038505554 minutes
2025-05-24 22:50:37,414:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:37,414:INFO:Initializing create_model()
2025-05-24 22:50:37,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:37,414:INFO:Checking exceptions
2025-05-24 22:50:37,415:INFO:Importing libraries
2025-05-24 22:50:37,415:INFO:Copying training dataset
2025-05-24 22:50:37,423:INFO:Defining folds
2025-05-24 22:50:37,423:INFO:Declaring metric variables
2025-05-24 22:50:37,427:INFO:Importing untrained model
2025-05-24 22:50:37,433:INFO:Decision Tree Classifier Imported successfully
2025-05-24 22:50:37,442:INFO:Starting cross validation
2025-05-24 22:50:37,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:39,875:INFO:Calculating mean and std
2025-05-24 22:50:39,878:INFO:Creating metrics dataframe
2025-05-24 22:50:39,884:INFO:Uploading results into container
2025-05-24 22:50:39,886:INFO:Uploading model into container now
2025-05-24 22:50:39,888:INFO:_master_model_container: 4
2025-05-24 22:50:39,889:INFO:_display_container: 2
2025-05-24 22:50:39,889:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-24 22:50:39,889:INFO:create_model() successfully completed......................................
2025-05-24 22:50:39,977:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:39,977:INFO:Creating metrics dataframe
2025-05-24 22:50:39,991:INFO:Initializing SVM - Linear Kernel
2025-05-24 22:50:39,991:INFO:Total runtime is 0.26390508413314817 minutes
2025-05-24 22:50:39,997:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:39,997:INFO:Initializing create_model()
2025-05-24 22:50:39,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:39,997:INFO:Checking exceptions
2025-05-24 22:50:39,998:INFO:Importing libraries
2025-05-24 22:50:39,998:INFO:Copying training dataset
2025-05-24 22:50:40,007:INFO:Defining folds
2025-05-24 22:50:40,007:INFO:Declaring metric variables
2025-05-24 22:50:40,012:INFO:Importing untrained model
2025-05-24 22:50:40,017:INFO:SVM - Linear Kernel Imported successfully
2025-05-24 22:50:40,028:INFO:Starting cross validation
2025-05-24 22:50:40,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:42,056:INFO:Calculating mean and std
2025-05-24 22:50:42,060:INFO:Creating metrics dataframe
2025-05-24 22:50:42,065:INFO:Uploading results into container
2025-05-24 22:50:42,066:INFO:Uploading model into container now
2025-05-24 22:50:42,069:INFO:_master_model_container: 5
2025-05-24 22:50:42,069:INFO:_display_container: 2
2025-05-24 22:50:42,071:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-24 22:50:42,071:INFO:create_model() successfully completed......................................
2025-05-24 22:50:42,150:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:42,150:INFO:Creating metrics dataframe
2025-05-24 22:50:42,161:INFO:Initializing Ridge Classifier
2025-05-24 22:50:42,161:INFO:Total runtime is 0.3000671625137329 minutes
2025-05-24 22:50:42,165:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:42,165:INFO:Initializing create_model()
2025-05-24 22:50:42,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:42,166:INFO:Checking exceptions
2025-05-24 22:50:42,166:INFO:Importing libraries
2025-05-24 22:50:42,166:INFO:Copying training dataset
2025-05-24 22:50:42,176:INFO:Defining folds
2025-05-24 22:50:42,176:INFO:Declaring metric variables
2025-05-24 22:50:42,181:INFO:Importing untrained model
2025-05-24 22:50:42,189:INFO:Ridge Classifier Imported successfully
2025-05-24 22:50:42,197:INFO:Starting cross validation
2025-05-24 22:50:42,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:44,414:INFO:Calculating mean and std
2025-05-24 22:50:44,416:INFO:Creating metrics dataframe
2025-05-24 22:50:44,420:INFO:Uploading results into container
2025-05-24 22:50:44,422:INFO:Uploading model into container now
2025-05-24 22:50:44,422:INFO:_master_model_container: 6
2025-05-24 22:50:44,422:INFO:_display_container: 2
2025-05-24 22:50:44,423:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-24 22:50:44,423:INFO:create_model() successfully completed......................................
2025-05-24 22:50:44,503:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:44,503:INFO:Creating metrics dataframe
2025-05-24 22:50:44,514:INFO:Initializing Random Forest Classifier
2025-05-24 22:50:44,514:INFO:Total runtime is 0.33927617867787674 minutes
2025-05-24 22:50:44,520:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:44,520:INFO:Initializing create_model()
2025-05-24 22:50:44,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:44,520:INFO:Checking exceptions
2025-05-24 22:50:44,520:INFO:Importing libraries
2025-05-24 22:50:44,520:INFO:Copying training dataset
2025-05-24 22:50:44,528:INFO:Defining folds
2025-05-24 22:50:44,529:INFO:Declaring metric variables
2025-05-24 22:50:44,534:INFO:Importing untrained model
2025-05-24 22:50:44,541:INFO:Random Forest Classifier Imported successfully
2025-05-24 22:50:44,552:INFO:Starting cross validation
2025-05-24 22:50:44,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:47,534:INFO:Calculating mean and std
2025-05-24 22:50:47,536:INFO:Creating metrics dataframe
2025-05-24 22:50:47,539:INFO:Uploading results into container
2025-05-24 22:50:47,540:INFO:Uploading model into container now
2025-05-24 22:50:47,540:INFO:_master_model_container: 7
2025-05-24 22:50:47,540:INFO:_display_container: 2
2025-05-24 22:50:47,541:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-24 22:50:47,541:INFO:create_model() successfully completed......................................
2025-05-24 22:50:47,622:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:47,622:INFO:Creating metrics dataframe
2025-05-24 22:50:47,633:INFO:Initializing Quadratic Discriminant Analysis
2025-05-24 22:50:47,634:INFO:Total runtime is 0.39127768278121944 minutes
2025-05-24 22:50:47,639:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:47,639:INFO:Initializing create_model()
2025-05-24 22:50:47,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:47,640:INFO:Checking exceptions
2025-05-24 22:50:47,640:INFO:Importing libraries
2025-05-24 22:50:47,640:INFO:Copying training dataset
2025-05-24 22:50:47,648:INFO:Defining folds
2025-05-24 22:50:47,648:INFO:Declaring metric variables
2025-05-24 22:50:47,652:INFO:Importing untrained model
2025-05-24 22:50:47,659:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-24 22:50:47,667:INFO:Starting cross validation
2025-05-24 22:50:47,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:48,938:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:48,939:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:48,959:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:48,970:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:49,016:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:49,195:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:49,662:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:49,670:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:50:49,793:INFO:Calculating mean and std
2025-05-24 22:50:49,795:INFO:Creating metrics dataframe
2025-05-24 22:50:49,797:INFO:Uploading results into container
2025-05-24 22:50:49,798:INFO:Uploading model into container now
2025-05-24 22:50:49,799:INFO:_master_model_container: 8
2025-05-24 22:50:49,799:INFO:_display_container: 2
2025-05-24 22:50:49,799:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-24 22:50:49,799:INFO:create_model() successfully completed......................................
2025-05-24 22:50:49,881:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:49,881:INFO:Creating metrics dataframe
2025-05-24 22:50:49,893:INFO:Initializing Ada Boost Classifier
2025-05-24 22:50:49,893:INFO:Total runtime is 0.42892771561940507 minutes
2025-05-24 22:50:49,898:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:49,898:INFO:Initializing create_model()
2025-05-24 22:50:49,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:49,899:INFO:Checking exceptions
2025-05-24 22:50:49,899:INFO:Importing libraries
2025-05-24 22:50:49,899:INFO:Copying training dataset
2025-05-24 22:50:49,910:INFO:Defining folds
2025-05-24 22:50:49,910:INFO:Declaring metric variables
2025-05-24 22:50:49,915:INFO:Importing untrained model
2025-05-24 22:50:49,923:INFO:Ada Boost Classifier Imported successfully
2025-05-24 22:50:49,933:INFO:Starting cross validation
2025-05-24 22:50:49,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:50,994:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:50,994:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:50,995:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,081:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,161:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,324:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,439:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,787:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,793:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:50:51,925:INFO:Calculating mean and std
2025-05-24 22:50:51,927:INFO:Creating metrics dataframe
2025-05-24 22:50:51,929:INFO:Uploading results into container
2025-05-24 22:50:51,930:INFO:Uploading model into container now
2025-05-24 22:50:51,930:INFO:_master_model_container: 9
2025-05-24 22:50:51,930:INFO:_display_container: 2
2025-05-24 22:50:51,931:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-24 22:50:51,931:INFO:create_model() successfully completed......................................
2025-05-24 22:50:52,010:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:52,010:INFO:Creating metrics dataframe
2025-05-24 22:50:52,024:INFO:Initializing Gradient Boosting Classifier
2025-05-24 22:50:52,024:INFO:Total runtime is 0.4644585609436035 minutes
2025-05-24 22:50:52,029:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:52,030:INFO:Initializing create_model()
2025-05-24 22:50:52,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:52,030:INFO:Checking exceptions
2025-05-24 22:50:52,030:INFO:Importing libraries
2025-05-24 22:50:52,030:INFO:Copying training dataset
2025-05-24 22:50:52,042:INFO:Defining folds
2025-05-24 22:50:52,042:INFO:Declaring metric variables
2025-05-24 22:50:52,046:INFO:Importing untrained model
2025-05-24 22:50:52,054:INFO:Gradient Boosting Classifier Imported successfully
2025-05-24 22:50:52,063:INFO:Starting cross validation
2025-05-24 22:50:52,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:54,923:INFO:Calculating mean and std
2025-05-24 22:50:54,924:INFO:Creating metrics dataframe
2025-05-24 22:50:54,927:INFO:Uploading results into container
2025-05-24 22:50:54,927:INFO:Uploading model into container now
2025-05-24 22:50:54,928:INFO:_master_model_container: 10
2025-05-24 22:50:54,928:INFO:_display_container: 2
2025-05-24 22:50:54,928:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-24 22:50:54,928:INFO:create_model() successfully completed......................................
2025-05-24 22:50:55,003:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:55,004:INFO:Creating metrics dataframe
2025-05-24 22:50:55,014:INFO:Initializing Linear Discriminant Analysis
2025-05-24 22:50:55,015:INFO:Total runtime is 0.5142797191937765 minutes
2025-05-24 22:50:55,021:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:55,021:INFO:Initializing create_model()
2025-05-24 22:50:55,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:55,022:INFO:Checking exceptions
2025-05-24 22:50:55,022:INFO:Importing libraries
2025-05-24 22:50:55,022:INFO:Copying training dataset
2025-05-24 22:50:55,030:INFO:Defining folds
2025-05-24 22:50:55,030:INFO:Declaring metric variables
2025-05-24 22:50:55,034:INFO:Importing untrained model
2025-05-24 22:50:55,042:INFO:Linear Discriminant Analysis Imported successfully
2025-05-24 22:50:55,052:INFO:Starting cross validation
2025-05-24 22:50:55,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:50:56,921:INFO:Calculating mean and std
2025-05-24 22:50:56,923:INFO:Creating metrics dataframe
2025-05-24 22:50:56,926:INFO:Uploading results into container
2025-05-24 22:50:56,927:INFO:Uploading model into container now
2025-05-24 22:50:56,928:INFO:_master_model_container: 11
2025-05-24 22:50:56,928:INFO:_display_container: 2
2025-05-24 22:50:56,928:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-24 22:50:56,928:INFO:create_model() successfully completed......................................
2025-05-24 22:50:57,008:INFO:SubProcess create_model() end ==================================
2025-05-24 22:50:57,008:INFO:Creating metrics dataframe
2025-05-24 22:50:57,020:INFO:Initializing Extra Trees Classifier
2025-05-24 22:50:57,021:INFO:Total runtime is 0.5477328777313233 minutes
2025-05-24 22:50:57,025:INFO:SubProcess create_model() called ==================================
2025-05-24 22:50:57,025:INFO:Initializing create_model()
2025-05-24 22:50:57,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:50:57,025:INFO:Checking exceptions
2025-05-24 22:50:57,026:INFO:Importing libraries
2025-05-24 22:50:57,026:INFO:Copying training dataset
2025-05-24 22:50:57,035:INFO:Defining folds
2025-05-24 22:50:57,035:INFO:Declaring metric variables
2025-05-24 22:50:57,040:INFO:Importing untrained model
2025-05-24 22:50:57,046:INFO:Extra Trees Classifier Imported successfully
2025-05-24 22:50:57,057:INFO:Starting cross validation
2025-05-24 22:50:57,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:00,124:INFO:Calculating mean and std
2025-05-24 22:51:00,126:INFO:Creating metrics dataframe
2025-05-24 22:51:00,129:INFO:Uploading results into container
2025-05-24 22:51:00,129:INFO:Uploading model into container now
2025-05-24 22:51:00,130:INFO:_master_model_container: 12
2025-05-24 22:51:00,130:INFO:_display_container: 2
2025-05-24 22:51:00,131:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-24 22:51:00,131:INFO:create_model() successfully completed......................................
2025-05-24 22:51:00,206:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:00,207:INFO:Creating metrics dataframe
2025-05-24 22:51:00,218:INFO:Initializing Light Gradient Boosting Machine
2025-05-24 22:51:00,219:INFO:Total runtime is 0.6010348717371623 minutes
2025-05-24 22:51:00,223:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:00,223:INFO:Initializing create_model()
2025-05-24 22:51:00,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:00,224:INFO:Checking exceptions
2025-05-24 22:51:00,224:INFO:Importing libraries
2025-05-24 22:51:00,224:INFO:Copying training dataset
2025-05-24 22:51:00,232:INFO:Defining folds
2025-05-24 22:51:00,232:INFO:Declaring metric variables
2025-05-24 22:51:00,237:INFO:Importing untrained model
2025-05-24 22:51:00,242:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-24 22:51:00,250:INFO:Starting cross validation
2025-05-24 22:51:00,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:02,808:INFO:Calculating mean and std
2025-05-24 22:51:02,812:INFO:Creating metrics dataframe
2025-05-24 22:51:02,817:INFO:Uploading results into container
2025-05-24 22:51:02,819:INFO:Uploading model into container now
2025-05-24 22:51:02,820:INFO:_master_model_container: 13
2025-05-24 22:51:02,821:INFO:_display_container: 2
2025-05-24 22:51:02,824:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-24 22:51:02,824:INFO:create_model() successfully completed......................................
2025-05-24 22:51:02,934:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:02,935:INFO:Creating metrics dataframe
2025-05-24 22:51:02,950:INFO:Initializing Dummy Classifier
2025-05-24 22:51:02,951:INFO:Total runtime is 0.6465616623560588 minutes
2025-05-24 22:51:02,956:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:02,956:INFO:Initializing create_model()
2025-05-24 22:51:02,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213EE06FFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:02,957:INFO:Checking exceptions
2025-05-24 22:51:02,957:INFO:Importing libraries
2025-05-24 22:51:02,957:INFO:Copying training dataset
2025-05-24 22:51:02,968:INFO:Defining folds
2025-05-24 22:51:02,968:INFO:Declaring metric variables
2025-05-24 22:51:02,973:INFO:Importing untrained model
2025-05-24 22:51:02,978:INFO:Dummy Classifier Imported successfully
2025-05-24 22:51:02,989:INFO:Starting cross validation
2025-05-24 22:51:02,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:04,403:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,407:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,419:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,419:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,509:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,546:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,640:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:04,642:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:05,096:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:05,118:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:51:05,130:INFO:Calculating mean and std
2025-05-24 22:51:05,132:INFO:Creating metrics dataframe
2025-05-24 22:51:05,137:INFO:Uploading results into container
2025-05-24 22:51:05,138:INFO:Uploading model into container now
2025-05-24 22:51:05,138:INFO:_master_model_container: 14
2025-05-24 22:51:05,138:INFO:_display_container: 2
2025-05-24 22:51:05,139:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-24 22:51:05,139:INFO:create_model() successfully completed......................................
2025-05-24 22:51:05,241:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:05,241:INFO:Creating metrics dataframe
2025-05-24 22:51:05,258:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-24 22:51:05,268:INFO:Initializing create_model()
2025-05-24 22:51:05,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:05,269:INFO:Checking exceptions
2025-05-24 22:51:05,271:INFO:Importing libraries
2025-05-24 22:51:05,271:INFO:Copying training dataset
2025-05-24 22:51:05,278:INFO:Defining folds
2025-05-24 22:51:05,278:INFO:Declaring metric variables
2025-05-24 22:51:05,278:INFO:Importing untrained model
2025-05-24 22:51:05,278:INFO:Declaring custom model
2025-05-24 22:51:05,278:INFO:Logistic Regression Imported successfully
2025-05-24 22:51:05,287:INFO:Cross validation set to False
2025-05-24 22:51:05,287:INFO:Fitting Model
2025-05-24 22:51:05,601:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-24 22:51:05,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.
2025-05-24 22:51:05,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-24 22:51:05,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-24 22:51:05,603:INFO:[LightGBM] [Info] Total Bins 487
2025-05-24 22:51:05,603:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-24 22:51:05,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-24 22:51:05,604:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-24 22:51:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:51:05,651:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:51:05,651:INFO:create_model() successfully completed......................................
2025-05-24 22:51:05,771:INFO:_master_model_container: 14
2025-05-24 22:51:05,771:INFO:_display_container: 2
2025-05-24 22:51:05,772:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:51:05,772:INFO:compare_models() successfully completed......................................
2025-05-24 22:51:17,432:INFO:Initializing compare_models()
2025-05-24 22:51:17,433:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-24 22:51:17,434:INFO:Checking exceptions
2025-05-24 22:51:17,438:INFO:Preparing display monitor
2025-05-24 22:51:17,520:INFO:Initializing Logistic Regression
2025-05-24 22:51:17,520:INFO:Total runtime is 1.6609827677408855e-05 minutes
2025-05-24 22:51:17,531:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:17,533:INFO:Initializing create_model()
2025-05-24 22:51:17,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:17,533:INFO:Checking exceptions
2025-05-24 22:51:17,533:INFO:Importing libraries
2025-05-24 22:51:17,533:INFO:Copying training dataset
2025-05-24 22:51:17,544:INFO:Defining folds
2025-05-24 22:51:17,544:INFO:Declaring metric variables
2025-05-24 22:51:17,550:INFO:Importing untrained model
2025-05-24 22:51:17,555:INFO:Logistic Regression Imported successfully
2025-05-24 22:51:17,568:INFO:Starting cross validation
2025-05-24 22:51:17,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:19,485:INFO:Calculating mean and std
2025-05-24 22:51:19,491:INFO:Creating metrics dataframe
2025-05-24 22:51:19,503:INFO:Uploading results into container
2025-05-24 22:51:19,504:INFO:Uploading model into container now
2025-05-24 22:51:19,505:INFO:_master_model_container: 15
2025-05-24 22:51:19,505:INFO:_display_container: 3
2025-05-24 22:51:19,506:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:51:19,507:INFO:create_model() successfully completed......................................
2025-05-24 22:51:19,584:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:19,584:INFO:Creating metrics dataframe
2025-05-24 22:51:19,592:INFO:Initializing K Neighbors Classifier
2025-05-24 22:51:19,592:INFO:Total runtime is 0.03454423348108927 minutes
2025-05-24 22:51:19,598:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:19,598:INFO:Initializing create_model()
2025-05-24 22:51:19,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:19,599:INFO:Checking exceptions
2025-05-24 22:51:19,599:INFO:Importing libraries
2025-05-24 22:51:19,599:INFO:Copying training dataset
2025-05-24 22:51:19,605:INFO:Defining folds
2025-05-24 22:51:19,605:INFO:Declaring metric variables
2025-05-24 22:51:19,610:INFO:Importing untrained model
2025-05-24 22:51:19,614:INFO:K Neighbors Classifier Imported successfully
2025-05-24 22:51:19,623:INFO:Starting cross validation
2025-05-24 22:51:19,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:22,005:INFO:Calculating mean and std
2025-05-24 22:51:22,010:INFO:Creating metrics dataframe
2025-05-24 22:51:22,018:INFO:Uploading results into container
2025-05-24 22:51:22,020:INFO:Uploading model into container now
2025-05-24 22:51:22,021:INFO:_master_model_container: 16
2025-05-24 22:51:22,021:INFO:_display_container: 3
2025-05-24 22:51:22,022:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-24 22:51:22,023:INFO:create_model() successfully completed......................................
2025-05-24 22:51:22,153:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:22,153:INFO:Creating metrics dataframe
2025-05-24 22:51:22,164:INFO:Initializing Naive Bayes
2025-05-24 22:51:22,164:INFO:Total runtime is 0.07742444276809693 minutes
2025-05-24 22:51:22,169:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:22,169:INFO:Initializing create_model()
2025-05-24 22:51:22,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:22,170:INFO:Checking exceptions
2025-05-24 22:51:22,170:INFO:Importing libraries
2025-05-24 22:51:22,170:INFO:Copying training dataset
2025-05-24 22:51:22,180:INFO:Defining folds
2025-05-24 22:51:22,180:INFO:Declaring metric variables
2025-05-24 22:51:22,185:INFO:Importing untrained model
2025-05-24 22:51:22,192:INFO:Naive Bayes Imported successfully
2025-05-24 22:51:22,203:INFO:Starting cross validation
2025-05-24 22:51:22,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:26,857:INFO:Calculating mean and std
2025-05-24 22:51:26,858:INFO:Creating metrics dataframe
2025-05-24 22:51:26,861:INFO:Uploading results into container
2025-05-24 22:51:26,862:INFO:Uploading model into container now
2025-05-24 22:51:26,863:INFO:_master_model_container: 17
2025-05-24 22:51:26,864:INFO:_display_container: 3
2025-05-24 22:51:26,864:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-24 22:51:26,865:INFO:create_model() successfully completed......................................
2025-05-24 22:51:26,953:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:26,953:INFO:Creating metrics dataframe
2025-05-24 22:51:26,963:INFO:Initializing Decision Tree Classifier
2025-05-24 22:51:26,964:INFO:Total runtime is 0.15742084980010987 minutes
2025-05-24 22:51:26,969:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:26,969:INFO:Initializing create_model()
2025-05-24 22:51:26,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:26,970:INFO:Checking exceptions
2025-05-24 22:51:26,970:INFO:Importing libraries
2025-05-24 22:51:26,970:INFO:Copying training dataset
2025-05-24 22:51:26,980:INFO:Defining folds
2025-05-24 22:51:26,980:INFO:Declaring metric variables
2025-05-24 22:51:26,986:INFO:Importing untrained model
2025-05-24 22:51:26,992:INFO:Decision Tree Classifier Imported successfully
2025-05-24 22:51:27,004:INFO:Starting cross validation
2025-05-24 22:51:27,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:30,167:INFO:Calculating mean and std
2025-05-24 22:51:30,169:INFO:Creating metrics dataframe
2025-05-24 22:51:30,173:INFO:Uploading results into container
2025-05-24 22:51:30,174:INFO:Uploading model into container now
2025-05-24 22:51:30,175:INFO:_master_model_container: 18
2025-05-24 22:51:30,176:INFO:_display_container: 3
2025-05-24 22:51:30,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-24 22:51:30,177:INFO:create_model() successfully completed......................................
2025-05-24 22:51:30,323:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:30,323:INFO:Creating metrics dataframe
2025-05-24 22:51:30,341:INFO:Initializing SVM - Linear Kernel
2025-05-24 22:51:30,342:INFO:Total runtime is 0.2137234131495158 minutes
2025-05-24 22:51:30,354:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:30,354:INFO:Initializing create_model()
2025-05-24 22:51:30,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:30,355:INFO:Checking exceptions
2025-05-24 22:51:30,355:INFO:Importing libraries
2025-05-24 22:51:30,355:INFO:Copying training dataset
2025-05-24 22:51:30,384:INFO:Defining folds
2025-05-24 22:51:30,384:INFO:Declaring metric variables
2025-05-24 22:51:30,393:INFO:Importing untrained model
2025-05-24 22:51:30,408:INFO:SVM - Linear Kernel Imported successfully
2025-05-24 22:51:30,465:INFO:Starting cross validation
2025-05-24 22:51:30,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:34,093:INFO:Calculating mean and std
2025-05-24 22:51:34,101:INFO:Creating metrics dataframe
2025-05-24 22:51:34,107:INFO:Uploading results into container
2025-05-24 22:51:34,108:INFO:Uploading model into container now
2025-05-24 22:51:34,109:INFO:_master_model_container: 19
2025-05-24 22:51:34,110:INFO:_display_container: 3
2025-05-24 22:51:34,110:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-24 22:51:34,110:INFO:create_model() successfully completed......................................
2025-05-24 22:51:34,272:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:34,272:INFO:Creating metrics dataframe
2025-05-24 22:51:34,297:INFO:Initializing Ridge Classifier
2025-05-24 22:51:34,298:INFO:Total runtime is 0.27964661916097006 minutes
2025-05-24 22:51:34,308:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:34,308:INFO:Initializing create_model()
2025-05-24 22:51:34,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:34,309:INFO:Checking exceptions
2025-05-24 22:51:34,309:INFO:Importing libraries
2025-05-24 22:51:34,309:INFO:Copying training dataset
2025-05-24 22:51:34,335:INFO:Defining folds
2025-05-24 22:51:34,335:INFO:Declaring metric variables
2025-05-24 22:51:34,342:INFO:Importing untrained model
2025-05-24 22:51:34,356:INFO:Ridge Classifier Imported successfully
2025-05-24 22:51:34,377:INFO:Starting cross validation
2025-05-24 22:51:34,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:39,458:INFO:Calculating mean and std
2025-05-24 22:51:39,465:INFO:Creating metrics dataframe
2025-05-24 22:51:39,470:INFO:Uploading results into container
2025-05-24 22:51:39,471:INFO:Uploading model into container now
2025-05-24 22:51:39,472:INFO:_master_model_container: 20
2025-05-24 22:51:39,472:INFO:_display_container: 3
2025-05-24 22:51:39,473:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-24 22:51:39,473:INFO:create_model() successfully completed......................................
2025-05-24 22:51:39,697:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:39,697:INFO:Creating metrics dataframe
2025-05-24 22:51:39,719:INFO:Initializing Random Forest Classifier
2025-05-24 22:51:39,719:INFO:Total runtime is 0.370002273718516 minutes
2025-05-24 22:51:39,731:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:39,733:INFO:Initializing create_model()
2025-05-24 22:51:39,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:39,734:INFO:Checking exceptions
2025-05-24 22:51:39,734:INFO:Importing libraries
2025-05-24 22:51:39,734:INFO:Copying training dataset
2025-05-24 22:51:39,755:INFO:Defining folds
2025-05-24 22:51:39,756:INFO:Declaring metric variables
2025-05-24 22:51:39,776:INFO:Importing untrained model
2025-05-24 22:51:39,788:INFO:Random Forest Classifier Imported successfully
2025-05-24 22:51:39,803:INFO:Starting cross validation
2025-05-24 22:51:39,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:46,958:INFO:Calculating mean and std
2025-05-24 22:51:46,961:INFO:Creating metrics dataframe
2025-05-24 22:51:46,965:INFO:Uploading results into container
2025-05-24 22:51:46,966:INFO:Uploading model into container now
2025-05-24 22:51:46,967:INFO:_master_model_container: 21
2025-05-24 22:51:46,967:INFO:_display_container: 3
2025-05-24 22:51:46,968:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-24 22:51:46,968:INFO:create_model() successfully completed......................................
2025-05-24 22:51:47,057:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:47,057:INFO:Creating metrics dataframe
2025-05-24 22:51:47,068:INFO:Initializing Quadratic Discriminant Analysis
2025-05-24 22:51:47,068:INFO:Total runtime is 0.49248215754826863 minutes
2025-05-24 22:51:47,073:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:47,073:INFO:Initializing create_model()
2025-05-24 22:51:47,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:47,073:INFO:Checking exceptions
2025-05-24 22:51:47,074:INFO:Importing libraries
2025-05-24 22:51:47,074:INFO:Copying training dataset
2025-05-24 22:51:47,082:INFO:Defining folds
2025-05-24 22:51:47,082:INFO:Declaring metric variables
2025-05-24 22:51:47,089:INFO:Importing untrained model
2025-05-24 22:51:47,094:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-24 22:51:47,103:INFO:Starting cross validation
2025-05-24 22:51:47,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:49,231:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:49,237:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:49,266:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:49,271:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:49,453:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:49,730:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:50,438:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:50,571:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:50,989:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:51,108:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:51:51,258:INFO:Calculating mean and std
2025-05-24 22:51:51,260:INFO:Creating metrics dataframe
2025-05-24 22:51:51,264:INFO:Uploading results into container
2025-05-24 22:51:51,265:INFO:Uploading model into container now
2025-05-24 22:51:51,266:INFO:_master_model_container: 22
2025-05-24 22:51:51,266:INFO:_display_container: 3
2025-05-24 22:51:51,267:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-24 22:51:51,267:INFO:create_model() successfully completed......................................
2025-05-24 22:51:51,356:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:51,356:INFO:Creating metrics dataframe
2025-05-24 22:51:51,382:INFO:Initializing Ada Boost Classifier
2025-05-24 22:51:51,382:INFO:Total runtime is 0.5643834670384725 minutes
2025-05-24 22:51:51,388:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:51,388:INFO:Initializing create_model()
2025-05-24 22:51:51,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:51,389:INFO:Checking exceptions
2025-05-24 22:51:51,389:INFO:Importing libraries
2025-05-24 22:51:51,389:INFO:Copying training dataset
2025-05-24 22:51:51,408:INFO:Defining folds
2025-05-24 22:51:51,408:INFO:Declaring metric variables
2025-05-24 22:51:51,417:INFO:Importing untrained model
2025-05-24 22:51:51,430:INFO:Ada Boost Classifier Imported successfully
2025-05-24 22:51:51,450:INFO:Starting cross validation
2025-05-24 22:51:51,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:53,401:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:53,424:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:53,446:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:53,558:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:53,813:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:53,936:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:54,103:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:54,105:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:54,885:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:54,915:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:51:55,106:INFO:Calculating mean and std
2025-05-24 22:51:55,110:INFO:Creating metrics dataframe
2025-05-24 22:51:55,117:INFO:Uploading results into container
2025-05-24 22:51:55,119:INFO:Uploading model into container now
2025-05-24 22:51:55,120:INFO:_master_model_container: 23
2025-05-24 22:51:55,120:INFO:_display_container: 3
2025-05-24 22:51:55,121:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-24 22:51:55,122:INFO:create_model() successfully completed......................................
2025-05-24 22:51:55,303:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:55,303:INFO:Creating metrics dataframe
2025-05-24 22:51:55,320:INFO:Initializing Gradient Boosting Classifier
2025-05-24 22:51:55,321:INFO:Total runtime is 0.6300365487734477 minutes
2025-05-24 22:51:55,327:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:55,328:INFO:Initializing create_model()
2025-05-24 22:51:55,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:55,328:INFO:Checking exceptions
2025-05-24 22:51:55,328:INFO:Importing libraries
2025-05-24 22:51:55,328:INFO:Copying training dataset
2025-05-24 22:51:55,339:INFO:Defining folds
2025-05-24 22:51:55,339:INFO:Declaring metric variables
2025-05-24 22:51:55,353:INFO:Importing untrained model
2025-05-24 22:51:55,365:INFO:Gradient Boosting Classifier Imported successfully
2025-05-24 22:51:55,383:INFO:Starting cross validation
2025-05-24 22:51:55,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:51:59,282:INFO:Calculating mean and std
2025-05-24 22:51:59,285:INFO:Creating metrics dataframe
2025-05-24 22:51:59,290:INFO:Uploading results into container
2025-05-24 22:51:59,292:INFO:Uploading model into container now
2025-05-24 22:51:59,294:INFO:_master_model_container: 24
2025-05-24 22:51:59,294:INFO:_display_container: 3
2025-05-24 22:51:59,295:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-24 22:51:59,296:INFO:create_model() successfully completed......................................
2025-05-24 22:51:59,502:INFO:SubProcess create_model() end ==================================
2025-05-24 22:51:59,502:INFO:Creating metrics dataframe
2025-05-24 22:51:59,540:INFO:Initializing Linear Discriminant Analysis
2025-05-24 22:51:59,540:INFO:Total runtime is 0.7003447373708089 minutes
2025-05-24 22:51:59,553:INFO:SubProcess create_model() called ==================================
2025-05-24 22:51:59,554:INFO:Initializing create_model()
2025-05-24 22:51:59,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:51:59,555:INFO:Checking exceptions
2025-05-24 22:51:59,555:INFO:Importing libraries
2025-05-24 22:51:59,555:INFO:Copying training dataset
2025-05-24 22:51:59,580:INFO:Defining folds
2025-05-24 22:51:59,583:INFO:Declaring metric variables
2025-05-24 22:51:59,601:INFO:Importing untrained model
2025-05-24 22:51:59,612:INFO:Linear Discriminant Analysis Imported successfully
2025-05-24 22:51:59,637:INFO:Starting cross validation
2025-05-24 22:51:59,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:52:03,416:INFO:Calculating mean and std
2025-05-24 22:52:03,418:INFO:Creating metrics dataframe
2025-05-24 22:52:03,421:INFO:Uploading results into container
2025-05-24 22:52:03,423:INFO:Uploading model into container now
2025-05-24 22:52:03,424:INFO:_master_model_container: 25
2025-05-24 22:52:03,425:INFO:_display_container: 3
2025-05-24 22:52:03,426:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-24 22:52:03,426:INFO:create_model() successfully completed......................................
2025-05-24 22:52:03,589:INFO:SubProcess create_model() end ==================================
2025-05-24 22:52:03,590:INFO:Creating metrics dataframe
2025-05-24 22:52:03,621:INFO:Initializing Extra Trees Classifier
2025-05-24 22:52:03,621:INFO:Total runtime is 0.7683685739835103 minutes
2025-05-24 22:52:03,631:INFO:SubProcess create_model() called ==================================
2025-05-24 22:52:03,631:INFO:Initializing create_model()
2025-05-24 22:52:03,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:52:03,632:INFO:Checking exceptions
2025-05-24 22:52:03,632:INFO:Importing libraries
2025-05-24 22:52:03,632:INFO:Copying training dataset
2025-05-24 22:52:03,648:INFO:Defining folds
2025-05-24 22:52:03,648:INFO:Declaring metric variables
2025-05-24 22:52:03,662:INFO:Importing untrained model
2025-05-24 22:52:03,671:INFO:Extra Trees Classifier Imported successfully
2025-05-24 22:52:03,690:INFO:Starting cross validation
2025-05-24 22:52:03,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:52:08,653:INFO:Calculating mean and std
2025-05-24 22:52:08,655:INFO:Creating metrics dataframe
2025-05-24 22:52:08,661:INFO:Uploading results into container
2025-05-24 22:52:08,663:INFO:Uploading model into container now
2025-05-24 22:52:08,664:INFO:_master_model_container: 26
2025-05-24 22:52:08,664:INFO:_display_container: 3
2025-05-24 22:52:08,665:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-24 22:52:08,665:INFO:create_model() successfully completed......................................
2025-05-24 22:52:08,798:INFO:SubProcess create_model() end ==================================
2025-05-24 22:52:08,798:INFO:Creating metrics dataframe
2025-05-24 22:52:08,814:INFO:Initializing Light Gradient Boosting Machine
2025-05-24 22:52:08,814:INFO:Total runtime is 0.8549178878466288 minutes
2025-05-24 22:52:08,820:INFO:SubProcess create_model() called ==================================
2025-05-24 22:52:08,821:INFO:Initializing create_model()
2025-05-24 22:52:08,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:52:08,821:INFO:Checking exceptions
2025-05-24 22:52:08,821:INFO:Importing libraries
2025-05-24 22:52:08,822:INFO:Copying training dataset
2025-05-24 22:52:08,836:INFO:Defining folds
2025-05-24 22:52:08,836:INFO:Declaring metric variables
2025-05-24 22:52:08,846:INFO:Importing untrained model
2025-05-24 22:52:08,859:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-24 22:52:08,876:INFO:Starting cross validation
2025-05-24 22:52:08,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:52:12,698:INFO:Calculating mean and std
2025-05-24 22:52:12,703:INFO:Creating metrics dataframe
2025-05-24 22:52:12,718:INFO:Uploading results into container
2025-05-24 22:52:12,720:INFO:Uploading model into container now
2025-05-24 22:52:12,721:INFO:_master_model_container: 27
2025-05-24 22:52:12,721:INFO:_display_container: 3
2025-05-24 22:52:12,723:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-24 22:52:12,723:INFO:create_model() successfully completed......................................
2025-05-24 22:52:12,873:INFO:SubProcess create_model() end ==================================
2025-05-24 22:52:12,873:INFO:Creating metrics dataframe
2025-05-24 22:52:12,899:INFO:Initializing Dummy Classifier
2025-05-24 22:52:12,899:INFO:Total runtime is 0.9230056246121724 minutes
2025-05-24 22:52:12,910:INFO:SubProcess create_model() called ==================================
2025-05-24 22:52:12,911:INFO:Initializing create_model()
2025-05-24 22:52:12,911:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213ED93E4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:52:12,911:INFO:Checking exceptions
2025-05-24 22:52:12,911:INFO:Importing libraries
2025-05-24 22:52:12,911:INFO:Copying training dataset
2025-05-24 22:52:12,927:INFO:Defining folds
2025-05-24 22:52:12,928:INFO:Declaring metric variables
2025-05-24 22:52:12,935:INFO:Importing untrained model
2025-05-24 22:52:12,948:INFO:Dummy Classifier Imported successfully
2025-05-24 22:52:12,970:INFO:Starting cross validation
2025-05-24 22:52:12,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:52:15,029:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,044:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,129:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,255:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,531:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,565:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,744:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:15,785:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:16,349:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:16,353:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:52:16,379:INFO:Calculating mean and std
2025-05-24 22:52:16,382:INFO:Creating metrics dataframe
2025-05-24 22:52:16,388:INFO:Uploading results into container
2025-05-24 22:52:16,389:INFO:Uploading model into container now
2025-05-24 22:52:16,391:INFO:_master_model_container: 28
2025-05-24 22:52:16,392:INFO:_display_container: 3
2025-05-24 22:52:16,392:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-24 22:52:16,393:INFO:create_model() successfully completed......................................
2025-05-24 22:52:16,519:INFO:SubProcess create_model() end ==================================
2025-05-24 22:52:16,520:INFO:Creating metrics dataframe
2025-05-24 22:52:16,542:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-24 22:52:16,560:INFO:Initializing create_model()
2025-05-24 22:52:16,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:52:16,561:INFO:Checking exceptions
2025-05-24 22:52:16,564:INFO:Importing libraries
2025-05-24 22:52:16,565:INFO:Copying training dataset
2025-05-24 22:52:16,576:INFO:Defining folds
2025-05-24 22:52:16,577:INFO:Declaring metric variables
2025-05-24 22:52:16,577:INFO:Importing untrained model
2025-05-24 22:52:16,577:INFO:Declaring custom model
2025-05-24 22:52:16,578:INFO:Logistic Regression Imported successfully
2025-05-24 22:52:16,589:INFO:Cross validation set to False
2025-05-24 22:52:16,589:INFO:Fitting Model
2025-05-24 22:52:17,025:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-24 22:52:17,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.
2025-05-24 22:52:17,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-24 22:52:17,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-24 22:52:17,027:INFO:[LightGBM] [Info] Total Bins 487
2025-05-24 22:52:17,027:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-24 22:52:17,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-24 22:52:17,028:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-24 22:52:17,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:52:17,112:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:52:17,113:INFO:create_model() successfully completed......................................
2025-05-24 22:52:17,276:INFO:_master_model_container: 28
2025-05-24 22:52:17,276:INFO:_display_container: 3
2025-05-24 22:52:17,277:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:52:17,278:INFO:compare_models() successfully completed......................................
2025-05-24 22:57:44,798:INFO:Initializing compare_models()
2025-05-24 22:57:44,798:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-24 22:57:44,799:INFO:Checking exceptions
2025-05-24 22:57:44,805:INFO:Preparing display monitor
2025-05-24 22:57:44,837:INFO:Initializing Logistic Regression
2025-05-24 22:57:44,837:INFO:Total runtime is 0.0 minutes
2025-05-24 22:57:44,842:INFO:SubProcess create_model() called ==================================
2025-05-24 22:57:44,843:INFO:Initializing create_model()
2025-05-24 22:57:44,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:57:44,843:INFO:Checking exceptions
2025-05-24 22:57:44,843:INFO:Importing libraries
2025-05-24 22:57:44,843:INFO:Copying training dataset
2025-05-24 22:57:44,854:INFO:Defining folds
2025-05-24 22:57:44,854:INFO:Declaring metric variables
2025-05-24 22:57:44,857:INFO:Importing untrained model
2025-05-24 22:57:44,861:INFO:Logistic Regression Imported successfully
2025-05-24 22:57:44,908:INFO:Starting cross validation
2025-05-24 22:57:44,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:57:53,172:INFO:Calculating mean and std
2025-05-24 22:57:53,173:INFO:Creating metrics dataframe
2025-05-24 22:57:53,174:INFO:Uploading results into container
2025-05-24 22:57:53,175:INFO:Uploading model into container now
2025-05-24 22:57:53,175:INFO:_master_model_container: 29
2025-05-24 22:57:53,175:INFO:_display_container: 4
2025-05-24 22:57:53,175:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:57:53,175:INFO:create_model() successfully completed......................................
2025-05-24 22:57:53,246:INFO:SubProcess create_model() end ==================================
2025-05-24 22:57:53,246:INFO:Creating metrics dataframe
2025-05-24 22:57:53,254:INFO:Initializing K Neighbors Classifier
2025-05-24 22:57:53,254:INFO:Total runtime is 0.14027349948883056 minutes
2025-05-24 22:57:53,258:INFO:SubProcess create_model() called ==================================
2025-05-24 22:57:53,258:INFO:Initializing create_model()
2025-05-24 22:57:53,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:57:53,258:INFO:Checking exceptions
2025-05-24 22:57:53,258:INFO:Importing libraries
2025-05-24 22:57:53,258:INFO:Copying training dataset
2025-05-24 22:57:53,266:INFO:Defining folds
2025-05-24 22:57:53,266:INFO:Declaring metric variables
2025-05-24 22:57:53,269:INFO:Importing untrained model
2025-05-24 22:57:53,272:INFO:K Neighbors Classifier Imported successfully
2025-05-24 22:57:53,281:INFO:Starting cross validation
2025-05-24 22:57:53,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:57:55,085:INFO:Calculating mean and std
2025-05-24 22:57:55,086:INFO:Creating metrics dataframe
2025-05-24 22:57:55,087:INFO:Uploading results into container
2025-05-24 22:57:55,088:INFO:Uploading model into container now
2025-05-24 22:57:55,089:INFO:_master_model_container: 30
2025-05-24 22:57:55,089:INFO:_display_container: 4
2025-05-24 22:57:55,089:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-24 22:57:55,090:INFO:create_model() successfully completed......................................
2025-05-24 22:57:55,156:INFO:SubProcess create_model() end ==================================
2025-05-24 22:57:55,158:INFO:Creating metrics dataframe
2025-05-24 22:57:55,166:INFO:Initializing Naive Bayes
2025-05-24 22:57:55,166:INFO:Total runtime is 0.17214771111806232 minutes
2025-05-24 22:57:55,171:INFO:SubProcess create_model() called ==================================
2025-05-24 22:57:55,171:INFO:Initializing create_model()
2025-05-24 22:57:55,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:57:55,172:INFO:Checking exceptions
2025-05-24 22:57:55,172:INFO:Importing libraries
2025-05-24 22:57:55,172:INFO:Copying training dataset
2025-05-24 22:57:55,181:INFO:Defining folds
2025-05-24 22:57:55,181:INFO:Declaring metric variables
2025-05-24 22:57:55,185:INFO:Importing untrained model
2025-05-24 22:57:55,190:INFO:Naive Bayes Imported successfully
2025-05-24 22:57:55,202:INFO:Starting cross validation
2025-05-24 22:57:55,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:57:56,919:INFO:Calculating mean and std
2025-05-24 22:57:56,919:INFO:Creating metrics dataframe
2025-05-24 22:57:56,922:INFO:Uploading results into container
2025-05-24 22:57:56,922:INFO:Uploading model into container now
2025-05-24 22:57:56,922:INFO:_master_model_container: 31
2025-05-24 22:57:56,923:INFO:_display_container: 4
2025-05-24 22:57:56,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-24 22:57:56,923:INFO:create_model() successfully completed......................................
2025-05-24 22:57:56,993:INFO:SubProcess create_model() end ==================================
2025-05-24 22:57:56,993:INFO:Creating metrics dataframe
2025-05-24 22:57:57,002:INFO:Initializing Decision Tree Classifier
2025-05-24 22:57:57,003:INFO:Total runtime is 0.2027651786804199 minutes
2025-05-24 22:57:57,007:INFO:SubProcess create_model() called ==================================
2025-05-24 22:57:57,008:INFO:Initializing create_model()
2025-05-24 22:57:57,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:57:57,008:INFO:Checking exceptions
2025-05-24 22:57:57,008:INFO:Importing libraries
2025-05-24 22:57:57,008:INFO:Copying training dataset
2025-05-24 22:57:57,017:INFO:Defining folds
2025-05-24 22:57:57,017:INFO:Declaring metric variables
2025-05-24 22:57:57,022:INFO:Importing untrained model
2025-05-24 22:57:57,029:INFO:Decision Tree Classifier Imported successfully
2025-05-24 22:57:57,043:INFO:Starting cross validation
2025-05-24 22:57:57,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:57:59,454:INFO:Calculating mean and std
2025-05-24 22:57:59,455:INFO:Creating metrics dataframe
2025-05-24 22:57:59,459:INFO:Uploading results into container
2025-05-24 22:57:59,460:INFO:Uploading model into container now
2025-05-24 22:57:59,461:INFO:_master_model_container: 32
2025-05-24 22:57:59,462:INFO:_display_container: 4
2025-05-24 22:57:59,463:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-24 22:57:59,464:INFO:create_model() successfully completed......................................
2025-05-24 22:57:59,565:INFO:SubProcess create_model() end ==================================
2025-05-24 22:57:59,565:INFO:Creating metrics dataframe
2025-05-24 22:57:59,580:INFO:Initializing SVM - Linear Kernel
2025-05-24 22:57:59,580:INFO:Total runtime is 0.24570678869883217 minutes
2025-05-24 22:57:59,586:INFO:SubProcess create_model() called ==================================
2025-05-24 22:57:59,586:INFO:Initializing create_model()
2025-05-24 22:57:59,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:57:59,587:INFO:Checking exceptions
2025-05-24 22:57:59,587:INFO:Importing libraries
2025-05-24 22:57:59,587:INFO:Copying training dataset
2025-05-24 22:57:59,596:INFO:Defining folds
2025-05-24 22:57:59,597:INFO:Declaring metric variables
2025-05-24 22:57:59,603:INFO:Importing untrained model
2025-05-24 22:57:59,609:INFO:SVM - Linear Kernel Imported successfully
2025-05-24 22:57:59,621:INFO:Starting cross validation
2025-05-24 22:57:59,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:02,251:INFO:Calculating mean and std
2025-05-24 22:58:02,253:INFO:Creating metrics dataframe
2025-05-24 22:58:02,256:INFO:Uploading results into container
2025-05-24 22:58:02,258:INFO:Uploading model into container now
2025-05-24 22:58:02,259:INFO:_master_model_container: 33
2025-05-24 22:58:02,260:INFO:_display_container: 4
2025-05-24 22:58:02,260:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-24 22:58:02,261:INFO:create_model() successfully completed......................................
2025-05-24 22:58:02,394:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:02,397:INFO:Creating metrics dataframe
2025-05-24 22:58:02,422:INFO:Initializing Ridge Classifier
2025-05-24 22:58:02,422:INFO:Total runtime is 0.2930723388989766 minutes
2025-05-24 22:58:02,432:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:02,432:INFO:Initializing create_model()
2025-05-24 22:58:02,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:02,432:INFO:Checking exceptions
2025-05-24 22:58:02,432:INFO:Importing libraries
2025-05-24 22:58:02,433:INFO:Copying training dataset
2025-05-24 22:58:02,460:INFO:Defining folds
2025-05-24 22:58:02,460:INFO:Declaring metric variables
2025-05-24 22:58:02,468:INFO:Importing untrained model
2025-05-24 22:58:02,477:INFO:Ridge Classifier Imported successfully
2025-05-24 22:58:02,495:INFO:Starting cross validation
2025-05-24 22:58:02,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:05,499:INFO:Calculating mean and std
2025-05-24 22:58:05,501:INFO:Creating metrics dataframe
2025-05-24 22:58:05,504:INFO:Uploading results into container
2025-05-24 22:58:05,505:INFO:Uploading model into container now
2025-05-24 22:58:05,505:INFO:_master_model_container: 34
2025-05-24 22:58:05,506:INFO:_display_container: 4
2025-05-24 22:58:05,507:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-24 22:58:05,508:INFO:create_model() successfully completed......................................
2025-05-24 22:58:05,600:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:05,600:INFO:Creating metrics dataframe
2025-05-24 22:58:05,610:INFO:Initializing Random Forest Classifier
2025-05-24 22:58:05,610:INFO:Total runtime is 0.34621256192525224 minutes
2025-05-24 22:58:05,617:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:05,618:INFO:Initializing create_model()
2025-05-24 22:58:05,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:05,618:INFO:Checking exceptions
2025-05-24 22:58:05,618:INFO:Importing libraries
2025-05-24 22:58:05,618:INFO:Copying training dataset
2025-05-24 22:58:05,634:INFO:Defining folds
2025-05-24 22:58:05,634:INFO:Declaring metric variables
2025-05-24 22:58:05,640:INFO:Importing untrained model
2025-05-24 22:58:05,649:INFO:Random Forest Classifier Imported successfully
2025-05-24 22:58:05,662:INFO:Starting cross validation
2025-05-24 22:58:05,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:09,701:INFO:Calculating mean and std
2025-05-24 22:58:09,704:INFO:Creating metrics dataframe
2025-05-24 22:58:09,707:INFO:Uploading results into container
2025-05-24 22:58:09,709:INFO:Uploading model into container now
2025-05-24 22:58:09,710:INFO:_master_model_container: 35
2025-05-24 22:58:09,710:INFO:_display_container: 4
2025-05-24 22:58:09,713:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-24 22:58:09,715:INFO:create_model() successfully completed......................................
2025-05-24 22:58:09,837:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:09,837:INFO:Creating metrics dataframe
2025-05-24 22:58:09,853:INFO:Initializing Quadratic Discriminant Analysis
2025-05-24 22:58:09,853:INFO:Total runtime is 0.416929284731547 minutes
2025-05-24 22:58:09,858:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:09,859:INFO:Initializing create_model()
2025-05-24 22:58:09,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:09,859:INFO:Checking exceptions
2025-05-24 22:58:09,859:INFO:Importing libraries
2025-05-24 22:58:09,859:INFO:Copying training dataset
2025-05-24 22:58:09,873:INFO:Defining folds
2025-05-24 22:58:09,873:INFO:Declaring metric variables
2025-05-24 22:58:09,884:INFO:Importing untrained model
2025-05-24 22:58:09,893:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-24 22:58:09,910:INFO:Starting cross validation
2025-05-24 22:58:09,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:11,641:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:11,655:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:11,683:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:11,835:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:11,924:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,080:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,232:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,367:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,790:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,814:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 22:58:12,957:INFO:Calculating mean and std
2025-05-24 22:58:12,961:INFO:Creating metrics dataframe
2025-05-24 22:58:12,969:INFO:Uploading results into container
2025-05-24 22:58:12,970:INFO:Uploading model into container now
2025-05-24 22:58:12,971:INFO:_master_model_container: 36
2025-05-24 22:58:12,971:INFO:_display_container: 4
2025-05-24 22:58:12,972:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-24 22:58:12,972:INFO:create_model() successfully completed......................................
2025-05-24 22:58:13,068:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:13,069:INFO:Creating metrics dataframe
2025-05-24 22:58:13,081:INFO:Initializing Ada Boost Classifier
2025-05-24 22:58:13,081:INFO:Total runtime is 0.4707239508628845 minutes
2025-05-24 22:58:13,086:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:13,086:INFO:Initializing create_model()
2025-05-24 22:58:13,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:13,087:INFO:Checking exceptions
2025-05-24 22:58:13,087:INFO:Importing libraries
2025-05-24 22:58:13,087:INFO:Copying training dataset
2025-05-24 22:58:13,099:INFO:Defining folds
2025-05-24 22:58:13,099:INFO:Declaring metric variables
2025-05-24 22:58:13,104:INFO:Importing untrained model
2025-05-24 22:58:13,110:INFO:Ada Boost Classifier Imported successfully
2025-05-24 22:58:13,122:INFO:Starting cross validation
2025-05-24 22:58:13,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:15,553:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,563:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,768:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,796:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:15,913:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:16,001:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:16,499:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:16,517:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 22:58:16,653:INFO:Calculating mean and std
2025-05-24 22:58:16,655:INFO:Creating metrics dataframe
2025-05-24 22:58:16,659:INFO:Uploading results into container
2025-05-24 22:58:16,660:INFO:Uploading model into container now
2025-05-24 22:58:16,663:INFO:_master_model_container: 37
2025-05-24 22:58:16,663:INFO:_display_container: 4
2025-05-24 22:58:16,664:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-24 22:58:16,664:INFO:create_model() successfully completed......................................
2025-05-24 22:58:16,763:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:16,763:INFO:Creating metrics dataframe
2025-05-24 22:58:16,775:INFO:Initializing Gradient Boosting Classifier
2025-05-24 22:58:16,775:INFO:Total runtime is 0.532298974196116 minutes
2025-05-24 22:58:16,781:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:16,781:INFO:Initializing create_model()
2025-05-24 22:58:16,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:16,781:INFO:Checking exceptions
2025-05-24 22:58:16,781:INFO:Importing libraries
2025-05-24 22:58:16,781:INFO:Copying training dataset
2025-05-24 22:58:16,791:INFO:Defining folds
2025-05-24 22:58:16,792:INFO:Declaring metric variables
2025-05-24 22:58:16,800:INFO:Importing untrained model
2025-05-24 22:58:16,804:INFO:Gradient Boosting Classifier Imported successfully
2025-05-24 22:58:16,817:INFO:Starting cross validation
2025-05-24 22:58:16,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:20,266:INFO:Calculating mean and std
2025-05-24 22:58:20,268:INFO:Creating metrics dataframe
2025-05-24 22:58:20,271:INFO:Uploading results into container
2025-05-24 22:58:20,271:INFO:Uploading model into container now
2025-05-24 22:58:20,273:INFO:_master_model_container: 38
2025-05-24 22:58:20,273:INFO:_display_container: 4
2025-05-24 22:58:20,275:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-24 22:58:20,275:INFO:create_model() successfully completed......................................
2025-05-24 22:58:20,374:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:20,375:INFO:Creating metrics dataframe
2025-05-24 22:58:20,388:INFO:Initializing Linear Discriminant Analysis
2025-05-24 22:58:20,388:INFO:Total runtime is 0.5925085425376891 minutes
2025-05-24 22:58:20,394:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:20,395:INFO:Initializing create_model()
2025-05-24 22:58:20,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:20,395:INFO:Checking exceptions
2025-05-24 22:58:20,395:INFO:Importing libraries
2025-05-24 22:58:20,395:INFO:Copying training dataset
2025-05-24 22:58:20,407:INFO:Defining folds
2025-05-24 22:58:20,407:INFO:Declaring metric variables
2025-05-24 22:58:20,416:INFO:Importing untrained model
2025-05-24 22:58:20,421:INFO:Linear Discriminant Analysis Imported successfully
2025-05-24 22:58:20,433:INFO:Starting cross validation
2025-05-24 22:58:20,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:22,763:INFO:Calculating mean and std
2025-05-24 22:58:22,765:INFO:Creating metrics dataframe
2025-05-24 22:58:22,769:INFO:Uploading results into container
2025-05-24 22:58:22,770:INFO:Uploading model into container now
2025-05-24 22:58:22,772:INFO:_master_model_container: 39
2025-05-24 22:58:22,773:INFO:_display_container: 4
2025-05-24 22:58:22,773:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-24 22:58:22,774:INFO:create_model() successfully completed......................................
2025-05-24 22:58:22,887:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:22,887:INFO:Creating metrics dataframe
2025-05-24 22:58:22,902:INFO:Initializing Extra Trees Classifier
2025-05-24 22:58:22,902:INFO:Total runtime is 0.6344126065572102 minutes
2025-05-24 22:58:22,908:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:22,908:INFO:Initializing create_model()
2025-05-24 22:58:22,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:22,909:INFO:Checking exceptions
2025-05-24 22:58:22,909:INFO:Importing libraries
2025-05-24 22:58:22,909:INFO:Copying training dataset
2025-05-24 22:58:22,919:INFO:Defining folds
2025-05-24 22:58:22,919:INFO:Declaring metric variables
2025-05-24 22:58:22,925:INFO:Importing untrained model
2025-05-24 22:58:22,933:INFO:Extra Trees Classifier Imported successfully
2025-05-24 22:58:22,945:INFO:Starting cross validation
2025-05-24 22:58:22,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:26,323:INFO:Calculating mean and std
2025-05-24 22:58:26,324:INFO:Creating metrics dataframe
2025-05-24 22:58:26,327:INFO:Uploading results into container
2025-05-24 22:58:26,328:INFO:Uploading model into container now
2025-05-24 22:58:26,328:INFO:_master_model_container: 40
2025-05-24 22:58:26,328:INFO:_display_container: 4
2025-05-24 22:58:26,329:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-24 22:58:26,329:INFO:create_model() successfully completed......................................
2025-05-24 22:58:26,404:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:26,404:INFO:Creating metrics dataframe
2025-05-24 22:58:26,416:INFO:Initializing Light Gradient Boosting Machine
2025-05-24 22:58:26,416:INFO:Total runtime is 0.6929817477862039 minutes
2025-05-24 22:58:26,421:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:26,422:INFO:Initializing create_model()
2025-05-24 22:58:26,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:26,422:INFO:Checking exceptions
2025-05-24 22:58:26,422:INFO:Importing libraries
2025-05-24 22:58:26,422:INFO:Copying training dataset
2025-05-24 22:58:26,431:INFO:Defining folds
2025-05-24 22:58:26,431:INFO:Declaring metric variables
2025-05-24 22:58:26,435:INFO:Importing untrained model
2025-05-24 22:58:26,440:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-24 22:58:26,449:INFO:Starting cross validation
2025-05-24 22:58:26,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:29,118:INFO:Calculating mean and std
2025-05-24 22:58:29,122:INFO:Creating metrics dataframe
2025-05-24 22:58:29,128:INFO:Uploading results into container
2025-05-24 22:58:29,129:INFO:Uploading model into container now
2025-05-24 22:58:29,130:INFO:_master_model_container: 41
2025-05-24 22:58:29,131:INFO:_display_container: 4
2025-05-24 22:58:29,133:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-24 22:58:29,133:INFO:create_model() successfully completed......................................
2025-05-24 22:58:29,255:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:29,255:INFO:Creating metrics dataframe
2025-05-24 22:58:29,268:INFO:Initializing Dummy Classifier
2025-05-24 22:58:29,268:INFO:Total runtime is 0.7405149618784586 minutes
2025-05-24 22:58:29,273:INFO:SubProcess create_model() called ==================================
2025-05-24 22:58:29,274:INFO:Initializing create_model()
2025-05-24 22:58:29,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000213F0817150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:29,274:INFO:Checking exceptions
2025-05-24 22:58:29,274:INFO:Importing libraries
2025-05-24 22:58:29,274:INFO:Copying training dataset
2025-05-24 22:58:29,285:INFO:Defining folds
2025-05-24 22:58:29,285:INFO:Declaring metric variables
2025-05-24 22:58:29,289:INFO:Importing untrained model
2025-05-24 22:58:29,298:INFO:Dummy Classifier Imported successfully
2025-05-24 22:58:29,307:INFO:Starting cross validation
2025-05-24 22:58:29,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 22:58:30,592:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,608:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,617:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,622:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,688:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,779:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,814:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:30,879:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:31,270:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:31,272:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 22:58:31,285:INFO:Calculating mean and std
2025-05-24 22:58:31,289:INFO:Creating metrics dataframe
2025-05-24 22:58:31,296:INFO:Uploading results into container
2025-05-24 22:58:31,298:INFO:Uploading model into container now
2025-05-24 22:58:31,300:INFO:_master_model_container: 42
2025-05-24 22:58:31,300:INFO:_display_container: 4
2025-05-24 22:58:31,302:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-24 22:58:31,302:INFO:create_model() successfully completed......................................
2025-05-24 22:58:31,390:INFO:SubProcess create_model() end ==================================
2025-05-24 22:58:31,390:INFO:Creating metrics dataframe
2025-05-24 22:58:31,404:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-24 22:58:31,416:INFO:Initializing create_model()
2025-05-24 22:58:31,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213ED3F8610>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 22:58:31,416:INFO:Checking exceptions
2025-05-24 22:58:31,418:INFO:Importing libraries
2025-05-24 22:58:31,418:INFO:Copying training dataset
2025-05-24 22:58:31,426:INFO:Defining folds
2025-05-24 22:58:31,426:INFO:Declaring metric variables
2025-05-24 22:58:31,427:INFO:Importing untrained model
2025-05-24 22:58:31,427:INFO:Declaring custom model
2025-05-24 22:58:31,428:INFO:Logistic Regression Imported successfully
2025-05-24 22:58:31,437:INFO:Cross validation set to False
2025-05-24 22:58:31,437:INFO:Fitting Model
2025-05-24 22:58:32,053:INFO:[LightGBM] [Info] Number of positive: 491, number of negative: 3009
2025-05-24 22:58:32,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.
2025-05-24 22:58:32,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-24 22:58:32,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-24 22:58:32,056:INFO:[LightGBM] [Info] Total Bins 487
2025-05-24 22:58:32,057:INFO:[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 34
2025-05-24 22:58:32,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140286 -> initscore=-1.812919
2025-05-24 22:58:32,058:INFO:[LightGBM] [Info] Start training from score -1.812919
2025-05-24 22:58:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-24 22:58:32,182:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:58:32,182:INFO:create_model() successfully completed......................................
2025-05-24 22:58:32,335:INFO:_master_model_container: 42
2025-05-24 22:58:32,335:INFO:_display_container: 4
2025-05-24 22:58:32,336:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 22:58:32,337:INFO:compare_models() successfully completed......................................
