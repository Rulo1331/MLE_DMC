2025-05-12 20:57:18,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:57:18,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:07:38,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:09,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:41:32,743:INFO:PyCaret RegressionExperiment
2025-05-12 21:41:32,743:INFO:Logging name: reg-default-name
2025-05-12 21:41:32,743:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:41:32,743:INFO:version 3.3.2
2025-05-12 21:41:32,743:INFO:Initializing setup()
2025-05-12 21:41:32,743:INFO:self.USI: a710
2025-05-12 21:41:32,743:INFO:self._variable_keys: {'idx', 'n_jobs_param', 'pipeline', 'memory', 'y_train', 'y_test', 'target_param', 'fold_shuffle_param', 'gpu_param', 'logging_param', '_ml_usecase', '_available_plots', 'transform_target_param', 'exp_name_log', 'X', 'data', 'log_plots_param', 'fold_generator', 'USI', 'exp_id', 'gpu_n_jobs_param', 'y', 'html_param', 'X_train', 'X_test', 'seed', 'fold_groups_param'}
2025-05-12 21:41:32,743:INFO:Checking environment
2025-05-12 21:41:32,743:INFO:python_version: 3.11.0
2025-05-12 21:41:32,743:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 21:41:32,743:INFO:machine: AMD64
2025-05-12 21:41:32,743:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 21:41:32,755:INFO:Memory: svmem(total=12759322624, available=1693810688, percent=86.7, used=11065511936, free=1693810688)
2025-05-12 21:41:32,756:INFO:Physical Core: 4
2025-05-12 21:41:32,758:INFO:Logical Core: 8
2025-05-12 21:41:32,758:INFO:Checking libraries
2025-05-12 21:41:32,758:INFO:System:
2025-05-12 21:41:32,759:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 21:41:32,759:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:41:32,759:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 21:41:32,759:INFO:PyCaret required dependencies:
2025-05-12 21:41:32,949:INFO:                 pip: 22.3
2025-05-12 21:41:32,950:INFO:          setuptools: 65.5.0
2025-05-12 21:41:32,950:INFO:             pycaret: 3.3.2
2025-05-12 21:41:32,950:INFO:             IPython: 9.2.0
2025-05-12 21:41:32,950:INFO:          ipywidgets: 8.1.7
2025-05-12 21:41:32,950:INFO:                tqdm: 4.67.1
2025-05-12 21:41:32,950:INFO:               numpy: 1.26.4
2025-05-12 21:41:32,950:INFO:              pandas: 2.1.4
2025-05-12 21:41:32,950:INFO:              jinja2: 3.1.6
2025-05-12 21:41:32,950:INFO:               scipy: 1.11.4
2025-05-12 21:41:32,950:INFO:              joblib: 1.3.2
2025-05-12 21:41:32,950:INFO:             sklearn: 1.4.2
2025-05-12 21:41:32,950:INFO:                pyod: 2.0.5
2025-05-12 21:41:32,950:INFO:            imblearn: 0.13.0
2025-05-12 21:41:32,950:INFO:   category_encoders: 2.7.0
2025-05-12 21:41:32,950:INFO:            lightgbm: 4.6.0
2025-05-12 21:41:32,951:INFO:               numba: 0.61.2
2025-05-12 21:41:32,951:INFO:            requests: 2.32.3
2025-05-12 21:41:32,951:INFO:          matplotlib: 3.7.5
2025-05-12 21:41:32,951:INFO:          scikitplot: 0.3.7
2025-05-12 21:41:32,951:INFO:         yellowbrick: 1.5
2025-05-12 21:41:32,951:INFO:              plotly: 5.24.1
2025-05-12 21:41:32,951:INFO:    plotly-resampler: Not installed
2025-05-12 21:41:32,951:INFO:             kaleido: 0.2.1
2025-05-12 21:41:32,951:INFO:           schemdraw: 0.15
2025-05-12 21:41:32,951:INFO:         statsmodels: 0.14.4
2025-05-12 21:41:32,952:INFO:              sktime: 0.26.0
2025-05-12 21:41:32,952:INFO:               tbats: 1.1.3
2025-05-12 21:41:32,952:INFO:            pmdarima: 2.0.4
2025-05-12 21:41:32,952:INFO:              psutil: 7.0.0
2025-05-12 21:41:32,952:INFO:          markupsafe: 3.0.2
2025-05-12 21:41:32,953:INFO:             pickle5: Not installed
2025-05-12 21:41:32,953:INFO:         cloudpickle: 3.1.1
2025-05-12 21:41:32,953:INFO:         deprecation: 2.1.0
2025-05-12 21:41:32,954:INFO:              xxhash: 3.5.0
2025-05-12 21:41:32,955:INFO:           wurlitzer: Not installed
2025-05-12 21:41:32,955:INFO:PyCaret optional dependencies:
2025-05-12 21:41:32,995:INFO:                shap: Not installed
2025-05-12 21:41:32,995:INFO:           interpret: Not installed
2025-05-12 21:41:32,995:INFO:                umap: Not installed
2025-05-12 21:41:32,995:INFO:     ydata_profiling: Not installed
2025-05-12 21:41:32,995:INFO:  explainerdashboard: Not installed
2025-05-12 21:41:32,995:INFO:             autoviz: Not installed
2025-05-12 21:41:32,995:INFO:           fairlearn: Not installed
2025-05-12 21:41:32,995:INFO:          deepchecks: Not installed
2025-05-12 21:41:32,995:INFO:             xgboost: Not installed
2025-05-12 21:41:32,995:INFO:            catboost: Not installed
2025-05-12 21:41:32,995:INFO:              kmodes: Not installed
2025-05-12 21:41:32,996:INFO:             mlxtend: Not installed
2025-05-12 21:41:32,996:INFO:       statsforecast: Not installed
2025-05-12 21:41:32,996:INFO:        tune_sklearn: Not installed
2025-05-12 21:41:32,996:INFO:                 ray: Not installed
2025-05-12 21:41:32,996:INFO:            hyperopt: Not installed
2025-05-12 21:41:32,996:INFO:              optuna: Not installed
2025-05-12 21:41:32,996:INFO:               skopt: Not installed
2025-05-12 21:41:32,996:INFO:              mlflow: Not installed
2025-05-12 21:41:32,996:INFO:              gradio: Not installed
2025-05-12 21:41:32,996:INFO:             fastapi: Not installed
2025-05-12 21:41:32,996:INFO:             uvicorn: Not installed
2025-05-12 21:41:32,996:INFO:              m2cgen: Not installed
2025-05-12 21:41:32,996:INFO:           evidently: Not installed
2025-05-12 21:41:32,996:INFO:               fugue: Not installed
2025-05-12 21:41:32,997:INFO:           streamlit: Not installed
2025-05-12 21:41:32,997:INFO:             prophet: Not installed
2025-05-12 21:41:32,997:INFO:None
2025-05-12 21:41:32,997:INFO:Set up data.
2025-05-12 21:41:33,015:INFO:Set up folding strategy.
2025-05-12 21:41:33,015:INFO:Set up train/test split.
2025-05-12 21:41:33,096:INFO:Set up index.
2025-05-12 21:41:33,098:INFO:Assigning column types.
2025-05-12 21:41:33,108:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:41:33,109:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,118:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,326:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,474:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:41:33,479:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,484:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,603:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,711:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:41:33,720:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,779:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:33,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:33,947:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:41:34,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:41:34,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:41:34,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,559:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:41:34,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:34,783:INFO:Preparing preprocessing pipeline...
2025-05-12 21:41:34,783:INFO:Set up simple imputation.
2025-05-12 21:41:34,788:INFO:Set up encoding of categorical features.
2025-05-12 21:41:34,789:INFO:Set up feature normalization.
2025-05-12 21:41:34,845:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:41:34,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:41:34,854:INFO:Creating final display dataframe.
2025-05-12 21:41:34,997:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              a710
2025-05-12 21:41:35,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:41:35,232:INFO:setup() successfully completed in 2.49s...............
2025-05-12 21:41:57,222:INFO:Initializing compare_models()
2025-05-12 21:41:57,222:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:41:57,222:INFO:Checking exceptions
2025-05-12 21:41:57,226:INFO:Preparing display monitor
2025-05-12 21:41:57,284:INFO:Initializing Linear Regression
2025-05-12 21:41:57,284:INFO:Total runtime is 0.0 minutes
2025-05-12 21:41:57,294:INFO:SubProcess create_model() called ==================================
2025-05-12 21:41:57,296:INFO:Initializing create_model()
2025-05-12 21:41:57,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:41:57,296:INFO:Checking exceptions
2025-05-12 21:41:57,296:INFO:Importing libraries
2025-05-12 21:41:57,297:INFO:Copying training dataset
2025-05-12 21:41:57,305:INFO:Defining folds
2025-05-12 21:41:57,305:INFO:Declaring metric variables
2025-05-12 21:41:57,316:INFO:Importing untrained model
2025-05-12 21:41:57,322:INFO:Linear Regression Imported successfully
2025-05-12 21:41:57,331:INFO:Starting cross validation
2025-05-12 21:41:57,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:11,081:INFO:Calculating mean and std
2025-05-12 21:42:11,084:INFO:Creating metrics dataframe
2025-05-12 21:42:11,088:INFO:Uploading results into container
2025-05-12 21:42:11,090:INFO:Uploading model into container now
2025-05-12 21:42:11,091:INFO:_master_model_container: 1
2025-05-12 21:42:11,092:INFO:_display_container: 2
2025-05-12 21:42:11,092:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:11,093:INFO:create_model() successfully completed......................................
2025-05-12 21:42:11,203:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:11,203:INFO:Creating metrics dataframe
2025-05-12 21:42:11,214:INFO:Initializing Lasso Regression
2025-05-12 21:42:11,215:INFO:Total runtime is 0.23218616247177123 minutes
2025-05-12 21:42:11,223:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:11,223:INFO:Initializing create_model()
2025-05-12 21:42:11,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:11,224:INFO:Checking exceptions
2025-05-12 21:42:11,224:INFO:Importing libraries
2025-05-12 21:42:11,224:INFO:Copying training dataset
2025-05-12 21:42:11,231:INFO:Defining folds
2025-05-12 21:42:11,231:INFO:Declaring metric variables
2025-05-12 21:42:11,238:INFO:Importing untrained model
2025-05-12 21:42:11,244:INFO:Lasso Regression Imported successfully
2025-05-12 21:42:11,258:INFO:Starting cross validation
2025-05-12 21:42:11,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:11,602:INFO:Calculating mean and std
2025-05-12 21:42:11,604:INFO:Creating metrics dataframe
2025-05-12 21:42:11,609:INFO:Uploading results into container
2025-05-12 21:42:11,611:INFO:Uploading model into container now
2025-05-12 21:42:11,611:INFO:_master_model_container: 2
2025-05-12 21:42:11,611:INFO:_display_container: 2
2025-05-12 21:42:11,612:INFO:Lasso(random_state=123)
2025-05-12 21:42:11,612:INFO:create_model() successfully completed......................................
2025-05-12 21:42:11,705:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:11,705:INFO:Creating metrics dataframe
2025-05-12 21:42:11,715:INFO:Initializing Ridge Regression
2025-05-12 21:42:11,716:INFO:Total runtime is 0.2405272841453552 minutes
2025-05-12 21:42:11,722:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:11,723:INFO:Initializing create_model()
2025-05-12 21:42:11,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:11,723:INFO:Checking exceptions
2025-05-12 21:42:11,723:INFO:Importing libraries
2025-05-12 21:42:11,723:INFO:Copying training dataset
2025-05-12 21:42:11,730:INFO:Defining folds
2025-05-12 21:42:11,730:INFO:Declaring metric variables
2025-05-12 21:42:11,736:INFO:Importing untrained model
2025-05-12 21:42:11,746:INFO:Ridge Regression Imported successfully
2025-05-12 21:42:11,761:INFO:Starting cross validation
2025-05-12 21:42:11,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:12,120:INFO:Calculating mean and std
2025-05-12 21:42:12,122:INFO:Creating metrics dataframe
2025-05-12 21:42:12,125:INFO:Uploading results into container
2025-05-12 21:42:12,126:INFO:Uploading model into container now
2025-05-12 21:42:12,127:INFO:_master_model_container: 3
2025-05-12 21:42:12,127:INFO:_display_container: 2
2025-05-12 21:42:12,128:INFO:Ridge(random_state=123)
2025-05-12 21:42:12,128:INFO:create_model() successfully completed......................................
2025-05-12 21:42:12,238:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:12,238:INFO:Creating metrics dataframe
2025-05-12 21:42:12,252:INFO:Initializing Elastic Net
2025-05-12 21:42:12,252:INFO:Total runtime is 0.24947164853413897 minutes
2025-05-12 21:42:12,260:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:12,260:INFO:Initializing create_model()
2025-05-12 21:42:12,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:12,261:INFO:Checking exceptions
2025-05-12 21:42:12,261:INFO:Importing libraries
2025-05-12 21:42:12,261:INFO:Copying training dataset
2025-05-12 21:42:12,271:INFO:Defining folds
2025-05-12 21:42:12,271:INFO:Declaring metric variables
2025-05-12 21:42:12,277:INFO:Importing untrained model
2025-05-12 21:42:12,288:INFO:Elastic Net Imported successfully
2025-05-12 21:42:12,299:INFO:Starting cross validation
2025-05-12 21:42:12,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:12,621:INFO:Calculating mean and std
2025-05-12 21:42:12,623:INFO:Creating metrics dataframe
2025-05-12 21:42:12,625:INFO:Uploading results into container
2025-05-12 21:42:12,626:INFO:Uploading model into container now
2025-05-12 21:42:12,626:INFO:_master_model_container: 4
2025-05-12 21:42:12,626:INFO:_display_container: 2
2025-05-12 21:42:12,627:INFO:ElasticNet(random_state=123)
2025-05-12 21:42:12,627:INFO:create_model() successfully completed......................................
2025-05-12 21:42:12,712:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:12,712:INFO:Creating metrics dataframe
2025-05-12 21:42:12,722:INFO:Initializing Least Angle Regression
2025-05-12 21:42:12,723:INFO:Total runtime is 0.25730806191762284 minutes
2025-05-12 21:42:12,728:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:12,729:INFO:Initializing create_model()
2025-05-12 21:42:12,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:12,729:INFO:Checking exceptions
2025-05-12 21:42:12,729:INFO:Importing libraries
2025-05-12 21:42:12,729:INFO:Copying training dataset
2025-05-12 21:42:12,739:INFO:Defining folds
2025-05-12 21:42:12,739:INFO:Declaring metric variables
2025-05-12 21:42:12,744:INFO:Importing untrained model
2025-05-12 21:42:12,753:INFO:Least Angle Regression Imported successfully
2025-05-12 21:42:12,764:INFO:Starting cross validation
2025-05-12 21:42:12,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:13,162:INFO:Calculating mean and std
2025-05-12 21:42:13,164:INFO:Creating metrics dataframe
2025-05-12 21:42:13,168:INFO:Uploading results into container
2025-05-12 21:42:13,169:INFO:Uploading model into container now
2025-05-12 21:42:13,170:INFO:_master_model_container: 5
2025-05-12 21:42:13,170:INFO:_display_container: 2
2025-05-12 21:42:13,171:INFO:Lars(random_state=123)
2025-05-12 21:42:13,171:INFO:create_model() successfully completed......................................
2025-05-12 21:42:13,274:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:13,274:INFO:Creating metrics dataframe
2025-05-12 21:42:13,289:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:42:13,289:INFO:Total runtime is 0.26675569216410316 minutes
2025-05-12 21:42:13,294:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:13,296:INFO:Initializing create_model()
2025-05-12 21:42:13,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:13,297:INFO:Checking exceptions
2025-05-12 21:42:13,298:INFO:Importing libraries
2025-05-12 21:42:13,298:INFO:Copying training dataset
2025-05-12 21:42:13,310:INFO:Defining folds
2025-05-12 21:42:13,311:INFO:Declaring metric variables
2025-05-12 21:42:13,321:INFO:Importing untrained model
2025-05-12 21:42:13,330:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:42:13,343:INFO:Starting cross validation
2025-05-12 21:42:13,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:13,653:INFO:Calculating mean and std
2025-05-12 21:42:13,656:INFO:Creating metrics dataframe
2025-05-12 21:42:13,660:INFO:Uploading results into container
2025-05-12 21:42:13,661:INFO:Uploading model into container now
2025-05-12 21:42:13,662:INFO:_master_model_container: 6
2025-05-12 21:42:13,662:INFO:_display_container: 2
2025-05-12 21:42:13,663:INFO:LassoLars(random_state=123)
2025-05-12 21:42:13,663:INFO:create_model() successfully completed......................................
2025-05-12 21:42:13,765:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:13,765:INFO:Creating metrics dataframe
2025-05-12 21:42:13,779:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:42:13,779:INFO:Total runtime is 0.27492601474126177 minutes
2025-05-12 21:42:13,786:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:13,787:INFO:Initializing create_model()
2025-05-12 21:42:13,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:13,787:INFO:Checking exceptions
2025-05-12 21:42:13,788:INFO:Importing libraries
2025-05-12 21:42:13,788:INFO:Copying training dataset
2025-05-12 21:42:13,799:INFO:Defining folds
2025-05-12 21:42:13,799:INFO:Declaring metric variables
2025-05-12 21:42:13,810:INFO:Importing untrained model
2025-05-12 21:42:13,820:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:42:13,840:INFO:Starting cross validation
2025-05-12 21:42:13,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,188:INFO:Calculating mean and std
2025-05-12 21:42:14,190:INFO:Creating metrics dataframe
2025-05-12 21:42:14,193:INFO:Uploading results into container
2025-05-12 21:42:14,194:INFO:Uploading model into container now
2025-05-12 21:42:14,195:INFO:_master_model_container: 7
2025-05-12 21:42:14,195:INFO:_display_container: 2
2025-05-12 21:42:14,196:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:42:14,196:INFO:create_model() successfully completed......................................
2025-05-12 21:42:14,286:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:14,286:INFO:Creating metrics dataframe
2025-05-12 21:42:14,297:INFO:Initializing Bayesian Ridge
2025-05-12 21:42:14,298:INFO:Total runtime is 0.2835631728172302 minutes
2025-05-12 21:42:14,304:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:14,304:INFO:Initializing create_model()
2025-05-12 21:42:14,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:14,304:INFO:Checking exceptions
2025-05-12 21:42:14,305:INFO:Importing libraries
2025-05-12 21:42:14,305:INFO:Copying training dataset
2025-05-12 21:42:14,311:INFO:Defining folds
2025-05-12 21:42:14,311:INFO:Declaring metric variables
2025-05-12 21:42:14,318:INFO:Importing untrained model
2025-05-12 21:42:14,326:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:42:14,341:INFO:Starting cross validation
2025-05-12 21:42:14,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,646:INFO:Calculating mean and std
2025-05-12 21:42:14,649:INFO:Creating metrics dataframe
2025-05-12 21:42:14,652:INFO:Uploading results into container
2025-05-12 21:42:14,654:INFO:Uploading model into container now
2025-05-12 21:42:14,655:INFO:_master_model_container: 8
2025-05-12 21:42:14,655:INFO:_display_container: 2
2025-05-12 21:42:14,655:INFO:BayesianRidge()
2025-05-12 21:42:14,655:INFO:create_model() successfully completed......................................
2025-05-12 21:42:14,746:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:14,746:INFO:Creating metrics dataframe
2025-05-12 21:42:14,760:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:42:14,761:INFO:Total runtime is 0.2912874658902486 minutes
2025-05-12 21:42:14,768:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:14,769:INFO:Initializing create_model()
2025-05-12 21:42:14,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:14,769:INFO:Checking exceptions
2025-05-12 21:42:14,769:INFO:Importing libraries
2025-05-12 21:42:14,770:INFO:Copying training dataset
2025-05-12 21:42:14,782:INFO:Defining folds
2025-05-12 21:42:14,783:INFO:Declaring metric variables
2025-05-12 21:42:14,789:INFO:Importing untrained model
2025-05-12 21:42:14,798:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:42:14,810:INFO:Starting cross validation
2025-05-12 21:42:14,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,965:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,966:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,967:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:14,980:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,077:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,084:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:42:15,120:INFO:Calculating mean and std
2025-05-12 21:42:15,123:INFO:Creating metrics dataframe
2025-05-12 21:42:15,126:INFO:Uploading results into container
2025-05-12 21:42:15,127:INFO:Uploading model into container now
2025-05-12 21:42:15,128:INFO:_master_model_container: 9
2025-05-12 21:42:15,129:INFO:_display_container: 2
2025-05-12 21:42:15,129:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:42:15,130:INFO:create_model() successfully completed......................................
2025-05-12 21:42:15,219:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:15,219:INFO:Creating metrics dataframe
2025-05-12 21:42:15,230:INFO:Initializing Huber Regressor
2025-05-12 21:42:15,231:INFO:Total runtime is 0.2991190433502197 minutes
2025-05-12 21:42:15,237:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:15,238:INFO:Initializing create_model()
2025-05-12 21:42:15,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:15,238:INFO:Checking exceptions
2025-05-12 21:42:15,238:INFO:Importing libraries
2025-05-12 21:42:15,238:INFO:Copying training dataset
2025-05-12 21:42:15,244:INFO:Defining folds
2025-05-12 21:42:15,244:INFO:Declaring metric variables
2025-05-12 21:42:15,250:INFO:Importing untrained model
2025-05-12 21:42:15,257:INFO:Huber Regressor Imported successfully
2025-05-12 21:42:15,269:INFO:Starting cross validation
2025-05-12 21:42:15,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:15,606:INFO:Calculating mean and std
2025-05-12 21:42:15,608:INFO:Creating metrics dataframe
2025-05-12 21:42:15,612:INFO:Uploading results into container
2025-05-12 21:42:15,612:INFO:Uploading model into container now
2025-05-12 21:42:15,613:INFO:_master_model_container: 10
2025-05-12 21:42:15,613:INFO:_display_container: 2
2025-05-12 21:42:15,614:INFO:HuberRegressor()
2025-05-12 21:42:15,614:INFO:create_model() successfully completed......................................
2025-05-12 21:42:15,718:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:15,718:INFO:Creating metrics dataframe
2025-05-12 21:42:15,736:INFO:Initializing K Neighbors Regressor
2025-05-12 21:42:15,736:INFO:Total runtime is 0.3075305501619975 minutes
2025-05-12 21:42:15,742:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:15,742:INFO:Initializing create_model()
2025-05-12 21:42:15,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:15,743:INFO:Checking exceptions
2025-05-12 21:42:15,743:INFO:Importing libraries
2025-05-12 21:42:15,743:INFO:Copying training dataset
2025-05-12 21:42:15,752:INFO:Defining folds
2025-05-12 21:42:15,752:INFO:Declaring metric variables
2025-05-12 21:42:15,760:INFO:Importing untrained model
2025-05-12 21:42:15,769:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:42:15,784:INFO:Starting cross validation
2025-05-12 21:42:15,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:16,168:INFO:Calculating mean and std
2025-05-12 21:42:16,172:INFO:Creating metrics dataframe
2025-05-12 21:42:16,179:INFO:Uploading results into container
2025-05-12 21:42:16,180:INFO:Uploading model into container now
2025-05-12 21:42:16,181:INFO:_master_model_container: 11
2025-05-12 21:42:16,181:INFO:_display_container: 2
2025-05-12 21:42:16,182:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:42:16,182:INFO:create_model() successfully completed......................................
2025-05-12 21:42:16,262:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:16,262:INFO:Creating metrics dataframe
2025-05-12 21:42:16,275:INFO:Initializing Decision Tree Regressor
2025-05-12 21:42:16,276:INFO:Total runtime is 0.31653995911280314 minutes
2025-05-12 21:42:16,280:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:16,280:INFO:Initializing create_model()
2025-05-12 21:42:16,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:16,281:INFO:Checking exceptions
2025-05-12 21:42:16,281:INFO:Importing libraries
2025-05-12 21:42:16,281:INFO:Copying training dataset
2025-05-12 21:42:16,287:INFO:Defining folds
2025-05-12 21:42:16,288:INFO:Declaring metric variables
2025-05-12 21:42:16,293:INFO:Importing untrained model
2025-05-12 21:42:16,301:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:42:16,352:INFO:Starting cross validation
2025-05-12 21:42:16,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:16,683:INFO:Calculating mean and std
2025-05-12 21:42:16,685:INFO:Creating metrics dataframe
2025-05-12 21:42:16,690:INFO:Uploading results into container
2025-05-12 21:42:16,691:INFO:Uploading model into container now
2025-05-12 21:42:16,691:INFO:_master_model_container: 12
2025-05-12 21:42:16,692:INFO:_display_container: 2
2025-05-12 21:42:16,693:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:42:16,693:INFO:create_model() successfully completed......................................
2025-05-12 21:42:16,787:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:16,788:INFO:Creating metrics dataframe
2025-05-12 21:42:16,802:INFO:Initializing Random Forest Regressor
2025-05-12 21:42:16,802:INFO:Total runtime is 0.3253070036570231 minutes
2025-05-12 21:42:16,808:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:16,809:INFO:Initializing create_model()
2025-05-12 21:42:16,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:16,809:INFO:Checking exceptions
2025-05-12 21:42:16,809:INFO:Importing libraries
2025-05-12 21:42:16,810:INFO:Copying training dataset
2025-05-12 21:42:16,817:INFO:Defining folds
2025-05-12 21:42:16,817:INFO:Declaring metric variables
2025-05-12 21:42:16,824:INFO:Importing untrained model
2025-05-12 21:42:16,834:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:42:16,850:INFO:Starting cross validation
2025-05-12 21:42:16,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:18,063:INFO:Calculating mean and std
2025-05-12 21:42:18,066:INFO:Creating metrics dataframe
2025-05-12 21:42:18,072:INFO:Uploading results into container
2025-05-12 21:42:18,073:INFO:Uploading model into container now
2025-05-12 21:42:18,074:INFO:_master_model_container: 13
2025-05-12 21:42:18,074:INFO:_display_container: 2
2025-05-12 21:42:18,075:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:18,075:INFO:create_model() successfully completed......................................
2025-05-12 21:42:18,179:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:18,179:INFO:Creating metrics dataframe
2025-05-12 21:42:18,205:INFO:Initializing Extra Trees Regressor
2025-05-12 21:42:18,205:INFO:Total runtime is 0.34867718219757077 minutes
2025-05-12 21:42:18,212:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:18,213:INFO:Initializing create_model()
2025-05-12 21:42:18,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:18,213:INFO:Checking exceptions
2025-05-12 21:42:18,213:INFO:Importing libraries
2025-05-12 21:42:18,213:INFO:Copying training dataset
2025-05-12 21:42:18,223:INFO:Defining folds
2025-05-12 21:42:18,223:INFO:Declaring metric variables
2025-05-12 21:42:18,233:INFO:Importing untrained model
2025-05-12 21:42:18,241:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:42:18,255:INFO:Starting cross validation
2025-05-12 21:42:18,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:19,306:INFO:Calculating mean and std
2025-05-12 21:42:19,308:INFO:Creating metrics dataframe
2025-05-12 21:42:19,311:INFO:Uploading results into container
2025-05-12 21:42:19,313:INFO:Uploading model into container now
2025-05-12 21:42:19,313:INFO:_master_model_container: 14
2025-05-12 21:42:19,314:INFO:_display_container: 2
2025-05-12 21:42:19,315:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:19,315:INFO:create_model() successfully completed......................................
2025-05-12 21:42:19,408:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:19,408:INFO:Creating metrics dataframe
2025-05-12 21:42:19,424:INFO:Initializing AdaBoost Regressor
2025-05-12 21:42:19,424:INFO:Total runtime is 0.3690035939216613 minutes
2025-05-12 21:42:19,429:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:19,429:INFO:Initializing create_model()
2025-05-12 21:42:19,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:19,430:INFO:Checking exceptions
2025-05-12 21:42:19,430:INFO:Importing libraries
2025-05-12 21:42:19,430:INFO:Copying training dataset
2025-05-12 21:42:19,437:INFO:Defining folds
2025-05-12 21:42:19,437:INFO:Declaring metric variables
2025-05-12 21:42:19,444:INFO:Importing untrained model
2025-05-12 21:42:19,452:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:42:19,464:INFO:Starting cross validation
2025-05-12 21:42:19,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:20,047:INFO:Calculating mean and std
2025-05-12 21:42:20,050:INFO:Creating metrics dataframe
2025-05-12 21:42:20,053:INFO:Uploading results into container
2025-05-12 21:42:20,055:INFO:Uploading model into container now
2025-05-12 21:42:20,055:INFO:_master_model_container: 15
2025-05-12 21:42:20,055:INFO:_display_container: 2
2025-05-12 21:42:20,056:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:42:20,056:INFO:create_model() successfully completed......................................
2025-05-12 21:42:20,144:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:20,144:INFO:Creating metrics dataframe
2025-05-12 21:42:20,158:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:42:20,159:INFO:Total runtime is 0.3812346736590067 minutes
2025-05-12 21:42:20,163:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:20,163:INFO:Initializing create_model()
2025-05-12 21:42:20,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:20,163:INFO:Checking exceptions
2025-05-12 21:42:20,164:INFO:Importing libraries
2025-05-12 21:42:20,164:INFO:Copying training dataset
2025-05-12 21:42:20,171:INFO:Defining folds
2025-05-12 21:42:20,171:INFO:Declaring metric variables
2025-05-12 21:42:20,175:INFO:Importing untrained model
2025-05-12 21:42:20,184:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:42:20,193:INFO:Starting cross validation
2025-05-12 21:42:20,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:20,679:INFO:Calculating mean and std
2025-05-12 21:42:20,681:INFO:Creating metrics dataframe
2025-05-12 21:42:20,683:INFO:Uploading results into container
2025-05-12 21:42:20,684:INFO:Uploading model into container now
2025-05-12 21:42:20,684:INFO:_master_model_container: 16
2025-05-12 21:42:20,684:INFO:_display_container: 2
2025-05-12 21:42:20,685:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:42:20,685:INFO:create_model() successfully completed......................................
2025-05-12 21:42:20,777:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:20,778:INFO:Creating metrics dataframe
2025-05-12 21:42:20,794:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:42:20,794:INFO:Total runtime is 0.39183076222737623 minutes
2025-05-12 21:42:20,800:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:20,800:INFO:Initializing create_model()
2025-05-12 21:42:20,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:20,800:INFO:Checking exceptions
2025-05-12 21:42:20,801:INFO:Importing libraries
2025-05-12 21:42:20,801:INFO:Copying training dataset
2025-05-12 21:42:20,805:INFO:Defining folds
2025-05-12 21:42:20,805:INFO:Declaring metric variables
2025-05-12 21:42:20,810:INFO:Importing untrained model
2025-05-12 21:42:20,815:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:42:20,825:INFO:Starting cross validation
2025-05-12 21:42:20,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:21,358:INFO:Calculating mean and std
2025-05-12 21:42:21,361:INFO:Creating metrics dataframe
2025-05-12 21:42:21,366:INFO:Uploading results into container
2025-05-12 21:42:21,368:INFO:Uploading model into container now
2025-05-12 21:42:21,369:INFO:_master_model_container: 17
2025-05-12 21:42:21,369:INFO:_display_container: 2
2025-05-12 21:42:21,370:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:42:21,370:INFO:create_model() successfully completed......................................
2025-05-12 21:42:21,501:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:21,501:INFO:Creating metrics dataframe
2025-05-12 21:42:21,523:INFO:Initializing Dummy Regressor
2025-05-12 21:42:21,523:INFO:Total runtime is 0.4039914647738138 minutes
2025-05-12 21:42:21,534:INFO:SubProcess create_model() called ==================================
2025-05-12 21:42:21,535:INFO:Initializing create_model()
2025-05-12 21:42:21,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021274EB5F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:21,536:INFO:Checking exceptions
2025-05-12 21:42:21,536:INFO:Importing libraries
2025-05-12 21:42:21,536:INFO:Copying training dataset
2025-05-12 21:42:21,546:INFO:Defining folds
2025-05-12 21:42:21,546:INFO:Declaring metric variables
2025-05-12 21:42:21,557:INFO:Importing untrained model
2025-05-12 21:42:21,570:INFO:Dummy Regressor Imported successfully
2025-05-12 21:42:21,583:INFO:Starting cross validation
2025-05-12 21:42:21,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:21,962:INFO:Calculating mean and std
2025-05-12 21:42:21,967:INFO:Creating metrics dataframe
2025-05-12 21:42:21,972:INFO:Uploading results into container
2025-05-12 21:42:21,974:INFO:Uploading model into container now
2025-05-12 21:42:21,975:INFO:_master_model_container: 18
2025-05-12 21:42:21,975:INFO:_display_container: 2
2025-05-12 21:42:21,976:INFO:DummyRegressor()
2025-05-12 21:42:21,976:INFO:create_model() successfully completed......................................
2025-05-12 21:42:22,134:INFO:SubProcess create_model() end ==================================
2025-05-12 21:42:22,134:INFO:Creating metrics dataframe
2025-05-12 21:42:22,178:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:42:22,275:INFO:Initializing create_model()
2025-05-12 21:42:22,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:22,283:INFO:Checking exceptions
2025-05-12 21:42:22,302:INFO:Importing libraries
2025-05-12 21:42:22,302:INFO:Copying training dataset
2025-05-12 21:42:22,334:INFO:Defining folds
2025-05-12 21:42:22,334:INFO:Declaring metric variables
2025-05-12 21:42:22,335:INFO:Importing untrained model
2025-05-12 21:42:22,335:INFO:Declaring custom model
2025-05-12 21:42:22,339:INFO:Linear Regression Imported successfully
2025-05-12 21:42:22,344:INFO:Cross validation set to False
2025-05-12 21:42:22,344:INFO:Fitting Model
2025-05-12 21:42:22,469:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:22,469:INFO:create_model() successfully completed......................................
2025-05-12 21:42:22,653:INFO:_master_model_container: 18
2025-05-12 21:42:22,653:INFO:_display_container: 2
2025-05-12 21:42:22,654:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:22,654:INFO:compare_models() successfully completed......................................
2025-05-12 21:42:30,783:INFO:Initializing create_model()
2025-05-12 21:42:30,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:30,783:INFO:Checking exceptions
2025-05-12 21:42:30,817:INFO:Importing libraries
2025-05-12 21:42:30,817:INFO:Copying training dataset
2025-05-12 21:42:30,826:INFO:Defining folds
2025-05-12 21:42:30,827:INFO:Declaring metric variables
2025-05-12 21:42:30,836:INFO:Importing untrained model
2025-05-12 21:42:30,845:INFO:Linear Regression Imported successfully
2025-05-12 21:42:30,869:INFO:Starting cross validation
2025-05-12 21:42:30,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:31,709:INFO:Calculating mean and std
2025-05-12 21:42:31,711:INFO:Creating metrics dataframe
2025-05-12 21:42:31,734:INFO:Finalizing model
2025-05-12 21:42:31,915:INFO:Uploading results into container
2025-05-12 21:42:31,920:INFO:Uploading model into container now
2025-05-12 21:42:31,967:INFO:_master_model_container: 19
2025-05-12 21:42:31,968:INFO:_display_container: 3
2025-05-12 21:42:31,968:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:31,969:INFO:create_model() successfully completed......................................
2025-05-12 21:42:45,943:INFO:Initializing create_model()
2025-05-12 21:42:45,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:42:45,943:INFO:Checking exceptions
2025-05-12 21:42:45,971:INFO:Importing libraries
2025-05-12 21:42:45,971:INFO:Copying training dataset
2025-05-12 21:42:45,977:INFO:Defining folds
2025-05-12 21:42:45,979:INFO:Declaring metric variables
2025-05-12 21:42:45,986:INFO:Importing untrained model
2025-05-12 21:42:45,991:INFO:Linear Regression Imported successfully
2025-05-12 21:42:46,006:INFO:Starting cross validation
2025-05-12 21:42:46,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:42:46,486:INFO:Calculating mean and std
2025-05-12 21:42:46,487:INFO:Creating metrics dataframe
2025-05-12 21:42:46,499:INFO:Finalizing model
2025-05-12 21:42:46,591:INFO:Uploading results into container
2025-05-12 21:42:46,593:INFO:Uploading model into container now
2025-05-12 21:42:46,622:INFO:_master_model_container: 20
2025-05-12 21:42:46,623:INFO:_display_container: 4
2025-05-12 21:42:46,624:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:42:46,624:INFO:create_model() successfully completed......................................
2025-05-12 21:43:57,722:INFO:Initializing tune_model()
2025-05-12 21:43:57,722:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:43:57,722:INFO:Checking exceptions
2025-05-12 21:43:57,747:INFO:Copying training dataset
2025-05-12 21:43:57,752:INFO:Checking base model
2025-05-12 21:43:57,752:INFO:Base model : Linear Regression
2025-05-12 21:43:57,760:INFO:Declaring metric variables
2025-05-12 21:43:57,766:INFO:Defining Hyperparameters
2025-05-12 21:43:57,766:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:43:57,916:INFO:Tuning with n_jobs=-1
2025-05-12 21:43:57,917:INFO:Initializing GridSearchCV
2025-05-12 21:43:58,618:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:43:58,618:INFO:Hyperparameter search completed
2025-05-12 21:43:58,619:INFO:SubProcess create_model() called ==================================
2025-05-12 21:43:58,620:INFO:Initializing create_model()
2025-05-12 21:43:58,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021218DEF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:43:58,620:INFO:Checking exceptions
2025-05-12 21:43:58,621:INFO:Importing libraries
2025-05-12 21:43:58,621:INFO:Copying training dataset
2025-05-12 21:43:58,631:INFO:Defining folds
2025-05-12 21:43:58,631:INFO:Declaring metric variables
2025-05-12 21:43:58,639:INFO:Importing untrained model
2025-05-12 21:43:58,639:INFO:Declaring custom model
2025-05-12 21:43:58,646:INFO:Linear Regression Imported successfully
2025-05-12 21:43:58,665:INFO:Starting cross validation
2025-05-12 21:43:58,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:43:59,139:INFO:Calculating mean and std
2025-05-12 21:43:59,143:INFO:Creating metrics dataframe
2025-05-12 21:43:59,162:INFO:Finalizing model
2025-05-12 21:43:59,292:INFO:Uploading results into container
2025-05-12 21:43:59,294:INFO:Uploading model into container now
2025-05-12 21:43:59,295:INFO:_master_model_container: 21
2025-05-12 21:43:59,295:INFO:_display_container: 5
2025-05-12 21:43:59,296:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,296:INFO:create_model() successfully completed......................................
2025-05-12 21:43:59,407:INFO:SubProcess create_model() end ==================================
2025-05-12 21:43:59,408:INFO:choose_better activated
2025-05-12 21:43:59,412:INFO:SubProcess create_model() called ==================================
2025-05-12 21:43:59,413:INFO:Initializing create_model()
2025-05-12 21:43:59,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:43:59,413:INFO:Checking exceptions
2025-05-12 21:43:59,415:INFO:Importing libraries
2025-05-12 21:43:59,415:INFO:Copying training dataset
2025-05-12 21:43:59,421:INFO:Defining folds
2025-05-12 21:43:59,421:INFO:Declaring metric variables
2025-05-12 21:43:59,422:INFO:Importing untrained model
2025-05-12 21:43:59,422:INFO:Declaring custom model
2025-05-12 21:43:59,422:INFO:Linear Regression Imported successfully
2025-05-12 21:43:59,423:INFO:Starting cross validation
2025-05-12 21:43:59,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:43:59,725:INFO:Calculating mean and std
2025-05-12 21:43:59,727:INFO:Creating metrics dataframe
2025-05-12 21:43:59,733:INFO:Finalizing model
2025-05-12 21:43:59,822:INFO:Uploading results into container
2025-05-12 21:43:59,823:INFO:Uploading model into container now
2025-05-12 21:43:59,823:INFO:_master_model_container: 22
2025-05-12 21:43:59,824:INFO:_display_container: 6
2025-05-12 21:43:59,824:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,824:INFO:create_model() successfully completed......................................
2025-05-12 21:43:59,919:INFO:SubProcess create_model() end ==================================
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-05-12 21:43:59,920:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:43:59,921:INFO:choose_better completed
2025-05-12 21:43:59,921:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:43:59,933:INFO:_master_model_container: 22
2025-05-12 21:43:59,933:INFO:_display_container: 5
2025-05-12 21:43:59,934:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:43:59,934:INFO:tune_model() successfully completed......................................
2025-05-12 21:46:31,234:INFO:Initializing evaluate_model()
2025-05-12 21:46:31,234:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:46:31,243:INFO:Initializing plot_model()
2025-05-12 21:46:31,243:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:46:31,244:INFO:Checking exceptions
2025-05-12 21:46:31,247:INFO:Preloading libraries
2025-05-12 21:46:31,247:INFO:Copying training dataset
2025-05-12 21:46:31,248:INFO:Plot type: pipeline
2025-05-12 21:46:31,754:INFO:Visual Rendered Successfully
2025-05-12 21:46:31,995:INFO:plot_model() successfully completed......................................
2025-05-12 21:47:16,907:INFO:Initializing predict_model()
2025-05-12 21:47:16,908:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000021218DEF710>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021219076340>)
2025-05-12 21:47:16,908:INFO:Checking exceptions
2025-05-12 21:47:16,908:INFO:Preloading libraries
2025-05-12 21:47:17,371:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:00:56,427:INFO:Initializing save_model()
2025-05-12 22:00:56,428:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:00:56,428:INFO:Adding model into prep_pipe
2025-05-12 22:00:56,439:INFO:modelo_precio_final.pkl saved in current working directory
2025-05-12 22:00:56,448:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-05-12 22:00:56,448:INFO:save_model() successfully completed......................................
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:11:05,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:14:10,348:INFO:PyCaret RegressionExperiment
2025-05-12 22:14:10,349:INFO:Logging name: reg-default-name
2025-05-12 22:14:10,349:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:14:10,349:INFO:version 3.3.2
2025-05-12 22:14:10,349:INFO:Initializing setup()
2025-05-12 22:14:10,349:INFO:self.USI: beb0
2025-05-12 22:14:10,349:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'html_param', 'data', 'transform_target_param', 'y', 'gpu_param', 'logging_param', 'exp_name_log', 'exp_id', 'X_test', 'pipeline', 'n_jobs_param', 'USI', 'log_plots_param', 'fold_shuffle_param', 'idx', 'y_train', '_available_plots', 'X', 'target_param', '_ml_usecase', 'memory', 'y_test', 'fold_generator', 'X_train', 'fold_groups_param'}
2025-05-12 22:14:10,349:INFO:Checking environment
2025-05-12 22:14:10,349:INFO:python_version: 3.11.0
2025-05-12 22:14:10,349:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 22:14:10,349:INFO:machine: AMD64
2025-05-12 22:14:10,349:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 22:14:10,355:INFO:Memory: svmem(total=12759322624, available=1950679040, percent=84.7, used=10808643584, free=1950679040)
2025-05-12 22:14:10,355:INFO:Physical Core: 4
2025-05-12 22:14:10,355:INFO:Logical Core: 8
2025-05-12 22:14:10,355:INFO:Checking libraries
2025-05-12 22:14:10,356:INFO:System:
2025-05-12 22:14:10,356:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 22:14:10,356:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:14:10,356:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 22:14:10,356:INFO:PyCaret required dependencies:
2025-05-12 22:14:10,400:INFO:                 pip: 22.3
2025-05-12 22:14:10,400:INFO:          setuptools: 65.5.0
2025-05-12 22:14:10,400:INFO:             pycaret: 3.3.2
2025-05-12 22:14:10,400:INFO:             IPython: 9.2.0
2025-05-12 22:14:10,400:INFO:          ipywidgets: 8.1.7
2025-05-12 22:14:10,400:INFO:                tqdm: 4.67.1
2025-05-12 22:14:10,400:INFO:               numpy: 1.26.4
2025-05-12 22:14:10,400:INFO:              pandas: 2.1.4
2025-05-12 22:14:10,400:INFO:              jinja2: 3.1.6
2025-05-12 22:14:10,400:INFO:               scipy: 1.11.4
2025-05-12 22:14:10,400:INFO:              joblib: 1.3.2
2025-05-12 22:14:10,400:INFO:             sklearn: 1.4.2
2025-05-12 22:14:10,400:INFO:                pyod: 2.0.5
2025-05-12 22:14:10,400:INFO:            imblearn: 0.13.0
2025-05-12 22:14:10,400:INFO:   category_encoders: 2.7.0
2025-05-12 22:14:10,400:INFO:            lightgbm: 4.6.0
2025-05-12 22:14:10,400:INFO:               numba: 0.61.2
2025-05-12 22:14:10,400:INFO:            requests: 2.32.3
2025-05-12 22:14:10,400:INFO:          matplotlib: 3.7.5
2025-05-12 22:14:10,400:INFO:          scikitplot: 0.3.7
2025-05-12 22:14:10,400:INFO:         yellowbrick: 1.5
2025-05-12 22:14:10,401:INFO:              plotly: 5.24.1
2025-05-12 22:14:10,401:INFO:    plotly-resampler: Not installed
2025-05-12 22:14:10,401:INFO:             kaleido: 0.2.1
2025-05-12 22:14:10,401:INFO:           schemdraw: 0.15
2025-05-12 22:14:10,401:INFO:         statsmodels: 0.14.4
2025-05-12 22:14:10,401:INFO:              sktime: 0.26.0
2025-05-12 22:14:10,401:INFO:               tbats: 1.1.3
2025-05-12 22:14:10,401:INFO:            pmdarima: 2.0.4
2025-05-12 22:14:10,401:INFO:              psutil: 7.0.0
2025-05-12 22:14:10,401:INFO:          markupsafe: 3.0.2
2025-05-12 22:14:10,401:INFO:             pickle5: Not installed
2025-05-12 22:14:10,401:INFO:         cloudpickle: 3.1.1
2025-05-12 22:14:10,401:INFO:         deprecation: 2.1.0
2025-05-12 22:14:10,401:INFO:              xxhash: 3.5.0
2025-05-12 22:14:10,401:INFO:           wurlitzer: Not installed
2025-05-12 22:14:10,401:INFO:PyCaret optional dependencies:
2025-05-12 22:14:10,418:INFO:                shap: Not installed
2025-05-12 22:14:10,419:INFO:           interpret: Not installed
2025-05-12 22:14:10,419:INFO:                umap: Not installed
2025-05-12 22:14:10,419:INFO:     ydata_profiling: Not installed
2025-05-12 22:14:10,419:INFO:  explainerdashboard: Not installed
2025-05-12 22:14:10,419:INFO:             autoviz: Not installed
2025-05-12 22:14:10,419:INFO:           fairlearn: Not installed
2025-05-12 22:14:10,419:INFO:          deepchecks: Not installed
2025-05-12 22:14:10,419:INFO:             xgboost: Not installed
2025-05-12 22:14:10,419:INFO:            catboost: Not installed
2025-05-12 22:14:10,419:INFO:              kmodes: Not installed
2025-05-12 22:14:10,419:INFO:             mlxtend: Not installed
2025-05-12 22:14:10,419:INFO:       statsforecast: Not installed
2025-05-12 22:14:10,420:INFO:        tune_sklearn: Not installed
2025-05-12 22:14:10,420:INFO:                 ray: Not installed
2025-05-12 22:14:10,420:INFO:            hyperopt: Not installed
2025-05-12 22:14:10,420:INFO:              optuna: Not installed
2025-05-12 22:14:10,420:INFO:               skopt: Not installed
2025-05-12 22:14:10,420:INFO:              mlflow: Not installed
2025-05-12 22:14:10,420:INFO:              gradio: Not installed
2025-05-12 22:14:10,420:INFO:             fastapi: Not installed
2025-05-12 22:14:10,420:INFO:             uvicorn: Not installed
2025-05-12 22:14:10,420:INFO:              m2cgen: Not installed
2025-05-12 22:14:10,420:INFO:           evidently: Not installed
2025-05-12 22:14:10,420:INFO:               fugue: Not installed
2025-05-12 22:14:10,420:INFO:           streamlit: Not installed
2025-05-12 22:14:10,421:INFO:             prophet: Not installed
2025-05-12 22:14:10,421:INFO:None
2025-05-12 22:14:10,421:INFO:Set up data.
2025-05-12 22:14:10,428:INFO:Set up folding strategy.
2025-05-12 22:14:10,428:INFO:Set up train/test split.
2025-05-12 22:14:10,436:INFO:Set up index.
2025-05-12 22:14:10,437:INFO:Assigning column types.
2025-05-12 22:14:10,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:14:10,441:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,445:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,558:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,694:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:14:10,700:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,708:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:10,855:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:10,950:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,011:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:14:11,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,270:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:14:11,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,572:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:14:11,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:14:11,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,797:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:14:11,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:11,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:14:12,052:INFO:Preparing preprocessing pipeline...
2025-05-12 22:14:12,052:INFO:Set up simple imputation.
2025-05-12 22:14:12,055:INFO:Set up encoding of categorical features.
2025-05-12 22:14:12,055:INFO:Set up feature normalization.
2025-05-12 22:15:09,876:INFO:PyCaret RegressionExperiment
2025-05-12 22:15:09,876:INFO:Logging name: reg-default-name
2025-05-12 22:15:09,876:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:15:09,876:INFO:version 3.3.2
2025-05-12 22:15:09,877:INFO:Initializing setup()
2025-05-12 22:15:09,877:INFO:self.USI: e29e
2025-05-12 22:15:09,877:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'html_param', 'data', 'transform_target_param', 'y', 'gpu_param', 'logging_param', 'exp_name_log', 'exp_id', 'X_test', 'pipeline', 'n_jobs_param', 'USI', 'log_plots_param', 'fold_shuffle_param', 'idx', 'y_train', '_available_plots', 'X', 'target_param', '_ml_usecase', 'memory', 'y_test', 'fold_generator', 'X_train', 'fold_groups_param'}
2025-05-12 22:15:09,877:INFO:Checking environment
2025-05-12 22:15:09,877:INFO:python_version: 3.11.0
2025-05-12 22:15:09,877:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-12 22:15:09,877:INFO:machine: AMD64
2025-05-12 22:15:09,877:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-12 22:15:09,905:INFO:Memory: svmem(total=12759322624, available=1700532224, percent=86.7, used=11058790400, free=1700532224)
2025-05-12 22:15:09,906:INFO:Physical Core: 4
2025-05-12 22:15:09,906:INFO:Logical Core: 8
2025-05-12 22:15:09,906:INFO:Checking libraries
2025-05-12 22:15:09,906:INFO:System:
2025-05-12 22:15:09,906:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-12 22:15:09,906:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:15:09,906:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-12 22:15:09,906:INFO:PyCaret required dependencies:
2025-05-12 22:15:09,906:INFO:                 pip: 22.3
2025-05-12 22:15:09,907:INFO:          setuptools: 65.5.0
2025-05-12 22:15:09,907:INFO:             pycaret: 3.3.2
2025-05-12 22:15:09,907:INFO:             IPython: 9.2.0
2025-05-12 22:15:09,907:INFO:          ipywidgets: 8.1.7
2025-05-12 22:15:09,907:INFO:                tqdm: 4.67.1
2025-05-12 22:15:09,907:INFO:               numpy: 1.26.4
2025-05-12 22:15:09,907:INFO:              pandas: 2.1.4
2025-05-12 22:15:09,907:INFO:              jinja2: 3.1.6
2025-05-12 22:15:09,907:INFO:               scipy: 1.11.4
2025-05-12 22:15:09,907:INFO:              joblib: 1.3.2
2025-05-12 22:15:09,907:INFO:             sklearn: 1.4.2
2025-05-12 22:15:09,908:INFO:                pyod: 2.0.5
2025-05-12 22:15:09,908:INFO:            imblearn: 0.13.0
2025-05-12 22:15:09,908:INFO:   category_encoders: 2.7.0
2025-05-12 22:15:09,908:INFO:            lightgbm: 4.6.0
2025-05-12 22:15:09,908:INFO:               numba: 0.61.2
2025-05-12 22:15:09,908:INFO:            requests: 2.32.3
2025-05-12 22:15:09,908:INFO:          matplotlib: 3.7.5
2025-05-12 22:15:09,908:INFO:          scikitplot: 0.3.7
2025-05-12 22:15:09,908:INFO:         yellowbrick: 1.5
2025-05-12 22:15:09,908:INFO:              plotly: 5.24.1
2025-05-12 22:15:09,908:INFO:    plotly-resampler: Not installed
2025-05-12 22:15:09,908:INFO:             kaleido: 0.2.1
2025-05-12 22:15:09,909:INFO:           schemdraw: 0.15
2025-05-12 22:15:09,909:INFO:         statsmodels: 0.14.4
2025-05-12 22:15:09,909:INFO:              sktime: 0.26.0
2025-05-12 22:15:09,909:INFO:               tbats: 1.1.3
2025-05-12 22:15:09,909:INFO:            pmdarima: 2.0.4
2025-05-12 22:15:09,909:INFO:              psutil: 7.0.0
2025-05-12 22:15:09,909:INFO:          markupsafe: 3.0.2
2025-05-12 22:15:09,909:INFO:             pickle5: Not installed
2025-05-12 22:15:09,909:INFO:         cloudpickle: 3.1.1
2025-05-12 22:15:09,909:INFO:         deprecation: 2.1.0
2025-05-12 22:15:09,909:INFO:              xxhash: 3.5.0
2025-05-12 22:15:09,909:INFO:           wurlitzer: Not installed
2025-05-12 22:15:09,909:INFO:PyCaret optional dependencies:
2025-05-12 22:15:09,910:INFO:                shap: Not installed
2025-05-12 22:15:09,910:INFO:           interpret: Not installed
2025-05-12 22:15:09,910:INFO:                umap: Not installed
2025-05-12 22:15:09,910:INFO:     ydata_profiling: Not installed
2025-05-12 22:15:09,910:INFO:  explainerdashboard: Not installed
2025-05-12 22:15:09,910:INFO:             autoviz: Not installed
2025-05-12 22:15:09,910:INFO:           fairlearn: Not installed
2025-05-12 22:15:09,910:INFO:          deepchecks: Not installed
2025-05-12 22:15:09,910:INFO:             xgboost: Not installed
2025-05-12 22:15:09,910:INFO:            catboost: Not installed
2025-05-12 22:15:09,910:INFO:              kmodes: Not installed
2025-05-12 22:15:09,910:INFO:             mlxtend: Not installed
2025-05-12 22:15:09,910:INFO:       statsforecast: Not installed
2025-05-12 22:15:09,911:INFO:        tune_sklearn: Not installed
2025-05-12 22:15:09,911:INFO:                 ray: Not installed
2025-05-12 22:15:09,911:INFO:            hyperopt: Not installed
2025-05-12 22:15:09,911:INFO:              optuna: Not installed
2025-05-12 22:15:09,911:INFO:               skopt: Not installed
2025-05-12 22:15:09,911:INFO:              mlflow: Not installed
2025-05-12 22:15:09,911:INFO:              gradio: Not installed
2025-05-12 22:15:09,911:INFO:             fastapi: Not installed
2025-05-12 22:15:09,911:INFO:             uvicorn: Not installed
2025-05-12 22:15:09,911:INFO:              m2cgen: Not installed
2025-05-12 22:15:09,911:INFO:           evidently: Not installed
2025-05-12 22:15:09,911:INFO:               fugue: Not installed
2025-05-12 22:15:09,911:INFO:           streamlit: Not installed
2025-05-12 22:15:09,911:INFO:             prophet: Not installed
2025-05-12 22:15:09,911:INFO:None
2025-05-12 22:15:09,911:INFO:Set up data.
2025-05-12 22:15:09,919:INFO:Set up folding strategy.
2025-05-12 22:15:09,919:INFO:Set up train/test split.
2025-05-12 22:15:09,927:INFO:Set up index.
2025-05-12 22:15:09,927:INFO:Assigning column types.
2025-05-12 22:15:09,938:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:15:09,938:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:15:09,958:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:09,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,104:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,110:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,116:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,252:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:15:10,258:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,444:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,453:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,542:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,611:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:15:10,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:10,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:10,951:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:15:11,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,341:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:15:11,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:15:11,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:11,988:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:15:12,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,386:INFO:Preparing preprocessing pipeline...
2025-05-12 22:15:12,386:INFO:Set up simple imputation.
2025-05-12 22:15:12,389:INFO:Set up encoding of categorical features.
2025-05-12 22:15:12,389:INFO:Set up feature normalization.
2025-05-12 22:15:12,488:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:15:12,501:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:15:12,501:INFO:Creating final display dataframe.
2025-05-12 22:15:12,782:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              e29e
2025-05-12 22:15:12,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:12,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:15:13,080:INFO:setup() successfully completed in 3.21s...............
2025-05-12 22:16:10,400:INFO:Initializing compare_models()
2025-05-12 22:16:10,400:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:16:10,400:INFO:Checking exceptions
2025-05-12 22:16:10,403:INFO:Preparing display monitor
2025-05-12 22:16:10,440:INFO:Initializing Linear Regression
2025-05-12 22:16:10,441:INFO:Total runtime is 1.661380132039388e-05 minutes
2025-05-12 22:16:10,448:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:10,449:INFO:Initializing create_model()
2025-05-12 22:16:10,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:10,449:INFO:Checking exceptions
2025-05-12 22:16:10,450:INFO:Importing libraries
2025-05-12 22:16:10,450:INFO:Copying training dataset
2025-05-12 22:16:10,459:INFO:Defining folds
2025-05-12 22:16:10,459:INFO:Declaring metric variables
2025-05-12 22:16:10,465:INFO:Importing untrained model
2025-05-12 22:16:10,471:INFO:Linear Regression Imported successfully
2025-05-12 22:16:10,484:INFO:Starting cross validation
2025-05-12 22:16:10,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:20,465:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:20,497:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:22,139:INFO:Calculating mean and std
2025-05-12 22:16:22,144:INFO:Creating metrics dataframe
2025-05-12 22:16:22,156:INFO:Uploading results into container
2025-05-12 22:16:22,158:INFO:Uploading model into container now
2025-05-12 22:16:22,161:INFO:_master_model_container: 1
2025-05-12 22:16:22,161:INFO:_display_container: 2
2025-05-12 22:16:22,162:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:16:22,162:INFO:create_model() successfully completed......................................
2025-05-12 22:16:22,347:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:22,348:INFO:Creating metrics dataframe
2025-05-12 22:16:22,374:INFO:Initializing Lasso Regression
2025-05-12 22:16:22,375:INFO:Total runtime is 0.1989244818687439 minutes
2025-05-12 22:16:22,384:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:22,384:INFO:Initializing create_model()
2025-05-12 22:16:22,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:22,385:INFO:Checking exceptions
2025-05-12 22:16:22,385:INFO:Importing libraries
2025-05-12 22:16:22,385:INFO:Copying training dataset
2025-05-12 22:16:22,398:INFO:Defining folds
2025-05-12 22:16:22,398:INFO:Declaring metric variables
2025-05-12 22:16:22,412:INFO:Importing untrained model
2025-05-12 22:16:22,423:INFO:Lasso Regression Imported successfully
2025-05-12 22:16:22,445:INFO:Starting cross validation
2025-05-12 22:16:22,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:22,953:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:22,953:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:22,960:INFO:Calculating mean and std
2025-05-12 22:16:22,965:INFO:Creating metrics dataframe
2025-05-12 22:16:22,973:INFO:Uploading results into container
2025-05-12 22:16:22,974:INFO:Uploading model into container now
2025-05-12 22:16:22,976:INFO:_master_model_container: 2
2025-05-12 22:16:22,976:INFO:_display_container: 2
2025-05-12 22:16:22,977:INFO:Lasso(random_state=123)
2025-05-12 22:16:22,978:INFO:create_model() successfully completed......................................
2025-05-12 22:16:23,108:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:23,108:INFO:Creating metrics dataframe
2025-05-12 22:16:23,124:INFO:Initializing Ridge Regression
2025-05-12 22:16:23,124:INFO:Total runtime is 0.21140274206797283 minutes
2025-05-12 22:16:23,131:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:23,132:INFO:Initializing create_model()
2025-05-12 22:16:23,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:23,132:INFO:Checking exceptions
2025-05-12 22:16:23,133:INFO:Importing libraries
2025-05-12 22:16:23,133:INFO:Copying training dataset
2025-05-12 22:16:23,145:INFO:Defining folds
2025-05-12 22:16:23,145:INFO:Declaring metric variables
2025-05-12 22:16:23,156:INFO:Importing untrained model
2025-05-12 22:16:23,166:INFO:Ridge Regression Imported successfully
2025-05-12 22:16:23,186:INFO:Starting cross validation
2025-05-12 22:16:23,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:23,630:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:23,631:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:23,642:INFO:Calculating mean and std
2025-05-12 22:16:23,645:INFO:Creating metrics dataframe
2025-05-12 22:16:23,649:INFO:Uploading results into container
2025-05-12 22:16:23,650:INFO:Uploading model into container now
2025-05-12 22:16:23,650:INFO:_master_model_container: 3
2025-05-12 22:16:23,651:INFO:_display_container: 2
2025-05-12 22:16:23,652:INFO:Ridge(random_state=123)
2025-05-12 22:16:23,652:INFO:create_model() successfully completed......................................
2025-05-12 22:16:23,768:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:23,769:INFO:Creating metrics dataframe
2025-05-12 22:16:23,784:INFO:Initializing Elastic Net
2025-05-12 22:16:23,784:INFO:Total runtime is 0.22240562438964845 minutes
2025-05-12 22:16:23,792:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:23,793:INFO:Initializing create_model()
2025-05-12 22:16:23,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:23,793:INFO:Checking exceptions
2025-05-12 22:16:23,793:INFO:Importing libraries
2025-05-12 22:16:23,793:INFO:Copying training dataset
2025-05-12 22:16:23,805:INFO:Defining folds
2025-05-12 22:16:23,805:INFO:Declaring metric variables
2025-05-12 22:16:23,815:INFO:Importing untrained model
2025-05-12 22:16:23,827:INFO:Elastic Net Imported successfully
2025-05-12 22:16:23,848:INFO:Starting cross validation
2025-05-12 22:16:23,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:24,302:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:24,303:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:24,310:INFO:Calculating mean and std
2025-05-12 22:16:24,312:INFO:Creating metrics dataframe
2025-05-12 22:16:24,315:INFO:Uploading results into container
2025-05-12 22:16:24,316:INFO:Uploading model into container now
2025-05-12 22:16:24,317:INFO:_master_model_container: 4
2025-05-12 22:16:24,317:INFO:_display_container: 2
2025-05-12 22:16:24,319:INFO:ElasticNet(random_state=123)
2025-05-12 22:16:24,319:INFO:create_model() successfully completed......................................
2025-05-12 22:16:24,430:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:24,431:INFO:Creating metrics dataframe
2025-05-12 22:16:24,448:INFO:Initializing Least Angle Regression
2025-05-12 22:16:24,449:INFO:Total runtime is 0.23349436124165854 minutes
2025-05-12 22:16:24,457:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:24,457:INFO:Initializing create_model()
2025-05-12 22:16:24,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:24,458:INFO:Checking exceptions
2025-05-12 22:16:24,458:INFO:Importing libraries
2025-05-12 22:16:24,458:INFO:Copying training dataset
2025-05-12 22:16:24,467:INFO:Defining folds
2025-05-12 22:16:24,467:INFO:Declaring metric variables
2025-05-12 22:16:24,477:INFO:Importing untrained model
2025-05-12 22:16:24,486:INFO:Least Angle Regression Imported successfully
2025-05-12 22:16:24,503:INFO:Starting cross validation
2025-05-12 22:16:24,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:24,960:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:24,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:24,964:INFO:Calculating mean and std
2025-05-12 22:16:24,966:INFO:Creating metrics dataframe
2025-05-12 22:16:24,971:INFO:Uploading results into container
2025-05-12 22:16:24,972:INFO:Uploading model into container now
2025-05-12 22:16:24,972:INFO:_master_model_container: 5
2025-05-12 22:16:24,972:INFO:_display_container: 2
2025-05-12 22:16:24,973:INFO:Lars(random_state=123)
2025-05-12 22:16:24,974:INFO:create_model() successfully completed......................................
2025-05-12 22:16:25,106:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:25,107:INFO:Creating metrics dataframe
2025-05-12 22:16:25,125:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:16:25,125:INFO:Total runtime is 0.24475714763005577 minutes
2025-05-12 22:16:25,134:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:25,135:INFO:Initializing create_model()
2025-05-12 22:16:25,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:25,136:INFO:Checking exceptions
2025-05-12 22:16:25,136:INFO:Importing libraries
2025-05-12 22:16:25,136:INFO:Copying training dataset
2025-05-12 22:16:25,144:INFO:Defining folds
2025-05-12 22:16:25,144:INFO:Declaring metric variables
2025-05-12 22:16:25,153:INFO:Importing untrained model
2025-05-12 22:16:25,162:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:16:25,178:INFO:Starting cross validation
2025-05-12 22:16:25,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:25,611:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:25,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:25,619:INFO:Calculating mean and std
2025-05-12 22:16:25,621:INFO:Creating metrics dataframe
2025-05-12 22:16:25,626:INFO:Uploading results into container
2025-05-12 22:16:25,627:INFO:Uploading model into container now
2025-05-12 22:16:25,628:INFO:_master_model_container: 6
2025-05-12 22:16:25,629:INFO:_display_container: 2
2025-05-12 22:16:25,630:INFO:LassoLars(random_state=123)
2025-05-12 22:16:25,630:INFO:create_model() successfully completed......................................
2025-05-12 22:16:25,753:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:25,754:INFO:Creating metrics dataframe
2025-05-12 22:16:25,775:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:16:25,776:INFO:Total runtime is 0.25560639301935834 minutes
2025-05-12 22:16:25,785:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:25,785:INFO:Initializing create_model()
2025-05-12 22:16:25,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:25,786:INFO:Checking exceptions
2025-05-12 22:16:25,787:INFO:Importing libraries
2025-05-12 22:16:25,787:INFO:Copying training dataset
2025-05-12 22:16:25,799:INFO:Defining folds
2025-05-12 22:16:25,799:INFO:Declaring metric variables
2025-05-12 22:16:25,810:INFO:Importing untrained model
2025-05-12 22:16:25,820:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:16:25,843:INFO:Starting cross validation
2025-05-12 22:16:25,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:26,438:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:26,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:26,449:INFO:Calculating mean and std
2025-05-12 22:16:26,453:INFO:Creating metrics dataframe
2025-05-12 22:16:26,465:INFO:Uploading results into container
2025-05-12 22:16:26,466:INFO:Uploading model into container now
2025-05-12 22:16:26,467:INFO:_master_model_container: 7
2025-05-12 22:16:26,467:INFO:_display_container: 2
2025-05-12 22:16:26,469:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:16:26,470:INFO:create_model() successfully completed......................................
2025-05-12 22:16:26,594:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:26,594:INFO:Creating metrics dataframe
2025-05-12 22:16:26,613:INFO:Initializing Bayesian Ridge
2025-05-12 22:16:26,613:INFO:Total runtime is 0.26956028143564864 minutes
2025-05-12 22:16:26,620:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:26,621:INFO:Initializing create_model()
2025-05-12 22:16:26,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:26,622:INFO:Checking exceptions
2025-05-12 22:16:26,622:INFO:Importing libraries
2025-05-12 22:16:26,623:INFO:Copying training dataset
2025-05-12 22:16:26,632:INFO:Defining folds
2025-05-12 22:16:26,632:INFO:Declaring metric variables
2025-05-12 22:16:26,642:INFO:Importing untrained model
2025-05-12 22:16:26,652:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:16:26,675:INFO:Starting cross validation
2025-05-12 22:16:26,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:27,333:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:27,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:27,361:INFO:Calculating mean and std
2025-05-12 22:16:27,364:INFO:Creating metrics dataframe
2025-05-12 22:16:27,370:INFO:Uploading results into container
2025-05-12 22:16:27,372:INFO:Uploading model into container now
2025-05-12 22:16:27,373:INFO:_master_model_container: 8
2025-05-12 22:16:27,373:INFO:_display_container: 2
2025-05-12 22:16:27,374:INFO:BayesianRidge()
2025-05-12 22:16:27,374:INFO:create_model() successfully completed......................................
2025-05-12 22:16:27,484:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:27,485:INFO:Creating metrics dataframe
2025-05-12 22:16:27,508:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:16:27,508:INFO:Total runtime is 0.2844772100448609 minutes
2025-05-12 22:16:27,516:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:27,516:INFO:Initializing create_model()
2025-05-12 22:16:27,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:27,517:INFO:Checking exceptions
2025-05-12 22:16:27,517:INFO:Importing libraries
2025-05-12 22:16:27,519:INFO:Copying training dataset
2025-05-12 22:16:27,533:INFO:Defining folds
2025-05-12 22:16:27,534:INFO:Declaring metric variables
2025-05-12 22:16:27,548:INFO:Importing untrained model
2025-05-12 22:16:27,561:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:16:27,582:INFO:Starting cross validation
2025-05-12 22:16:27,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:28,277:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:28,278:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:28,288:INFO:Calculating mean and std
2025-05-12 22:16:28,291:INFO:Creating metrics dataframe
2025-05-12 22:16:28,295:INFO:Uploading results into container
2025-05-12 22:16:28,296:INFO:Uploading model into container now
2025-05-12 22:16:28,297:INFO:_master_model_container: 9
2025-05-12 22:16:28,297:INFO:_display_container: 2
2025-05-12 22:16:28,298:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:16:28,299:INFO:create_model() successfully completed......................................
2025-05-12 22:16:28,439:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:28,439:INFO:Creating metrics dataframe
2025-05-12 22:16:28,459:INFO:Initializing Huber Regressor
2025-05-12 22:16:28,459:INFO:Total runtime is 0.3003216147422791 minutes
2025-05-12 22:16:28,467:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:28,468:INFO:Initializing create_model()
2025-05-12 22:16:28,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:28,469:INFO:Checking exceptions
2025-05-12 22:16:28,469:INFO:Importing libraries
2025-05-12 22:16:28,469:INFO:Copying training dataset
2025-05-12 22:16:28,478:INFO:Defining folds
2025-05-12 22:16:28,478:INFO:Declaring metric variables
2025-05-12 22:16:28,489:INFO:Importing untrained model
2025-05-12 22:16:28,495:INFO:Huber Regressor Imported successfully
2025-05-12 22:16:28,518:INFO:Starting cross validation
2025-05-12 22:16:28,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:29,583:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:29,584:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:29,593:INFO:Calculating mean and std
2025-05-12 22:16:29,595:INFO:Creating metrics dataframe
2025-05-12 22:16:29,602:INFO:Uploading results into container
2025-05-12 22:16:29,603:INFO:Uploading model into container now
2025-05-12 22:16:29,604:INFO:_master_model_container: 10
2025-05-12 22:16:29,604:INFO:_display_container: 2
2025-05-12 22:16:29,604:INFO:HuberRegressor()
2025-05-12 22:16:29,604:INFO:create_model() successfully completed......................................
2025-05-12 22:16:29,724:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:29,724:INFO:Creating metrics dataframe
2025-05-12 22:16:29,747:INFO:Initializing K Neighbors Regressor
2025-05-12 22:16:29,747:INFO:Total runtime is 0.32178559303283694 minutes
2025-05-12 22:16:29,755:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:29,756:INFO:Initializing create_model()
2025-05-12 22:16:29,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:29,757:INFO:Checking exceptions
2025-05-12 22:16:29,757:INFO:Importing libraries
2025-05-12 22:16:29,758:INFO:Copying training dataset
2025-05-12 22:16:29,766:INFO:Defining folds
2025-05-12 22:16:29,766:INFO:Declaring metric variables
2025-05-12 22:16:29,778:INFO:Importing untrained model
2025-05-12 22:16:29,790:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:16:29,814:INFO:Starting cross validation
2025-05-12 22:16:29,818:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:30,488:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:30,489:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:30,501:INFO:Calculating mean and std
2025-05-12 22:16:30,505:INFO:Creating metrics dataframe
2025-05-12 22:16:30,512:INFO:Uploading results into container
2025-05-12 22:16:30,514:INFO:Uploading model into container now
2025-05-12 22:16:30,515:INFO:_master_model_container: 11
2025-05-12 22:16:30,516:INFO:_display_container: 2
2025-05-12 22:16:30,517:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:16:30,519:INFO:create_model() successfully completed......................................
2025-05-12 22:16:30,815:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:30,815:INFO:Creating metrics dataframe
2025-05-12 22:16:30,848:INFO:Initializing Decision Tree Regressor
2025-05-12 22:16:30,848:INFO:Total runtime is 0.3401374737421672 minutes
2025-05-12 22:16:30,890:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:30,891:INFO:Initializing create_model()
2025-05-12 22:16:30,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:30,891:INFO:Checking exceptions
2025-05-12 22:16:30,891:INFO:Importing libraries
2025-05-12 22:16:30,892:INFO:Copying training dataset
2025-05-12 22:16:30,914:INFO:Defining folds
2025-05-12 22:16:30,915:INFO:Declaring metric variables
2025-05-12 22:16:30,933:INFO:Importing untrained model
2025-05-12 22:16:30,995:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:16:31,015:INFO:Starting cross validation
2025-05-12 22:16:31,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:31,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:31,612:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:31,618:INFO:Calculating mean and std
2025-05-12 22:16:31,620:INFO:Creating metrics dataframe
2025-05-12 22:16:31,624:INFO:Uploading results into container
2025-05-12 22:16:31,625:INFO:Uploading model into container now
2025-05-12 22:16:31,626:INFO:_master_model_container: 12
2025-05-12 22:16:31,627:INFO:_display_container: 2
2025-05-12 22:16:31,628:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:16:31,628:INFO:create_model() successfully completed......................................
2025-05-12 22:16:31,747:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:31,748:INFO:Creating metrics dataframe
2025-05-12 22:16:31,782:INFO:Initializing Random Forest Regressor
2025-05-12 22:16:31,782:INFO:Total runtime is 0.3557050744692485 minutes
2025-05-12 22:16:31,798:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:31,799:INFO:Initializing create_model()
2025-05-12 22:16:31,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:31,799:INFO:Checking exceptions
2025-05-12 22:16:31,800:INFO:Importing libraries
2025-05-12 22:16:31,800:INFO:Copying training dataset
2025-05-12 22:16:31,822:INFO:Defining folds
2025-05-12 22:16:31,822:INFO:Declaring metric variables
2025-05-12 22:16:31,833:INFO:Importing untrained model
2025-05-12 22:16:31,853:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:16:31,876:INFO:Starting cross validation
2025-05-12 22:16:31,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:33,241:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:33,242:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:33,251:INFO:Calculating mean and std
2025-05-12 22:16:33,254:INFO:Creating metrics dataframe
2025-05-12 22:16:33,260:INFO:Uploading results into container
2025-05-12 22:16:33,262:INFO:Uploading model into container now
2025-05-12 22:16:33,263:INFO:_master_model_container: 13
2025-05-12 22:16:33,263:INFO:_display_container: 2
2025-05-12 22:16:33,264:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:33,264:INFO:create_model() successfully completed......................................
2025-05-12 22:16:33,371:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:33,372:INFO:Creating metrics dataframe
2025-05-12 22:16:33,392:INFO:Initializing Extra Trees Regressor
2025-05-12 22:16:33,392:INFO:Total runtime is 0.3825367649396261 minutes
2025-05-12 22:16:33,398:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:33,398:INFO:Initializing create_model()
2025-05-12 22:16:33,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:33,398:INFO:Checking exceptions
2025-05-12 22:16:33,399:INFO:Importing libraries
2025-05-12 22:16:33,399:INFO:Copying training dataset
2025-05-12 22:16:33,407:INFO:Defining folds
2025-05-12 22:16:33,407:INFO:Declaring metric variables
2025-05-12 22:16:33,414:INFO:Importing untrained model
2025-05-12 22:16:33,422:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:16:33,436:INFO:Starting cross validation
2025-05-12 22:16:33,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:34,465:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:34,466:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:34,468:INFO:Calculating mean and std
2025-05-12 22:16:34,470:INFO:Creating metrics dataframe
2025-05-12 22:16:34,474:INFO:Uploading results into container
2025-05-12 22:16:34,475:INFO:Uploading model into container now
2025-05-12 22:16:34,476:INFO:_master_model_container: 14
2025-05-12 22:16:34,476:INFO:_display_container: 2
2025-05-12 22:16:34,477:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:34,477:INFO:create_model() successfully completed......................................
2025-05-12 22:16:34,571:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:34,571:INFO:Creating metrics dataframe
2025-05-12 22:16:34,586:INFO:Initializing AdaBoost Regressor
2025-05-12 22:16:34,586:INFO:Total runtime is 0.4024460752805074 minutes
2025-05-12 22:16:34,592:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:34,592:INFO:Initializing create_model()
2025-05-12 22:16:34,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:34,592:INFO:Checking exceptions
2025-05-12 22:16:34,593:INFO:Importing libraries
2025-05-12 22:16:34,593:INFO:Copying training dataset
2025-05-12 22:16:34,599:INFO:Defining folds
2025-05-12 22:16:34,599:INFO:Declaring metric variables
2025-05-12 22:16:34,606:INFO:Importing untrained model
2025-05-12 22:16:34,613:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:16:34,629:INFO:Starting cross validation
2025-05-12 22:16:34,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:35,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:35,334:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:35,338:INFO:Calculating mean and std
2025-05-12 22:16:35,340:INFO:Creating metrics dataframe
2025-05-12 22:16:35,344:INFO:Uploading results into container
2025-05-12 22:16:35,345:INFO:Uploading model into container now
2025-05-12 22:16:35,346:INFO:_master_model_container: 15
2025-05-12 22:16:35,346:INFO:_display_container: 2
2025-05-12 22:16:35,347:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:16:35,347:INFO:create_model() successfully completed......................................
2025-05-12 22:16:35,455:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:35,455:INFO:Creating metrics dataframe
2025-05-12 22:16:35,476:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:16:35,476:INFO:Total runtime is 0.4172772765159607 minutes
2025-05-12 22:16:35,484:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:35,485:INFO:Initializing create_model()
2025-05-12 22:16:35,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:35,486:INFO:Checking exceptions
2025-05-12 22:16:35,486:INFO:Importing libraries
2025-05-12 22:16:35,486:INFO:Copying training dataset
2025-05-12 22:16:35,550:INFO:Defining folds
2025-05-12 22:16:35,550:INFO:Declaring metric variables
2025-05-12 22:16:35,560:INFO:Importing untrained model
2025-05-12 22:16:35,608:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:16:35,641:INFO:Starting cross validation
2025-05-12 22:16:35,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:36,344:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:36,344:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:36,346:INFO:Calculating mean and std
2025-05-12 22:16:36,351:INFO:Creating metrics dataframe
2025-05-12 22:16:36,360:INFO:Uploading results into container
2025-05-12 22:16:36,361:INFO:Uploading model into container now
2025-05-12 22:16:36,362:INFO:_master_model_container: 16
2025-05-12 22:16:36,362:INFO:_display_container: 2
2025-05-12 22:16:36,363:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:16:36,363:INFO:create_model() successfully completed......................................
2025-05-12 22:16:36,469:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:36,470:INFO:Creating metrics dataframe
2025-05-12 22:16:36,495:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:16:36,495:INFO:Total runtime is 0.4342536012331645 minutes
2025-05-12 22:16:36,504:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:36,504:INFO:Initializing create_model()
2025-05-12 22:16:36,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:36,505:INFO:Checking exceptions
2025-05-12 22:16:36,505:INFO:Importing libraries
2025-05-12 22:16:36,505:INFO:Copying training dataset
2025-05-12 22:16:36,514:INFO:Defining folds
2025-05-12 22:16:36,515:INFO:Declaring metric variables
2025-05-12 22:16:36,526:INFO:Importing untrained model
2025-05-12 22:16:36,545:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:16:36,610:INFO:Starting cross validation
2025-05-12 22:16:36,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:37,926:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:37,926:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:37,950:INFO:Calculating mean and std
2025-05-12 22:16:37,953:INFO:Creating metrics dataframe
2025-05-12 22:16:37,958:INFO:Uploading results into container
2025-05-12 22:16:37,962:INFO:Uploading model into container now
2025-05-12 22:16:37,963:INFO:_master_model_container: 17
2025-05-12 22:16:37,963:INFO:_display_container: 2
2025-05-12 22:16:37,965:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:16:37,965:INFO:create_model() successfully completed......................................
2025-05-12 22:16:38,092:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:38,093:INFO:Creating metrics dataframe
2025-05-12 22:16:38,112:INFO:Initializing Dummy Regressor
2025-05-12 22:16:38,113:INFO:Total runtime is 0.4612179676691691 minutes
2025-05-12 22:16:38,120:INFO:SubProcess create_model() called ==================================
2025-05-12 22:16:38,121:INFO:Initializing create_model()
2025-05-12 22:16:38,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2CF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:38,121:INFO:Checking exceptions
2025-05-12 22:16:38,122:INFO:Importing libraries
2025-05-12 22:16:38,122:INFO:Copying training dataset
2025-05-12 22:16:38,137:INFO:Defining folds
2025-05-12 22:16:38,138:INFO:Declaring metric variables
2025-05-12 22:16:38,147:INFO:Importing untrained model
2025-05-12 22:16:38,163:INFO:Dummy Regressor Imported successfully
2025-05-12 22:16:38,194:INFO:Starting cross validation
2025-05-12 22:16:38,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:16:38,736:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:16:38,737:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:16:38,992:INFO:Calculating mean and std
2025-05-12 22:16:38,995:INFO:Creating metrics dataframe
2025-05-12 22:16:39,002:INFO:Uploading results into container
2025-05-12 22:16:39,003:INFO:Uploading model into container now
2025-05-12 22:16:39,004:INFO:_master_model_container: 18
2025-05-12 22:16:39,004:INFO:_display_container: 2
2025-05-12 22:16:39,004:INFO:DummyRegressor()
2025-05-12 22:16:39,005:INFO:create_model() successfully completed......................................
2025-05-12 22:16:39,315:INFO:SubProcess create_model() end ==================================
2025-05-12 22:16:39,315:INFO:Creating metrics dataframe
2025-05-12 22:16:39,345:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:16:39,370:INFO:Initializing create_model()
2025-05-12 22:16:39,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:16:39,371:INFO:Checking exceptions
2025-05-12 22:16:39,374:INFO:Importing libraries
2025-05-12 22:16:39,374:INFO:Copying training dataset
2025-05-12 22:16:39,386:INFO:Defining folds
2025-05-12 22:16:39,386:INFO:Declaring metric variables
2025-05-12 22:16:39,386:INFO:Importing untrained model
2025-05-12 22:16:39,386:INFO:Declaring custom model
2025-05-12 22:16:39,387:INFO:Lasso Regression Imported successfully
2025-05-12 22:16:39,392:INFO:Cross validation set to False
2025-05-12 22:16:39,392:INFO:Fitting Model
2025-05-12 22:16:39,503:INFO:Lasso(random_state=123)
2025-05-12 22:16:39,503:INFO:create_model() successfully completed......................................
2025-05-12 22:16:39,663:INFO:_master_model_container: 18
2025-05-12 22:16:39,663:INFO:_display_container: 2
2025-05-12 22:16:39,664:INFO:Lasso(random_state=123)
2025-05-12 22:16:39,664:INFO:compare_models() successfully completed......................................
2025-05-12 22:18:08,758:INFO:Initializing create_model()
2025-05-12 22:18:08,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:08,758:INFO:Checking exceptions
2025-05-12 22:18:08,780:INFO:Importing libraries
2025-05-12 22:18:08,780:INFO:Copying training dataset
2025-05-12 22:18:08,788:INFO:Defining folds
2025-05-12 22:18:08,788:INFO:Declaring metric variables
2025-05-12 22:18:08,795:INFO:Importing untrained model
2025-05-12 22:18:08,800:INFO:Linear Regression Imported successfully
2025-05-12 22:18:08,812:INFO:Starting cross validation
2025-05-12 22:18:08,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:09,115:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:09,116:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:09,125:INFO:Calculating mean and std
2025-05-12 22:18:09,125:INFO:Creating metrics dataframe
2025-05-12 22:18:09,130:INFO:Finalizing model
2025-05-12 22:18:09,192:INFO:Uploading results into container
2025-05-12 22:18:09,193:INFO:Uploading model into container now
2025-05-12 22:18:09,204:INFO:_master_model_container: 19
2025-05-12 22:18:09,204:INFO:_display_container: 3
2025-05-12 22:18:09,204:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:09,204:INFO:create_model() successfully completed......................................
2025-05-12 22:18:13,220:INFO:Initializing tune_model()
2025-05-12 22:18:13,220:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:18:13,220:INFO:Checking exceptions
2025-05-12 22:18:13,240:INFO:Copying training dataset
2025-05-12 22:18:13,244:INFO:Checking base model
2025-05-12 22:18:13,245:INFO:Base model : Linear Regression
2025-05-12 22:18:13,250:INFO:Declaring metric variables
2025-05-12 22:18:13,255:INFO:Defining Hyperparameters
2025-05-12 22:18:13,255:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 22:18:13,351:INFO:Tuning with n_jobs=-1
2025-05-12 22:18:13,351:INFO:Initializing GridSearchCV
2025-05-12 22:18:13,923:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 22:18:13,923:INFO:Hyperparameter search completed
2025-05-12 22:18:13,924:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:13,924:INFO:Initializing create_model()
2025-05-12 22:18:13,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC04A710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 22:18:13,924:INFO:Checking exceptions
2025-05-12 22:18:13,924:INFO:Importing libraries
2025-05-12 22:18:13,924:INFO:Copying training dataset
2025-05-12 22:18:13,931:INFO:Defining folds
2025-05-12 22:18:13,932:INFO:Declaring metric variables
2025-05-12 22:18:13,936:INFO:Importing untrained model
2025-05-12 22:18:13,936:INFO:Declaring custom model
2025-05-12 22:18:13,943:INFO:Linear Regression Imported successfully
2025-05-12 22:18:13,955:INFO:Starting cross validation
2025-05-12 22:18:13,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:14,421:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:14,421:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:14,433:INFO:Calculating mean and std
2025-05-12 22:18:14,437:INFO:Creating metrics dataframe
2025-05-12 22:18:14,453:INFO:Finalizing model
2025-05-12 22:18:14,588:INFO:Uploading results into container
2025-05-12 22:18:14,590:INFO:Uploading model into container now
2025-05-12 22:18:14,591:INFO:_master_model_container: 20
2025-05-12 22:18:14,592:INFO:_display_container: 4
2025-05-12 22:18:14,592:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:14,592:INFO:create_model() successfully completed......................................
2025-05-12 22:18:14,746:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:14,746:INFO:choose_better activated
2025-05-12 22:18:14,755:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:14,756:INFO:Initializing create_model()
2025-05-12 22:18:14,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:14,757:INFO:Checking exceptions
2025-05-12 22:18:14,761:INFO:Importing libraries
2025-05-12 22:18:14,761:INFO:Copying training dataset
2025-05-12 22:18:14,771:INFO:Defining folds
2025-05-12 22:18:14,771:INFO:Declaring metric variables
2025-05-12 22:18:14,772:INFO:Importing untrained model
2025-05-12 22:18:14,772:INFO:Declaring custom model
2025-05-12 22:18:14,773:INFO:Linear Regression Imported successfully
2025-05-12 22:18:14,773:INFO:Starting cross validation
2025-05-12 22:18:14,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:15,214:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:15,215:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:15,219:INFO:Calculating mean and std
2025-05-12 22:18:15,220:INFO:Creating metrics dataframe
2025-05-12 22:18:15,223:INFO:Finalizing model
2025-05-12 22:18:15,313:INFO:Uploading results into container
2025-05-12 22:18:15,313:INFO:Uploading model into container now
2025-05-12 22:18:15,314:INFO:_master_model_container: 21
2025-05-12 22:18:15,314:INFO:_display_container: 5
2025-05-12 22:18:15,314:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:15,314:INFO:create_model() successfully completed......................................
2025-05-12 22:18:15,420:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:15,420:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.1485
2025-05-12 22:18:15,421:INFO:LinearRegression(n_jobs=-1) result for R2 is -0.1485
2025-05-12 22:18:15,422:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 22:18:15,422:INFO:choose_better completed
2025-05-12 22:18:15,422:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:18:15,443:INFO:_master_model_container: 21
2025-05-12 22:18:15,443:INFO:_display_container: 4
2025-05-12 22:18:15,444:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:15,444:INFO:tune_model() successfully completed......................................
2025-05-12 22:18:20,758:INFO:Initializing evaluate_model()
2025-05-12 22:18:20,758:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:18:20,777:INFO:Initializing plot_model()
2025-05-12 22:18:20,777:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:18:20,778:INFO:Checking exceptions
2025-05-12 22:18:20,781:INFO:Preloading libraries
2025-05-12 22:18:20,782:INFO:Copying training dataset
2025-05-12 22:18:20,782:INFO:Plot type: pipeline
2025-05-12 22:18:21,145:INFO:Visual Rendered Successfully
2025-05-12 22:18:21,251:INFO:plot_model() successfully completed......................................
2025-05-12 22:18:25,687:INFO:Initializing predict_model()
2025-05-12 22:18:25,688:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3C80D8720>)
2025-05-12 22:18:25,688:INFO:Checking exceptions
2025-05-12 22:18:25,688:INFO:Preloading libraries
2025-05-12 22:18:25,802:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:20:05,343:INFO:Initializing create_model()
2025-05-12 22:20:05,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:20:05,343:INFO:Checking exceptions
2025-05-12 22:20:05,363:INFO:Importing libraries
2025-05-12 22:20:05,363:INFO:Copying training dataset
2025-05-12 22:20:05,371:INFO:Defining folds
2025-05-12 22:20:05,371:INFO:Declaring metric variables
2025-05-12 22:20:05,397:INFO:Importing untrained model
2025-05-12 22:20:05,406:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:05,434:INFO:Starting cross validation
2025-05-12 22:20:05,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:05,769:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:05,770:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:05,780:INFO:Calculating mean and std
2025-05-12 22:20:05,781:INFO:Creating metrics dataframe
2025-05-12 22:20:05,784:INFO:Finalizing model
2025-05-12 22:20:05,833:INFO:Uploading results into container
2025-05-12 22:20:05,834:INFO:Uploading model into container now
2025-05-12 22:20:05,847:INFO:_master_model_container: 22
2025-05-12 22:20:05,847:INFO:_display_container: 6
2025-05-12 22:20:05,848:INFO:Lasso(random_state=123)
2025-05-12 22:20:05,848:INFO:create_model() successfully completed......................................
2025-05-12 22:20:08,411:INFO:Initializing tune_model()
2025-05-12 22:20:08,411:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:20:08,411:INFO:Checking exceptions
2025-05-12 22:20:08,434:INFO:Copying training dataset
2025-05-12 22:20:08,439:INFO:Checking base model
2025-05-12 22:20:08,439:INFO:Base model : Lasso Regression
2025-05-12 22:20:08,445:INFO:Declaring metric variables
2025-05-12 22:20:08,452:INFO:Defining Hyperparameters
2025-05-12 22:20:08,540:INFO:Tuning with n_jobs=-1
2025-05-12 22:20:08,541:INFO:Initializing RandomizedSearchCV
2025-05-12 22:20:10,238:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:20:10,239:INFO:Hyperparameter search completed
2025-05-12 22:20:10,239:INFO:SubProcess create_model() called ==================================
2025-05-12 22:20:10,239:INFO:Initializing create_model()
2025-05-12 22:20:10,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC2A0210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:20:10,239:INFO:Checking exceptions
2025-05-12 22:20:10,239:INFO:Importing libraries
2025-05-12 22:20:10,240:INFO:Copying training dataset
2025-05-12 22:20:10,245:INFO:Defining folds
2025-05-12 22:20:10,245:INFO:Declaring metric variables
2025-05-12 22:20:10,248:INFO:Importing untrained model
2025-05-12 22:20:10,248:INFO:Declaring custom model
2025-05-12 22:20:10,251:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:10,258:INFO:Starting cross validation
2025-05-12 22:20:10,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:10,475:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:10,475:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:10,480:INFO:Calculating mean and std
2025-05-12 22:20:10,481:INFO:Creating metrics dataframe
2025-05-12 22:20:10,485:INFO:Finalizing model
2025-05-12 22:20:10,532:INFO:Uploading results into container
2025-05-12 22:20:10,533:INFO:Uploading model into container now
2025-05-12 22:20:10,533:INFO:_master_model_container: 23
2025-05-12 22:20:10,533:INFO:_display_container: 7
2025-05-12 22:20:10,534:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:20:10,534:INFO:create_model() successfully completed......................................
2025-05-12 22:20:10,606:INFO:SubProcess create_model() end ==================================
2025-05-12 22:20:10,607:INFO:choose_better activated
2025-05-12 22:20:10,611:INFO:SubProcess create_model() called ==================================
2025-05-12 22:20:10,612:INFO:Initializing create_model()
2025-05-12 22:20:10,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:20:10,612:INFO:Checking exceptions
2025-05-12 22:20:10,615:INFO:Importing libraries
2025-05-12 22:20:10,615:INFO:Copying training dataset
2025-05-12 22:20:10,620:INFO:Defining folds
2025-05-12 22:20:10,620:INFO:Declaring metric variables
2025-05-12 22:20:10,621:INFO:Importing untrained model
2025-05-12 22:20:10,621:INFO:Declaring custom model
2025-05-12 22:20:10,622:INFO:Lasso Regression Imported successfully
2025-05-12 22:20:10,622:INFO:Starting cross validation
2025-05-12 22:20:10,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:20:10,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:20:10,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:20:10,924:INFO:Calculating mean and std
2025-05-12 22:20:10,925:INFO:Creating metrics dataframe
2025-05-12 22:20:10,927:INFO:Finalizing model
2025-05-12 22:20:10,985:INFO:Uploading results into container
2025-05-12 22:20:10,986:INFO:Uploading model into container now
2025-05-12 22:20:10,986:INFO:_master_model_container: 24
2025-05-12 22:20:10,986:INFO:_display_container: 8
2025-05-12 22:20:10,987:INFO:Lasso(random_state=123)
2025-05-12 22:20:10,987:INFO:create_model() successfully completed......................................
2025-05-12 22:20:11,055:INFO:SubProcess create_model() end ==================================
2025-05-12 22:20:11,056:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:20:11,056:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:20:11,057:INFO:Lasso(random_state=123) is best model
2025-05-12 22:20:11,057:INFO:choose_better completed
2025-05-12 22:20:11,057:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:20:11,069:INFO:_master_model_container: 24
2025-05-12 22:20:11,069:INFO:_display_container: 7
2025-05-12 22:20:11,069:INFO:Lasso(random_state=123)
2025-05-12 22:20:11,069:INFO:tune_model() successfully completed......................................
2025-05-12 22:20:14,086:INFO:Initializing evaluate_model()
2025-05-12 22:20:14,087:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:20:14,096:INFO:Initializing plot_model()
2025-05-12 22:20:14,096:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:20:14,097:INFO:Checking exceptions
2025-05-12 22:20:14,099:INFO:Preloading libraries
2025-05-12 22:20:14,099:INFO:Copying training dataset
2025-05-12 22:20:14,099:INFO:Plot type: pipeline
2025-05-12 22:20:14,236:INFO:Visual Rendered Successfully
2025-05-12 22:20:14,323:INFO:plot_model() successfully completed......................................
2025-05-12 22:20:17,035:INFO:Initializing predict_model()
2025-05-12 22:20:17,035:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECB03420>)
2025-05-12 22:20:17,035:INFO:Checking exceptions
2025-05-12 22:20:17,035:INFO:Preloading libraries
2025-05-12 22:20:17,167:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:37,186:INFO:Initializing create_model()
2025-05-12 22:25:37,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=en, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:37,188:INFO:Checking exceptions
2025-05-12 22:25:37,205:INFO:Importing libraries
2025-05-12 22:25:37,206:INFO:Copying training dataset
2025-05-12 22:25:37,212:INFO:Defining folds
2025-05-12 22:25:37,212:INFO:Declaring metric variables
2025-05-12 22:25:37,218:INFO:Importing untrained model
2025-05-12 22:25:37,222:INFO:Elastic Net Imported successfully
2025-05-12 22:25:37,232:INFO:Starting cross validation
2025-05-12 22:25:37,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:47,008:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:47,009:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:47,370:INFO:Calculating mean and std
2025-05-12 22:25:47,371:INFO:Creating metrics dataframe
2025-05-12 22:25:47,379:INFO:Finalizing model
2025-05-12 22:25:47,449:INFO:Uploading results into container
2025-05-12 22:25:47,450:INFO:Uploading model into container now
2025-05-12 22:25:47,472:INFO:_master_model_container: 25
2025-05-12 22:25:47,472:INFO:_display_container: 9
2025-05-12 22:25:47,473:INFO:ElasticNet(random_state=123)
2025-05-12 22:25:47,473:INFO:create_model() successfully completed......................................
2025-05-12 22:25:58,332:INFO:Initializing tune_model()
2025-05-12 22:25:58,332:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:58,332:INFO:Checking exceptions
2025-05-12 22:25:58,354:INFO:Copying training dataset
2025-05-12 22:25:58,358:INFO:Checking base model
2025-05-12 22:25:58,359:INFO:Base model : Elastic Net
2025-05-12 22:25:58,364:INFO:Declaring metric variables
2025-05-12 22:25:58,370:INFO:Defining Hyperparameters
2025-05-12 22:25:58,453:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:58,453:INFO:Initializing RandomizedSearchCV
2025-05-12 22:26:00,250:INFO:best_params: {'actual_estimator__l1_ratio': 0.664, 'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 9.88}
2025-05-12 22:26:00,251:INFO:Hyperparameter search completed
2025-05-12 22:26:00,251:INFO:SubProcess create_model() called ==================================
2025-05-12 22:26:00,252:INFO:Initializing create_model()
2025-05-12 22:26:00,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3EC1073D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'l1_ratio': 0.664, 'fit_intercept': True, 'alpha': 9.88})
2025-05-12 22:26:00,252:INFO:Checking exceptions
2025-05-12 22:26:00,252:INFO:Importing libraries
2025-05-12 22:26:00,252:INFO:Copying training dataset
2025-05-12 22:26:00,258:INFO:Defining folds
2025-05-12 22:26:00,259:INFO:Declaring metric variables
2025-05-12 22:26:00,263:INFO:Importing untrained model
2025-05-12 22:26:00,263:INFO:Declaring custom model
2025-05-12 22:26:00,268:INFO:Elastic Net Imported successfully
2025-05-12 22:26:00,279:INFO:Starting cross validation
2025-05-12 22:26:00,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:26:00,556:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:26:00,556:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:26:00,561:INFO:Calculating mean and std
2025-05-12 22:26:00,562:INFO:Creating metrics dataframe
2025-05-12 22:26:00,568:INFO:Finalizing model
2025-05-12 22:26:00,619:INFO:Uploading results into container
2025-05-12 22:26:00,620:INFO:Uploading model into container now
2025-05-12 22:26:00,620:INFO:_master_model_container: 26
2025-05-12 22:26:00,621:INFO:_display_container: 10
2025-05-12 22:26:00,621:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123)
2025-05-12 22:26:00,621:INFO:create_model() successfully completed......................................
2025-05-12 22:26:00,705:INFO:SubProcess create_model() end ==================================
2025-05-12 22:26:00,705:INFO:choose_better activated
2025-05-12 22:26:00,708:INFO:SubProcess create_model() called ==================================
2025-05-12 22:26:00,709:INFO:Initializing create_model()
2025-05-12 22:26:00,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:26:00,709:INFO:Checking exceptions
2025-05-12 22:26:00,710:INFO:Importing libraries
2025-05-12 22:26:00,710:INFO:Copying training dataset
2025-05-12 22:26:00,715:INFO:Defining folds
2025-05-12 22:26:00,715:INFO:Declaring metric variables
2025-05-12 22:26:00,715:INFO:Importing untrained model
2025-05-12 22:26:00,715:INFO:Declaring custom model
2025-05-12 22:26:00,716:INFO:Elastic Net Imported successfully
2025-05-12 22:26:00,716:INFO:Starting cross validation
2025-05-12 22:26:00,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:26:00,977:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:26:00,978:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:26:00,981:INFO:Calculating mean and std
2025-05-12 22:26:00,981:INFO:Creating metrics dataframe
2025-05-12 22:26:00,983:INFO:Finalizing model
2025-05-12 22:26:01,024:INFO:Uploading results into container
2025-05-12 22:26:01,024:INFO:Uploading model into container now
2025-05-12 22:26:01,025:INFO:_master_model_container: 27
2025-05-12 22:26:01,025:INFO:_display_container: 11
2025-05-12 22:26:01,025:INFO:ElasticNet(random_state=123)
2025-05-12 22:26:01,025:INFO:create_model() successfully completed......................................
2025-05-12 22:26:01,098:INFO:SubProcess create_model() end ==================================
2025-05-12 22:26:01,098:INFO:ElasticNet(random_state=123) result for R2 is -0.0421
2025-05-12 22:26:01,099:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123) result for R2 is -0.0421
2025-05-12 22:26:01,099:INFO:ElasticNet(random_state=123) is best model
2025-05-12 22:26:01,099:INFO:choose_better completed
2025-05-12 22:26:01,100:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:26:01,110:INFO:_master_model_container: 27
2025-05-12 22:26:01,110:INFO:_display_container: 10
2025-05-12 22:26:01,110:INFO:ElasticNet(random_state=123)
2025-05-12 22:26:01,110:INFO:tune_model() successfully completed......................................
2025-05-12 22:26:03,825:INFO:Initializing evaluate_model()
2025-05-12 22:26:03,825:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:26:03,837:INFO:Initializing plot_model()
2025-05-12 22:26:03,837:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:03,837:INFO:Checking exceptions
2025-05-12 22:26:03,839:INFO:Preloading libraries
2025-05-12 22:26:03,839:INFO:Copying training dataset
2025-05-12 22:26:03,839:INFO:Plot type: pipeline
2025-05-12 22:26:04,029:INFO:Visual Rendered Successfully
2025-05-12 22:26:04,103:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:06,114:INFO:Initializing plot_model()
2025-05-12 22:26:06,114:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:06,114:INFO:Checking exceptions
2025-05-12 22:26:06,116:INFO:Preloading libraries
2025-05-12 22:26:06,117:INFO:Copying training dataset
2025-05-12 22:26:06,117:INFO:Plot type: parameter
2025-05-12 22:26:06,122:INFO:Visual Rendered Successfully
2025-05-12 22:26:06,215:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:07,450:INFO:Initializing plot_model()
2025-05-12 22:26:07,450:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:07,450:INFO:Checking exceptions
2025-05-12 22:26:07,454:INFO:Preloading libraries
2025-05-12 22:26:07,454:INFO:Copying training dataset
2025-05-12 22:26:07,454:INFO:Plot type: residuals
2025-05-12 22:26:07,683:INFO:Fitting Model
2025-05-12 22:26:07,683:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names
  warnings.warn(

2025-05-12 22:26:07,726:INFO:Scoring test/hold-out set
2025-05-12 22:26:08,673:INFO:Visual Rendered Successfully
2025-05-12 22:26:08,746:INFO:plot_model() successfully completed......................................
2025-05-12 22:26:08,846:INFO:Initializing plot_model()
2025-05-12 22:26:08,847:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:26:08,847:INFO:Checking exceptions
2025-05-12 22:26:08,850:INFO:Preloading libraries
2025-05-12 22:26:08,850:INFO:Copying training dataset
2025-05-12 22:26:08,850:INFO:Plot type: error
2025-05-12 22:26:09,124:INFO:Fitting Model
2025-05-12 22:26:09,124:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names
  warnings.warn(

2025-05-12 22:26:09,124:INFO:Scoring test/hold-out set
2025-05-12 22:26:09,386:INFO:Visual Rendered Successfully
2025-05-12 22:26:09,498:INFO:plot_model() successfully completed......................................
2025-05-12 22:27:59,133:INFO:Initializing predict_model()
2025-05-12 22:27:59,133:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECD14AE0>)
2025-05-12 22:27:59,133:INFO:Checking exceptions
2025-05-12 22:27:59,133:INFO:Preloading libraries
2025-05-12 22:27:59,373:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:36:22,188:INFO:Initializing create_model()
2025-05-12 22:36:22,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:36:22,189:INFO:Checking exceptions
2025-05-12 22:36:22,216:INFO:Importing libraries
2025-05-12 22:36:22,216:INFO:Copying training dataset
2025-05-12 22:36:22,224:INFO:Defining folds
2025-05-12 22:36:22,224:INFO:Declaring metric variables
2025-05-12 22:36:22,233:INFO:Importing untrained model
2025-05-12 22:36:22,241:INFO:Lasso Regression Imported successfully
2025-05-12 22:36:22,255:INFO:Starting cross validation
2025-05-12 22:36:22,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:36:30,540:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:36:30,541:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:36:31,158:INFO:Calculating mean and std
2025-05-12 22:36:31,160:INFO:Creating metrics dataframe
2025-05-12 22:36:31,170:INFO:Finalizing model
2025-05-12 22:36:31,225:INFO:Uploading results into container
2025-05-12 22:36:31,226:INFO:Uploading model into container now
2025-05-12 22:36:31,235:INFO:_master_model_container: 28
2025-05-12 22:36:31,236:INFO:_display_container: 12
2025-05-12 22:36:31,236:INFO:Lasso(random_state=123)
2025-05-12 22:36:31,236:INFO:create_model() successfully completed......................................
2025-05-12 22:46:40,121:INFO:Initializing tune_model()
2025-05-12 22:46:40,121:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:46:40,121:INFO:Checking exceptions
2025-05-12 22:46:40,140:INFO:Copying training dataset
2025-05-12 22:46:40,144:INFO:Checking base model
2025-05-12 22:46:40,144:INFO:Base model : Lasso Regression
2025-05-12 22:46:40,149:INFO:Declaring metric variables
2025-05-12 22:46:40,155:INFO:Defining Hyperparameters
2025-05-12 22:46:40,245:INFO:Tuning with n_jobs=-1
2025-05-12 22:46:40,246:INFO:Initializing RandomizedSearchCV
2025-05-12 22:46:50,358:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:46:50,360:INFO:Hyperparameter search completed
2025-05-12 22:46:50,361:INFO:SubProcess create_model() called ==================================
2025-05-12 22:46:50,362:INFO:Initializing create_model()
2025-05-12 22:46:50,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3ECF40090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:46:50,363:INFO:Checking exceptions
2025-05-12 22:46:50,364:INFO:Importing libraries
2025-05-12 22:46:50,364:INFO:Copying training dataset
2025-05-12 22:46:50,378:INFO:Defining folds
2025-05-12 22:46:50,378:INFO:Declaring metric variables
2025-05-12 22:46:50,386:INFO:Importing untrained model
2025-05-12 22:46:50,386:INFO:Declaring custom model
2025-05-12 22:46:50,395:INFO:Lasso Regression Imported successfully
2025-05-12 22:46:50,413:INFO:Starting cross validation
2025-05-12 22:46:50,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:46:50,780:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:46:50,780:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:46:50,789:INFO:Calculating mean and std
2025-05-12 22:46:50,791:INFO:Creating metrics dataframe
2025-05-12 22:46:50,798:INFO:Finalizing model
2025-05-12 22:46:50,871:INFO:Uploading results into container
2025-05-12 22:46:50,872:INFO:Uploading model into container now
2025-05-12 22:46:50,873:INFO:_master_model_container: 29
2025-05-12 22:46:50,873:INFO:_display_container: 13
2025-05-12 22:46:50,874:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:46:50,874:INFO:create_model() successfully completed......................................
2025-05-12 22:46:50,966:INFO:SubProcess create_model() end ==================================
2025-05-12 22:46:50,966:INFO:choose_better activated
2025-05-12 22:46:50,972:INFO:SubProcess create_model() called ==================================
2025-05-12 22:46:50,973:INFO:Initializing create_model()
2025-05-12 22:46:50,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:46:50,973:INFO:Checking exceptions
2025-05-12 22:46:50,975:INFO:Importing libraries
2025-05-12 22:46:50,975:INFO:Copying training dataset
2025-05-12 22:46:50,980:INFO:Defining folds
2025-05-12 22:46:50,980:INFO:Declaring metric variables
2025-05-12 22:46:50,980:INFO:Importing untrained model
2025-05-12 22:46:50,980:INFO:Declaring custom model
2025-05-12 22:46:50,981:INFO:Lasso Regression Imported successfully
2025-05-12 22:46:50,981:INFO:Starting cross validation
2025-05-12 22:46:50,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:46:51,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:46:51,266:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:46:51,277:INFO:Calculating mean and std
2025-05-12 22:46:51,278:INFO:Creating metrics dataframe
2025-05-12 22:46:51,281:INFO:Finalizing model
2025-05-12 22:46:51,371:INFO:Uploading results into container
2025-05-12 22:46:51,372:INFO:Uploading model into container now
2025-05-12 22:46:51,372:INFO:_master_model_container: 30
2025-05-12 22:46:51,373:INFO:_display_container: 14
2025-05-12 22:46:51,373:INFO:Lasso(random_state=123)
2025-05-12 22:46:51,373:INFO:create_model() successfully completed......................................
2025-05-12 22:46:51,477:INFO:SubProcess create_model() end ==================================
2025-05-12 22:46:51,477:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:46:51,478:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:46:51,478:INFO:Lasso(random_state=123) is best model
2025-05-12 22:46:51,478:INFO:choose_better completed
2025-05-12 22:46:51,478:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:46:51,495:INFO:_master_model_container: 30
2025-05-12 22:46:51,495:INFO:_display_container: 13
2025-05-12 22:46:51,495:INFO:Lasso(random_state=123)
2025-05-12 22:46:51,496:INFO:tune_model() successfully completed......................................
2025-05-12 22:46:54,225:INFO:Initializing evaluate_model()
2025-05-12 22:46:54,225:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:46:54,234:INFO:Initializing plot_model()
2025-05-12 22:46:54,234:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:46:54,234:INFO:Checking exceptions
2025-05-12 22:46:54,237:INFO:Preloading libraries
2025-05-12 22:46:54,237:INFO:Copying training dataset
2025-05-12 22:46:54,237:INFO:Plot type: pipeline
2025-05-12 22:46:54,362:INFO:Visual Rendered Successfully
2025-05-12 22:46:54,430:INFO:plot_model() successfully completed......................................
2025-05-12 22:46:56,395:INFO:Initializing predict_model()
2025-05-12 22:46:56,395:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D3EC2CF710>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D3ECD14400>)
2025-05-12 22:46:56,395:INFO:Checking exceptions
2025-05-12 22:46:56,395:INFO:Preloading libraries
2025-05-12 22:46:56,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:47:00,391:INFO:Initializing save_model()
2025-05-12 22:47:00,391:INFO:save_model(model=Lasso(random_state=123), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:47:00,392:INFO:Adding model into prep_pipe
2025-05-12 22:47:00,401:INFO:modelo_precio_final.pkl saved in current working directory
2025-05-12 22:47:00,413:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', Lasso(random_state=123))])
2025-05-12 22:47:00,413:INFO:save_model() successfully completed......................................
2025-05-19 19:54:32,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:54:33,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:04:22,759:INFO:PyCaret ClassificationExperiment
2025-05-19 20:04:22,759:INFO:Logging name: clf-default-name
2025-05-19 20:04:22,759:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 20:04:22,759:INFO:version 3.3.2
2025-05-19 20:04:22,759:INFO:Initializing setup()
2025-05-19 20:04:22,759:INFO:self.USI: 1301
2025-05-19 20:04:22,759:INFO:self._variable_keys: {'USI', 'logging_param', 'idx', 'fold_shuffle_param', 'data', 'pipeline', '_ml_usecase', 'exp_id', 'memory', 'y_test', 'X', 'log_plots_param', 'y_train', 'X_test', 'html_param', 'y', 'seed', 'gpu_param', 'exp_name_log', 'fold_generator', 'is_multiclass', 'n_jobs_param', 'fold_groups_param', '_available_plots', 'X_train', 'target_param', 'fix_imbalance', 'gpu_n_jobs_param'}
2025-05-19 20:04:23,075:INFO:Checking environment
2025-05-19 20:04:23,075:INFO:python_version: 3.11.0
2025-05-19 20:04:23,075:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-05-19 20:04:23,075:INFO:machine: AMD64
2025-05-19 20:04:23,075:INFO:platform: Windows-10-10.0.19045-SP0
2025-05-19 20:04:23,080:INFO:Memory: svmem(total=12759322624, available=1364443136, percent=89.3, used=11394879488, free=1364443136)
2025-05-19 20:04:23,081:INFO:Physical Core: 4
2025-05-19 20:04:23,081:INFO:Logical Core: 8
2025-05-19 20:04:23,081:INFO:Checking libraries
2025-05-19 20:04:23,081:INFO:System:
2025-05-19 20:04:23,081:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-05-19 20:04:23,081:INFO:executable: c:\Users\RAUL\AppData\Local\Programs\Python\Python311\python.exe
2025-05-19 20:04:23,081:INFO:   machine: Windows-10-10.0.19045-SP0
2025-05-19 20:04:23,081:INFO:PyCaret required dependencies:
2025-05-19 20:04:23,282:INFO:                 pip: 22.3
2025-05-19 20:04:23,282:INFO:          setuptools: 65.5.0
2025-05-19 20:04:23,282:INFO:             pycaret: 3.3.2
2025-05-19 20:04:23,282:INFO:             IPython: 9.2.0
2025-05-19 20:04:23,282:INFO:          ipywidgets: 8.1.7
2025-05-19 20:04:23,282:INFO:                tqdm: 4.67.1
2025-05-19 20:04:23,282:INFO:               numpy: 1.26.4
2025-05-19 20:04:23,282:INFO:              pandas: 2.1.4
2025-05-19 20:04:23,282:INFO:              jinja2: 3.1.6
2025-05-19 20:04:23,282:INFO:               scipy: 1.11.4
2025-05-19 20:04:23,282:INFO:              joblib: 1.3.2
2025-05-19 20:04:23,283:INFO:             sklearn: 1.4.2
2025-05-19 20:04:23,283:INFO:                pyod: 2.0.5
2025-05-19 20:04:23,283:INFO:            imblearn: 0.13.0
2025-05-19 20:04:23,283:INFO:   category_encoders: 2.7.0
2025-05-19 20:04:23,283:INFO:            lightgbm: 4.6.0
2025-05-19 20:04:23,283:INFO:               numba: 0.61.2
2025-05-19 20:04:23,283:INFO:            requests: 2.32.3
2025-05-19 20:04:23,283:INFO:          matplotlib: 3.7.5
2025-05-19 20:04:23,283:INFO:          scikitplot: 0.3.7
2025-05-19 20:04:23,283:INFO:         yellowbrick: 1.5
2025-05-19 20:04:23,283:INFO:              plotly: 5.24.1
2025-05-19 20:04:23,283:INFO:    plotly-resampler: Not installed
2025-05-19 20:04:23,283:INFO:             kaleido: 0.2.1
2025-05-19 20:04:23,283:INFO:           schemdraw: 0.15
2025-05-19 20:04:23,283:INFO:         statsmodels: 0.14.4
2025-05-19 20:04:23,283:INFO:              sktime: 0.26.0
2025-05-19 20:04:23,283:INFO:               tbats: 1.1.3
2025-05-19 20:04:23,284:INFO:            pmdarima: 2.0.4
2025-05-19 20:04:23,284:INFO:              psutil: 7.0.0
2025-05-19 20:04:23,284:INFO:          markupsafe: 3.0.2
2025-05-19 20:04:23,284:INFO:             pickle5: Not installed
2025-05-19 20:04:23,284:INFO:         cloudpickle: 3.1.1
2025-05-19 20:04:23,284:INFO:         deprecation: 2.1.0
2025-05-19 20:04:23,284:INFO:              xxhash: 3.5.0
2025-05-19 20:04:23,284:INFO:           wurlitzer: Not installed
2025-05-19 20:04:23,284:INFO:PyCaret optional dependencies:
2025-05-19 20:04:23,307:INFO:                shap: Not installed
2025-05-19 20:04:23,308:INFO:           interpret: Not installed
2025-05-19 20:04:23,308:INFO:                umap: Not installed
2025-05-19 20:04:23,308:INFO:     ydata_profiling: Not installed
2025-05-19 20:04:23,308:INFO:  explainerdashboard: Not installed
2025-05-19 20:04:23,308:INFO:             autoviz: Not installed
2025-05-19 20:04:23,308:INFO:           fairlearn: Not installed
2025-05-19 20:04:23,308:INFO:          deepchecks: Not installed
2025-05-19 20:04:23,308:INFO:             xgboost: Not installed
2025-05-19 20:04:23,308:INFO:            catboost: Not installed
2025-05-19 20:04:23,308:INFO:              kmodes: Not installed
2025-05-19 20:04:23,308:INFO:             mlxtend: Not installed
2025-05-19 20:04:23,308:INFO:       statsforecast: Not installed
2025-05-19 20:04:23,308:INFO:        tune_sklearn: Not installed
2025-05-19 20:04:23,308:INFO:                 ray: Not installed
2025-05-19 20:04:23,309:INFO:            hyperopt: Not installed
2025-05-19 20:04:23,309:INFO:              optuna: Not installed
2025-05-19 20:04:23,309:INFO:               skopt: Not installed
2025-05-19 20:04:23,309:INFO:              mlflow: Not installed
2025-05-19 20:04:23,309:INFO:              gradio: Not installed
2025-05-19 20:04:23,309:INFO:             fastapi: Not installed
2025-05-19 20:04:23,309:INFO:             uvicorn: Not installed
2025-05-19 20:04:23,309:INFO:              m2cgen: Not installed
2025-05-19 20:04:23,309:INFO:           evidently: Not installed
2025-05-19 20:04:23,309:INFO:               fugue: Not installed
2025-05-19 20:04:23,309:INFO:           streamlit: Not installed
2025-05-19 20:04:23,309:INFO:             prophet: Not installed
2025-05-19 20:04:23,309:INFO:None
2025-05-19 20:04:23,309:INFO:Set up data.
2025-05-19 20:04:23,320:INFO:Set up folding strategy.
2025-05-19 20:04:23,320:INFO:Set up train/test split.
2025-05-19 20:04:23,390:INFO:Set up index.
2025-05-19 20:04:23,390:INFO:Assigning column types.
2025-05-19 20:04:23,396:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 20:04:23,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:23,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:23,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 20:04:23,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:24,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 20:04:24,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,279:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 20:04:24,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,662:INFO:Preparing preprocessing pipeline...
2025-05-19 20:04:24,667:INFO:Set up simple imputation.
2025-05-19 20:04:24,673:INFO:Set up encoding of categorical features.
2025-05-19 20:04:24,673:INFO:Set up removing multicollinearity.
2025-05-19 20:04:24,674:INFO:Set up column transformation.
2025-05-19 20:04:24,674:INFO:Set up feature normalization.
2025-05-19 20:04:24,674:INFO:Set up feature selection.
2025-05-19 20:04:24,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:24,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:25,588:INFO:Finished creating preprocessing pipeline.
2025-05-19 20:04:25,627:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\RAUL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transform...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 20:04:25,627:INFO:Creating final display dataframe.
2025-05-19 20:04:26,384:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              1301
2025-05-19 20:04:26,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 20:04:26,689:INFO:setup() successfully completed in 3.94s...............
2025-05-19 20:05:16,601:INFO:Initializing compare_models()
2025-05-19 20:05:16,602:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 20:05:16,602:INFO:Checking exceptions
2025-05-19 20:05:16,611:INFO:Preparing display monitor
2025-05-19 20:05:16,652:INFO:Initializing Logistic Regression
2025-05-19 20:05:16,653:INFO:Total runtime is 0.0 minutes
2025-05-19 20:05:16,659:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:16,660:INFO:Initializing create_model()
2025-05-19 20:05:16,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:16,660:INFO:Checking exceptions
2025-05-19 20:05:16,661:INFO:Importing libraries
2025-05-19 20:05:16,661:INFO:Copying training dataset
2025-05-19 20:05:16,671:INFO:Defining folds
2025-05-19 20:05:16,671:INFO:Declaring metric variables
2025-05-19 20:05:16,675:INFO:Importing untrained model
2025-05-19 20:05:16,683:INFO:Logistic Regression Imported successfully
2025-05-19 20:05:16,693:INFO:Starting cross validation
2025-05-19 20:05:16,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:28,132:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,133:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,320:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,426:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,629:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,647:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,904:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:28,924:INFO:Calculating mean and std
2025-05-19 20:05:28,928:INFO:Creating metrics dataframe
2025-05-19 20:05:28,931:INFO:Uploading results into container
2025-05-19 20:05:28,932:INFO:Uploading model into container now
2025-05-19 20:05:28,933:INFO:_master_model_container: 1
2025-05-19 20:05:28,933:INFO:_display_container: 2
2025-05-19 20:05:28,934:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 20:05:28,935:INFO:create_model() successfully completed......................................
2025-05-19 20:05:29,065:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:29,065:INFO:Creating metrics dataframe
2025-05-19 20:05:29,076:INFO:Initializing K Neighbors Classifier
2025-05-19 20:05:29,076:INFO:Total runtime is 0.20707589785257977 minutes
2025-05-19 20:05:29,083:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:29,083:INFO:Initializing create_model()
2025-05-19 20:05:29,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:29,083:INFO:Checking exceptions
2025-05-19 20:05:29,083:INFO:Importing libraries
2025-05-19 20:05:29,084:INFO:Copying training dataset
2025-05-19 20:05:29,091:INFO:Defining folds
2025-05-19 20:05:29,091:INFO:Declaring metric variables
2025-05-19 20:05:29,100:INFO:Importing untrained model
2025-05-19 20:05:29,107:INFO:K Neighbors Classifier Imported successfully
2025-05-19 20:05:29,131:INFO:Starting cross validation
2025-05-19 20:05:29,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:30,262:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:30,876:INFO:Calculating mean and std
2025-05-19 20:05:30,879:INFO:Creating metrics dataframe
2025-05-19 20:05:30,882:INFO:Uploading results into container
2025-05-19 20:05:30,883:INFO:Uploading model into container now
2025-05-19 20:05:30,884:INFO:_master_model_container: 2
2025-05-19 20:05:30,885:INFO:_display_container: 2
2025-05-19 20:05:30,886:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 20:05:30,886:INFO:create_model() successfully completed......................................
2025-05-19 20:05:30,988:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:30,988:INFO:Creating metrics dataframe
2025-05-19 20:05:30,998:INFO:Initializing Naive Bayes
2025-05-19 20:05:30,998:INFO:Total runtime is 0.2391100565592448 minutes
2025-05-19 20:05:31,003:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:31,003:INFO:Initializing create_model()
2025-05-19 20:05:31,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:31,004:INFO:Checking exceptions
2025-05-19 20:05:31,004:INFO:Importing libraries
2025-05-19 20:05:31,004:INFO:Copying training dataset
2025-05-19 20:05:31,011:INFO:Defining folds
2025-05-19 20:05:31,011:INFO:Declaring metric variables
2025-05-19 20:05:31,018:INFO:Importing untrained model
2025-05-19 20:05:31,025:INFO:Naive Bayes Imported successfully
2025-05-19 20:05:31,037:INFO:Starting cross validation
2025-05-19 20:05:31,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:31,722:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,724:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,754:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,765:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,876:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:31,981:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,010:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,111:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,168:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,207:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:32,224:INFO:Calculating mean and std
2025-05-19 20:05:32,227:INFO:Creating metrics dataframe
2025-05-19 20:05:32,231:INFO:Uploading results into container
2025-05-19 20:05:32,233:INFO:Uploading model into container now
2025-05-19 20:05:32,234:INFO:_master_model_container: 3
2025-05-19 20:05:32,234:INFO:_display_container: 2
2025-05-19 20:05:32,235:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 20:05:32,235:INFO:create_model() successfully completed......................................
2025-05-19 20:05:32,339:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:32,340:INFO:Creating metrics dataframe
2025-05-19 20:05:32,352:INFO:Initializing Decision Tree Classifier
2025-05-19 20:05:32,353:INFO:Total runtime is 0.2616799831390381 minutes
2025-05-19 20:05:32,358:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:32,358:INFO:Initializing create_model()
2025-05-19 20:05:32,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:32,359:INFO:Checking exceptions
2025-05-19 20:05:32,359:INFO:Importing libraries
2025-05-19 20:05:32,359:INFO:Copying training dataset
2025-05-19 20:05:32,367:INFO:Defining folds
2025-05-19 20:05:32,367:INFO:Declaring metric variables
2025-05-19 20:05:32,377:INFO:Importing untrained model
2025-05-19 20:05:32,386:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:05:32,398:INFO:Starting cross validation
2025-05-19 20:05:32,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:33,694:INFO:Calculating mean and std
2025-05-19 20:05:33,696:INFO:Creating metrics dataframe
2025-05-19 20:05:33,699:INFO:Uploading results into container
2025-05-19 20:05:33,701:INFO:Uploading model into container now
2025-05-19 20:05:33,702:INFO:_master_model_container: 4
2025-05-19 20:05:33,702:INFO:_display_container: 2
2025-05-19 20:05:33,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:33,703:INFO:create_model() successfully completed......................................
2025-05-19 20:05:33,792:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:33,792:INFO:Creating metrics dataframe
2025-05-19 20:05:33,802:INFO:Initializing SVM - Linear Kernel
2025-05-19 20:05:33,803:INFO:Total runtime is 0.28585828940073654 minutes
2025-05-19 20:05:33,807:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:33,807:INFO:Initializing create_model()
2025-05-19 20:05:33,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:33,808:INFO:Checking exceptions
2025-05-19 20:05:33,808:INFO:Importing libraries
2025-05-19 20:05:33,808:INFO:Copying training dataset
2025-05-19 20:05:33,814:INFO:Defining folds
2025-05-19 20:05:33,814:INFO:Declaring metric variables
2025-05-19 20:05:33,819:INFO:Importing untrained model
2025-05-19 20:05:33,826:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 20:05:33,838:INFO:Starting cross validation
2025-05-19 20:05:33,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:34,566:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,571:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,740:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:34,860:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,073:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,085:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:35,099:INFO:Calculating mean and std
2025-05-19 20:05:35,101:INFO:Creating metrics dataframe
2025-05-19 20:05:35,106:INFO:Uploading results into container
2025-05-19 20:05:35,107:INFO:Uploading model into container now
2025-05-19 20:05:35,109:INFO:_master_model_container: 5
2025-05-19 20:05:35,109:INFO:_display_container: 2
2025-05-19 20:05:35,111:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 20:05:35,111:INFO:create_model() successfully completed......................................
2025-05-19 20:05:35,220:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:35,220:INFO:Creating metrics dataframe
2025-05-19 20:05:35,244:INFO:Initializing Ridge Classifier
2025-05-19 20:05:35,244:INFO:Total runtime is 0.3098706444104513 minutes
2025-05-19 20:05:35,250:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:35,250:INFO:Initializing create_model()
2025-05-19 20:05:35,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:35,250:INFO:Checking exceptions
2025-05-19 20:05:35,251:INFO:Importing libraries
2025-05-19 20:05:35,251:INFO:Copying training dataset
2025-05-19 20:05:35,258:INFO:Defining folds
2025-05-19 20:05:35,258:INFO:Declaring metric variables
2025-05-19 20:05:35,263:INFO:Importing untrained model
2025-05-19 20:05:35,271:INFO:Ridge Classifier Imported successfully
2025-05-19 20:05:35,285:INFO:Starting cross validation
2025-05-19 20:05:35,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:36,039:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,047:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,057:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,059:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,223:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,226:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,372:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,378:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,546:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,560:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:36,576:INFO:Calculating mean and std
2025-05-19 20:05:36,579:INFO:Creating metrics dataframe
2025-05-19 20:05:36,583:INFO:Uploading results into container
2025-05-19 20:05:36,584:INFO:Uploading model into container now
2025-05-19 20:05:36,585:INFO:_master_model_container: 6
2025-05-19 20:05:36,585:INFO:_display_container: 2
2025-05-19 20:05:36,585:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 20:05:36,586:INFO:create_model() successfully completed......................................
2025-05-19 20:05:36,680:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:36,680:INFO:Creating metrics dataframe
2025-05-19 20:05:36,691:INFO:Initializing Random Forest Classifier
2025-05-19 20:05:36,691:INFO:Total runtime is 0.33399424950281786 minutes
2025-05-19 20:05:36,696:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:36,696:INFO:Initializing create_model()
2025-05-19 20:05:36,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:36,697:INFO:Checking exceptions
2025-05-19 20:05:36,697:INFO:Importing libraries
2025-05-19 20:05:36,697:INFO:Copying training dataset
2025-05-19 20:05:36,703:INFO:Defining folds
2025-05-19 20:05:36,703:INFO:Declaring metric variables
2025-05-19 20:05:36,709:INFO:Importing untrained model
2025-05-19 20:05:36,716:INFO:Random Forest Classifier Imported successfully
2025-05-19 20:05:36,726:INFO:Starting cross validation
2025-05-19 20:05:36,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:38,783:INFO:Calculating mean and std
2025-05-19 20:05:38,785:INFO:Creating metrics dataframe
2025-05-19 20:05:38,788:INFO:Uploading results into container
2025-05-19 20:05:38,789:INFO:Uploading model into container now
2025-05-19 20:05:38,791:INFO:_master_model_container: 7
2025-05-19 20:05:38,792:INFO:_display_container: 2
2025-05-19 20:05:38,793:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 20:05:38,794:INFO:create_model() successfully completed......................................
2025-05-19 20:05:38,879:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:38,880:INFO:Creating metrics dataframe
2025-05-19 20:05:38,890:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 20:05:38,890:INFO:Total runtime is 0.37062769333521534 minutes
2025-05-19 20:05:38,896:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:38,896:INFO:Initializing create_model()
2025-05-19 20:05:38,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:38,896:INFO:Checking exceptions
2025-05-19 20:05:38,896:INFO:Importing libraries
2025-05-19 20:05:38,896:INFO:Copying training dataset
2025-05-19 20:05:38,900:INFO:Defining folds
2025-05-19 20:05:38,900:INFO:Declaring metric variables
2025-05-19 20:05:38,906:INFO:Importing untrained model
2025-05-19 20:05:38,913:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 20:05:38,922:INFO:Starting cross validation
2025-05-19 20:05:38,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:39,600:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,603:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,608:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,621:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,757:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,763:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,914:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:39,924:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,135:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,138:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:40,155:INFO:Calculating mean and std
2025-05-19 20:05:40,157:INFO:Creating metrics dataframe
2025-05-19 20:05:40,162:INFO:Uploading results into container
2025-05-19 20:05:40,163:INFO:Uploading model into container now
2025-05-19 20:05:40,164:INFO:_master_model_container: 8
2025-05-19 20:05:40,164:INFO:_display_container: 2
2025-05-19 20:05:40,165:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 20:05:40,165:INFO:create_model() successfully completed......................................
2025-05-19 20:05:40,273:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:40,273:INFO:Creating metrics dataframe
2025-05-19 20:05:40,293:INFO:Initializing Ada Boost Classifier
2025-05-19 20:05:40,293:INFO:Total runtime is 0.3940156221389771 minutes
2025-05-19 20:05:40,299:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:40,299:INFO:Initializing create_model()
2025-05-19 20:05:40,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:40,299:INFO:Checking exceptions
2025-05-19 20:05:40,300:INFO:Importing libraries
2025-05-19 20:05:40,300:INFO:Copying training dataset
2025-05-19 20:05:40,308:INFO:Defining folds
2025-05-19 20:05:40,308:INFO:Declaring metric variables
2025-05-19 20:05:40,314:INFO:Importing untrained model
2025-05-19 20:05:40,322:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:05:40,348:INFO:Starting cross validation
2025-05-19 20:05:40,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:40,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:40,970:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,423:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,567:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,648:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,692:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,957:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:41,958:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:05:42,024:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:42,189:INFO:Calculating mean and std
2025-05-19 20:05:42,196:INFO:Creating metrics dataframe
2025-05-19 20:05:42,216:INFO:Uploading results into container
2025-05-19 20:05:42,220:INFO:Uploading model into container now
2025-05-19 20:05:42,221:INFO:_master_model_container: 9
2025-05-19 20:05:42,222:INFO:_display_container: 2
2025-05-19 20:05:42,223:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:05:42,223:INFO:create_model() successfully completed......................................
2025-05-19 20:05:42,321:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:42,321:INFO:Creating metrics dataframe
2025-05-19 20:05:42,333:INFO:Initializing Gradient Boosting Classifier
2025-05-19 20:05:42,334:INFO:Total runtime is 0.42803772687911995 minutes
2025-05-19 20:05:42,338:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:42,339:INFO:Initializing create_model()
2025-05-19 20:05:42,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:42,339:INFO:Checking exceptions
2025-05-19 20:05:42,340:INFO:Importing libraries
2025-05-19 20:05:42,340:INFO:Copying training dataset
2025-05-19 20:05:42,348:INFO:Defining folds
2025-05-19 20:05:42,348:INFO:Declaring metric variables
2025-05-19 20:05:42,355:INFO:Importing untrained model
2025-05-19 20:05:42,363:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 20:05:42,372:INFO:Starting cross validation
2025-05-19 20:05:42,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:43,944:INFO:Calculating mean and std
2025-05-19 20:05:43,946:INFO:Creating metrics dataframe
2025-05-19 20:05:43,948:INFO:Uploading results into container
2025-05-19 20:05:43,949:INFO:Uploading model into container now
2025-05-19 20:05:43,950:INFO:_master_model_container: 10
2025-05-19 20:05:43,950:INFO:_display_container: 2
2025-05-19 20:05:43,951:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 20:05:43,951:INFO:create_model() successfully completed......................................
2025-05-19 20:05:44,035:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:44,035:INFO:Creating metrics dataframe
2025-05-19 20:05:44,049:INFO:Initializing Linear Discriminant Analysis
2025-05-19 20:05:44,050:INFO:Total runtime is 0.45663642883300787 minutes
2025-05-19 20:05:44,055:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:44,055:INFO:Initializing create_model()
2025-05-19 20:05:44,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:44,055:INFO:Checking exceptions
2025-05-19 20:05:44,056:INFO:Importing libraries
2025-05-19 20:05:44,056:INFO:Copying training dataset
2025-05-19 20:05:44,062:INFO:Defining folds
2025-05-19 20:05:44,062:INFO:Declaring metric variables
2025-05-19 20:05:44,067:INFO:Importing untrained model
2025-05-19 20:05:44,072:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 20:05:44,083:INFO:Starting cross validation
2025-05-19 20:05:44,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:44,757:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,764:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,770:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:44,797:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,020:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,208:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,285:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,286:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,461:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,462:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:45,479:INFO:Calculating mean and std
2025-05-19 20:05:45,482:INFO:Creating metrics dataframe
2025-05-19 20:05:45,486:INFO:Uploading results into container
2025-05-19 20:05:45,487:INFO:Uploading model into container now
2025-05-19 20:05:45,488:INFO:_master_model_container: 11
2025-05-19 20:05:45,488:INFO:_display_container: 2
2025-05-19 20:05:45,489:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 20:05:45,489:INFO:create_model() successfully completed......................................
2025-05-19 20:05:45,600:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:45,601:INFO:Creating metrics dataframe
2025-05-19 20:05:45,617:INFO:Initializing Extra Trees Classifier
2025-05-19 20:05:45,617:INFO:Total runtime is 0.48275386095047 minutes
2025-05-19 20:05:45,624:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:45,624:INFO:Initializing create_model()
2025-05-19 20:05:45,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:45,625:INFO:Checking exceptions
2025-05-19 20:05:45,625:INFO:Importing libraries
2025-05-19 20:05:45,625:INFO:Copying training dataset
2025-05-19 20:05:45,631:INFO:Defining folds
2025-05-19 20:05:45,631:INFO:Declaring metric variables
2025-05-19 20:05:45,636:INFO:Importing untrained model
2025-05-19 20:05:45,644:INFO:Extra Trees Classifier Imported successfully
2025-05-19 20:05:45,655:INFO:Starting cross validation
2025-05-19 20:05:45,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:47,587:INFO:Calculating mean and std
2025-05-19 20:05:47,588:INFO:Creating metrics dataframe
2025-05-19 20:05:47,591:INFO:Uploading results into container
2025-05-19 20:05:47,591:INFO:Uploading model into container now
2025-05-19 20:05:47,592:INFO:_master_model_container: 12
2025-05-19 20:05:47,592:INFO:_display_container: 2
2025-05-19 20:05:47,593:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 20:05:47,593:INFO:create_model() successfully completed......................................
2025-05-19 20:05:47,674:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:47,674:INFO:Creating metrics dataframe
2025-05-19 20:05:47,687:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 20:05:47,687:INFO:Total runtime is 0.5172545711199443 minutes
2025-05-19 20:05:47,692:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:47,692:INFO:Initializing create_model()
2025-05-19 20:05:47,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:47,693:INFO:Checking exceptions
2025-05-19 20:05:47,693:INFO:Importing libraries
2025-05-19 20:05:47,693:INFO:Copying training dataset
2025-05-19 20:05:47,698:INFO:Defining folds
2025-05-19 20:05:47,698:INFO:Declaring metric variables
2025-05-19 20:05:47,703:INFO:Importing untrained model
2025-05-19 20:05:47,709:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 20:05:47,716:INFO:Starting cross validation
2025-05-19 20:05:47,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:48,651:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,704:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,744:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:48,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:49,301:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:49,326:INFO:Calculating mean and std
2025-05-19 20:05:49,329:INFO:Creating metrics dataframe
2025-05-19 20:05:49,335:INFO:Uploading results into container
2025-05-19 20:05:49,336:INFO:Uploading model into container now
2025-05-19 20:05:49,337:INFO:_master_model_container: 13
2025-05-19 20:05:49,337:INFO:_display_container: 2
2025-05-19 20:05:49,339:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 20:05:49,339:INFO:create_model() successfully completed......................................
2025-05-19 20:05:49,458:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:49,458:INFO:Creating metrics dataframe
2025-05-19 20:05:49,471:INFO:Initializing Dummy Classifier
2025-05-19 20:05:49,471:INFO:Total runtime is 0.5469799002011618 minutes
2025-05-19 20:05:49,477:INFO:SubProcess create_model() called ==================================
2025-05-19 20:05:49,478:INFO:Initializing create_model()
2025-05-19 20:05:49,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599BBF7050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:49,478:INFO:Checking exceptions
2025-05-19 20:05:49,478:INFO:Importing libraries
2025-05-19 20:05:49,478:INFO:Copying training dataset
2025-05-19 20:05:49,485:INFO:Defining folds
2025-05-19 20:05:49,485:INFO:Declaring metric variables
2025-05-19 20:05:49,494:INFO:Importing untrained model
2025-05-19 20:05:49,499:INFO:Dummy Classifier Imported successfully
2025-05-19 20:05:49,514:INFO:Starting cross validation
2025-05-19 20:05:49,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:05:50,413:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,427:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,455:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,597:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,835:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:50,997:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,021:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,187:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,241:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,245:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:05:51,259:INFO:Calculating mean and std
2025-05-19 20:05:51,261:INFO:Creating metrics dataframe
2025-05-19 20:05:51,266:INFO:Uploading results into container
2025-05-19 20:05:51,267:INFO:Uploading model into container now
2025-05-19 20:05:51,269:INFO:_master_model_container: 14
2025-05-19 20:05:51,269:INFO:_display_container: 2
2025-05-19 20:05:51,269:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 20:05:51,269:INFO:create_model() successfully completed......................................
2025-05-19 20:05:51,380:INFO:SubProcess create_model() end ==================================
2025-05-19 20:05:51,380:INFO:Creating metrics dataframe
2025-05-19 20:05:51,403:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 20:05:51,421:INFO:Initializing create_model()
2025-05-19 20:05:51,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:05:51,421:INFO:Checking exceptions
2025-05-19 20:05:51,426:INFO:Importing libraries
2025-05-19 20:05:51,426:INFO:Copying training dataset
2025-05-19 20:05:51,467:INFO:Defining folds
2025-05-19 20:05:51,467:INFO:Declaring metric variables
2025-05-19 20:05:51,468:INFO:Importing untrained model
2025-05-19 20:05:51,468:INFO:Declaring custom model
2025-05-19 20:05:51,469:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:05:51,508:INFO:Cross validation set to False
2025-05-19 20:05:51,508:INFO:Fitting Model
2025-05-19 20:05:51,709:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:05:51,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.
2025-05-19 20:05:51,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:05:51,710:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:05:51,711:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:05:51,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:05:51,783:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:51,783:INFO:create_model() successfully completed......................................
2025-05-19 20:05:51,955:INFO:_master_model_container: 14
2025-05-19 20:05:51,955:INFO:_display_container: 2
2025-05-19 20:05:51,956:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:05:51,956:INFO:compare_models() successfully completed......................................
2025-05-19 20:24:57,322:INFO:Initializing tune_model()
2025-05-19 20:24:57,322:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:24:57,322:INFO:Checking exceptions
2025-05-19 20:24:57,360:INFO:Copying training dataset
2025-05-19 20:24:57,366:INFO:Checking base model
2025-05-19 20:24:57,366:INFO:Base model : Decision Tree Classifier
2025-05-19 20:24:57,370:INFO:Declaring metric variables
2025-05-19 20:24:57,376:INFO:Defining Hyperparameters
2025-05-19 20:24:57,568:INFO:Tuning with n_jobs=-1
2025-05-19 20:24:57,569:INFO:Initializing RandomizedSearchCV
2025-05-19 20:25:20,475:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 20:25:20,476:INFO:Hyperparameter search completed
2025-05-19 20:25:20,477:INFO:SubProcess create_model() called ==================================
2025-05-19 20:25:20,478:INFO:Initializing create_model()
2025-05-19 20:25:20,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000259961ED3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 20:25:20,479:INFO:Checking exceptions
2025-05-19 20:25:20,480:INFO:Importing libraries
2025-05-19 20:25:20,480:INFO:Copying training dataset
2025-05-19 20:25:20,493:INFO:Defining folds
2025-05-19 20:25:20,494:INFO:Declaring metric variables
2025-05-19 20:25:20,503:INFO:Importing untrained model
2025-05-19 20:25:20,504:INFO:Declaring custom model
2025-05-19 20:25:20,513:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:25:20,531:INFO:Starting cross validation
2025-05-19 20:25:20,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:25:21,529:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:25:22,058:INFO:Calculating mean and std
2025-05-19 20:25:22,060:INFO:Creating metrics dataframe
2025-05-19 20:25:22,069:INFO:Finalizing model
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2025-05-19 20:25:22,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:25:22,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:25:22,220:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:25:22,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:25:22,221:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:25:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:22,266:INFO:Uploading results into container
2025-05-19 20:25:22,267:INFO:Uploading model into container now
2025-05-19 20:25:22,268:INFO:_master_model_container: 15
2025-05-19 20:25:22,268:INFO:_display_container: 3
2025-05-19 20:25:22,269:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:22,270:INFO:create_model() successfully completed......................................
2025-05-19 20:25:22,391:INFO:SubProcess create_model() end ==================================
2025-05-19 20:25:22,391:INFO:choose_better activated
2025-05-19 20:25:22,394:INFO:SubProcess create_model() called ==================================
2025-05-19 20:25:22,395:INFO:Initializing create_model()
2025-05-19 20:25:22,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:25:22,395:INFO:Checking exceptions
2025-05-19 20:25:22,397:INFO:Importing libraries
2025-05-19 20:25:22,397:INFO:Copying training dataset
2025-05-19 20:25:22,401:INFO:Defining folds
2025-05-19 20:25:22,401:INFO:Declaring metric variables
2025-05-19 20:25:22,401:INFO:Importing untrained model
2025-05-19 20:25:22,401:INFO:Declaring custom model
2025-05-19 20:25:22,402:INFO:Decision Tree Classifier Imported successfully
2025-05-19 20:25:22,403:INFO:Starting cross validation
2025-05-19 20:25:22,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:25:23,485:INFO:Calculating mean and std
2025-05-19 20:25:23,486:INFO:Creating metrics dataframe
2025-05-19 20:25:23,492:INFO:Finalizing model
2025-05-19 20:25:23,630:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:25:23,630:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.
2025-05-19 20:25:23,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:25:23,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:25:23,631:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:25:23,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:25:23,670:INFO:Uploading results into container
2025-05-19 20:25:23,670:INFO:Uploading model into container now
2025-05-19 20:25:23,671:INFO:_master_model_container: 16
2025-05-19 20:25:23,671:INFO:_display_container: 4
2025-05-19 20:25:23,672:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:23,672:INFO:create_model() successfully completed......................................
2025-05-19 20:25:23,768:INFO:SubProcess create_model() end ==================================
2025-05-19 20:25:23,769:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-05-19 20:25:23,769:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-05-19 20:25:23,770:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 20:25:23,770:INFO:choose_better completed
2025-05-19 20:25:23,771:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:25:23,783:INFO:_master_model_container: 16
2025-05-19 20:25:23,784:INFO:_display_container: 3
2025-05-19 20:25:23,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 20:25:23,784:INFO:tune_model() successfully completed......................................
2025-05-19 20:25:23,896:INFO:Initializing plot_model()
2025-05-19 20:25:23,897:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:25:23,897:INFO:Checking exceptions
2025-05-19 20:25:23,901:INFO:Preloading libraries
2025-05-19 20:25:23,902:INFO:Copying training dataset
2025-05-19 20:25:23,902:INFO:Plot type: pr
2025-05-19 20:25:24,069:INFO:Fitting Model
2025-05-19 20:25:24,110:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:25:24,111:INFO:Scoring test/hold-out set
2025-05-19 20:25:24,335:INFO:Visual Rendered Successfully
2025-05-19 20:25:24,413:INFO:plot_model() successfully completed......................................
2025-05-19 20:25:24,414:INFO:Initializing plot_model()
2025-05-19 20:25:24,414:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:25:24,414:INFO:Checking exceptions
2025-05-19 20:25:24,418:INFO:Preloading libraries
2025-05-19 20:25:24,418:INFO:Copying training dataset
2025-05-19 20:25:24,418:INFO:Plot type: confusion_matrix
2025-05-19 20:25:24,562:INFO:Fitting Model
2025-05-19 20:25:24,562:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:25:24,563:INFO:Scoring test/hold-out set
2025-05-19 20:25:24,727:INFO:Visual Rendered Successfully
2025-05-19 20:25:24,816:INFO:plot_model() successfully completed......................................
2025-05-19 20:27:33,335:INFO:Initializing create_model()
2025-05-19 20:27:33,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:27:33,336:INFO:Checking exceptions
2025-05-19 20:27:33,365:INFO:Importing libraries
2025-05-19 20:27:33,365:INFO:Copying training dataset
2025-05-19 20:27:33,379:INFO:Defining folds
2025-05-19 20:27:33,379:INFO:Declaring metric variables
2025-05-19 20:27:33,384:INFO:Importing untrained model
2025-05-19 20:27:33,389:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:27:33,402:INFO:Starting cross validation
2025-05-19 20:27:33,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:27:34,170:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,182:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,183:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,222:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,308:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,351:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,527:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,587:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,961:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:34,987:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:35,038:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:27:35,172:INFO:Calculating mean and std
2025-05-19 20:27:35,173:INFO:Creating metrics dataframe
2025-05-19 20:27:35,178:INFO:Finalizing model
2025-05-19 20:27:35,300:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.
2025-05-19 20:27:35,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:27:35,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:27:35,301:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:27:35,302:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:27:35,302:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:27:35,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:27:35,350:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:27:35,480:INFO:Uploading results into container
2025-05-19 20:27:35,482:INFO:Uploading model into container now
2025-05-19 20:27:35,494:INFO:_master_model_container: 17
2025-05-19 20:27:35,494:INFO:_display_container: 4
2025-05-19 20:27:35,495:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:27:35,495:INFO:create_model() successfully completed......................................
2025-05-19 20:29:26,910:INFO:Initializing tune_model()
2025-05-19 20:29:26,910:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:29:26,911:INFO:Checking exceptions
2025-05-19 20:29:26,946:INFO:Copying training dataset
2025-05-19 20:29:26,953:INFO:Checking base model
2025-05-19 20:29:26,953:INFO:Base model : Ada Boost Classifier
2025-05-19 20:29:26,959:INFO:Declaring metric variables
2025-05-19 20:29:26,965:INFO:Defining Hyperparameters
2025-05-19 20:29:27,126:INFO:Tuning with n_jobs=-1
2025-05-19 20:29:27,126:INFO:Initializing RandomizedSearchCV
2025-05-19 20:29:44,282:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:29:44,284:INFO:Hyperparameter search completed
2025-05-19 20:29:44,284:INFO:SubProcess create_model() called ==================================
2025-05-19 20:29:44,285:INFO:Initializing create_model()
2025-05-19 20:29:44,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025997B18DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:29:44,286:INFO:Checking exceptions
2025-05-19 20:29:44,286:INFO:Importing libraries
2025-05-19 20:29:44,287:INFO:Copying training dataset
2025-05-19 20:29:44,295:INFO:Defining folds
2025-05-19 20:29:44,295:INFO:Declaring metric variables
2025-05-19 20:29:44,301:INFO:Importing untrained model
2025-05-19 20:29:44,301:INFO:Declaring custom model
2025-05-19 20:29:44,309:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:44,328:INFO:Starting cross validation
2025-05-19 20:29:44,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:46,917:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:46,952:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:46,991:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:47,142:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,105:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,226:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,228:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:48,241:INFO:Calculating mean and std
2025-05-19 20:29:48,242:INFO:Creating metrics dataframe
2025-05-19 20:29:48,248:INFO:Finalizing model
2025-05-19 20:29:48,383:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:48,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2025-05-19 20:29:48,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:48,384:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:48,823:INFO:Uploading results into container
2025-05-19 20:29:48,824:INFO:Uploading model into container now
2025-05-19 20:29:48,825:INFO:_master_model_container: 18
2025-05-19 20:29:48,825:INFO:_display_container: 5
2025-05-19 20:29:48,825:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:29:48,825:INFO:create_model() successfully completed......................................
2025-05-19 20:29:48,913:INFO:SubProcess create_model() end ==================================
2025-05-19 20:29:48,913:INFO:choose_better activated
2025-05-19 20:29:48,916:INFO:SubProcess create_model() called ==================================
2025-05-19 20:29:48,917:INFO:Initializing create_model()
2025-05-19 20:29:48,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:29:48,917:INFO:Checking exceptions
2025-05-19 20:29:48,918:INFO:Importing libraries
2025-05-19 20:29:48,918:INFO:Copying training dataset
2025-05-19 20:29:48,923:INFO:Defining folds
2025-05-19 20:29:48,923:INFO:Declaring metric variables
2025-05-19 20:29:48,923:INFO:Importing untrained model
2025-05-19 20:29:48,923:INFO:Declaring custom model
2025-05-19 20:29:48,924:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:48,924:INFO:Starting cross validation
2025-05-19 20:29:48,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:49,426:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,445:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,567:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,864:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,904:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:49,995:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,162:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,220:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,239:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:50,457:INFO:Calculating mean and std
2025-05-19 20:29:50,457:INFO:Creating metrics dataframe
2025-05-19 20:29:50,459:INFO:Finalizing model
2025-05-19 20:29:50,592:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:50,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2025-05-19 20:29:50,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:29:50,593:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:29:50,593:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:50,593:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:50,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:50,594:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:50,628:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:50,749:INFO:Uploading results into container
2025-05-19 20:29:50,750:INFO:Uploading model into container now
2025-05-19 20:29:50,750:INFO:_master_model_container: 19
2025-05-19 20:29:50,750:INFO:_display_container: 6
2025-05-19 20:29:50,750:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:50,750:INFO:create_model() successfully completed......................................
2025-05-19 20:29:50,832:INFO:SubProcess create_model() end ==================================
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for F1 is 0.3167
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for F1 is 0.15
2025-05-19 20:29:50,833:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:29:50,833:INFO:choose_better completed
2025-05-19 20:29:50,834:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:29:50,846:INFO:_master_model_container: 19
2025-05-19 20:29:50,846:INFO:_display_container: 5
2025-05-19 20:29:50,846:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:50,847:INFO:tune_model() successfully completed......................................
2025-05-19 20:29:50,934:INFO:Initializing plot_model()
2025-05-19 20:29:50,934:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:29:50,934:INFO:Checking exceptions
2025-05-19 20:29:50,942:INFO:Preloading libraries
2025-05-19 20:29:50,948:INFO:Copying training dataset
2025-05-19 20:29:50,948:INFO:Plot type: pr
2025-05-19 20:29:51,141:INFO:Fitting Model
2025-05-19 20:29:51,142:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:29:51,143:INFO:Scoring test/hold-out set
2025-05-19 20:29:51,423:INFO:Visual Rendered Successfully
2025-05-19 20:29:51,513:INFO:plot_model() successfully completed......................................
2025-05-19 20:29:51,514:INFO:Initializing plot_model()
2025-05-19 20:29:51,514:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:29:51,514:INFO:Checking exceptions
2025-05-19 20:29:51,519:INFO:Preloading libraries
2025-05-19 20:29:51,527:INFO:Copying training dataset
2025-05-19 20:29:51,527:INFO:Plot type: confusion_matrix
2025-05-19 20:29:51,684:INFO:Fitting Model
2025-05-19 20:29:51,684:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:29:51,684:INFO:Scoring test/hold-out set
2025-05-19 20:29:51,923:INFO:Visual Rendered Successfully
2025-05-19 20:29:52,049:INFO:plot_model() successfully completed......................................
2025-05-19 20:29:52,049:INFO:Initializing create_model()
2025-05-19 20:29:52,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:29:52,050:INFO:Checking exceptions
2025-05-19 20:29:52,077:INFO:Importing libraries
2025-05-19 20:29:52,078:INFO:Copying training dataset
2025-05-19 20:29:52,090:INFO:Defining folds
2025-05-19 20:29:52,091:INFO:Declaring metric variables
2025-05-19 20:29:52,107:INFO:Importing untrained model
2025-05-19 20:29:52,114:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:29:52,127:INFO:Starting cross validation
2025-05-19 20:29:52,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:29:52,864:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,873:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,897:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:52,905:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,032:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,034:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,220:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,281:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,524:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,573:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:53,595:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:29:53,795:INFO:Calculating mean and std
2025-05-19 20:29:53,797:INFO:Creating metrics dataframe
2025-05-19 20:29:53,805:INFO:Finalizing model
2025-05-19 20:29:53,986:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:29:53,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.
2025-05-19 20:29:53,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:29:53,987:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:29:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:29:54,114:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:29:54,268:INFO:Uploading results into container
2025-05-19 20:29:54,269:INFO:Uploading model into container now
2025-05-19 20:29:54,286:INFO:_master_model_container: 20
2025-05-19 20:29:54,286:INFO:_display_container: 6
2025-05-19 20:29:54,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:29:54,287:INFO:create_model() successfully completed......................................
2025-05-19 20:30:02,724:INFO:Initializing create_model()
2025-05-19 20:30:02,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:02,724:INFO:Checking exceptions
2025-05-19 20:30:02,747:INFO:Importing libraries
2025-05-19 20:30:02,748:INFO:Copying training dataset
2025-05-19 20:30:02,758:INFO:Defining folds
2025-05-19 20:30:02,759:INFO:Declaring metric variables
2025-05-19 20:30:02,766:INFO:Importing untrained model
2025-05-19 20:30:02,774:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:02,787:INFO:Starting cross validation
2025-05-19 20:30:02,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:03,603:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,605:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,607:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,622:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,749:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:03,790:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,048:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,149:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,309:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,341:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,471:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:04,609:INFO:Calculating mean and std
2025-05-19 20:30:04,611:INFO:Creating metrics dataframe
2025-05-19 20:30:04,618:INFO:Finalizing model
2025-05-19 20:30:04,782:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:04,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-05-19 20:30:04,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:04,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:04,783:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:04,847:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:04,977:INFO:Uploading results into container
2025-05-19 20:30:04,978:INFO:Uploading model into container now
2025-05-19 20:30:04,993:INFO:_master_model_container: 21
2025-05-19 20:30:04,993:INFO:_display_container: 7
2025-05-19 20:30:04,994:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:04,994:INFO:create_model() successfully completed......................................
2025-05-19 20:30:05,099:INFO:Initializing tune_model()
2025-05-19 20:30:05,100:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:30:05,100:INFO:Checking exceptions
2025-05-19 20:30:05,121:INFO:Copying training dataset
2025-05-19 20:30:05,126:INFO:Checking base model
2025-05-19 20:30:05,127:INFO:Base model : Ada Boost Classifier
2025-05-19 20:30:05,132:INFO:Declaring metric variables
2025-05-19 20:30:05,139:INFO:Defining Hyperparameters
2025-05-19 20:30:05,246:INFO:Tuning with n_jobs=-1
2025-05-19 20:30:05,246:INFO:Initializing RandomizedSearchCV
2025-05-19 20:30:31,104:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:30:31,106:INFO:Hyperparameter search completed
2025-05-19 20:30:31,106:INFO:SubProcess create_model() called ==================================
2025-05-19 20:30:31,108:INFO:Initializing create_model()
2025-05-19 20:30:31,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000259F40470D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:30:31,108:INFO:Checking exceptions
2025-05-19 20:30:31,109:INFO:Importing libraries
2025-05-19 20:30:31,109:INFO:Copying training dataset
2025-05-19 20:30:31,126:INFO:Defining folds
2025-05-19 20:30:31,126:INFO:Declaring metric variables
2025-05-19 20:30:31,134:INFO:Importing untrained model
2025-05-19 20:30:31,134:INFO:Declaring custom model
2025-05-19 20:30:31,142:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:31,173:INFO:Starting cross validation
2025-05-19 20:30:31,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:33,634:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,143:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,425:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:34,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,356:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,480:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,552:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:35,561:INFO:Calculating mean and std
2025-05-19 20:30:35,563:INFO:Creating metrics dataframe
2025-05-19 20:30:35,574:INFO:Finalizing model
2025-05-19 20:30:35,841:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000063 seconds.
2025-05-19 20:30:35,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:35,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:35,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:35,843:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:36,517:INFO:Uploading results into container
2025-05-19 20:30:36,518:INFO:Uploading model into container now
2025-05-19 20:30:36,519:INFO:_master_model_container: 22
2025-05-19 20:30:36,519:INFO:_display_container: 8
2025-05-19 20:30:36,520:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:30:36,520:INFO:create_model() successfully completed......................................
2025-05-19 20:30:36,648:INFO:SubProcess create_model() end ==================================
2025-05-19 20:30:36,649:INFO:choose_better activated
2025-05-19 20:30:36,656:INFO:SubProcess create_model() called ==================================
2025-05-19 20:30:36,656:INFO:Initializing create_model()
2025-05-19 20:30:36,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:36,657:INFO:Checking exceptions
2025-05-19 20:30:36,660:INFO:Importing libraries
2025-05-19 20:30:36,660:INFO:Copying training dataset
2025-05-19 20:30:36,669:INFO:Defining folds
2025-05-19 20:30:36,670:INFO:Declaring metric variables
2025-05-19 20:30:36,670:INFO:Importing untrained model
2025-05-19 20:30:36,670:INFO:Declaring custom model
2025-05-19 20:30:36,671:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:36,671:INFO:Starting cross validation
2025-05-19 20:30:36,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:37,760:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:37,763:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:37,793:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,328:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,354:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,808:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,851:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:38,950:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,054:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,072:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,179:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:39,366:INFO:Calculating mean and std
2025-05-19 20:30:39,367:INFO:Creating metrics dataframe
2025-05-19 20:30:39,373:INFO:Finalizing model
2025-05-19 20:30:39,531:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:39,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.
2025-05-19 20:30:39,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:39,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:39,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:39,534:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:39,578:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:39,708:INFO:Uploading results into container
2025-05-19 20:30:39,708:INFO:Uploading model into container now
2025-05-19 20:30:39,709:INFO:_master_model_container: 23
2025-05-19 20:30:39,709:INFO:_display_container: 9
2025-05-19 20:30:39,709:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:39,709:INFO:create_model() successfully completed......................................
2025-05-19 20:30:39,787:INFO:SubProcess create_model() end ==================================
2025-05-19 20:30:39,788:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for F1 is 0.3167
2025-05-19 20:30:39,788:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for F1 is 0.15
2025-05-19 20:30:39,789:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:30:39,789:INFO:choose_better completed
2025-05-19 20:30:39,789:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:30:39,800:INFO:_master_model_container: 23
2025-05-19 20:30:39,800:INFO:_display_container: 8
2025-05-19 20:30:39,801:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:39,801:INFO:tune_model() successfully completed......................................
2025-05-19 20:30:39,942:INFO:Initializing plot_model()
2025-05-19 20:30:39,942:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:30:39,942:INFO:Checking exceptions
2025-05-19 20:30:39,948:INFO:Preloading libraries
2025-05-19 20:30:39,954:INFO:Copying training dataset
2025-05-19 20:30:39,954:INFO:Plot type: pr
2025-05-19 20:30:40,121:INFO:Fitting Model
2025-05-19 20:30:40,121:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:30:40,121:INFO:Scoring test/hold-out set
2025-05-19 20:30:40,382:INFO:Visual Rendered Successfully
2025-05-19 20:30:40,460:INFO:plot_model() successfully completed......................................
2025-05-19 20:30:40,461:INFO:Initializing plot_model()
2025-05-19 20:30:40,461:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:30:40,461:INFO:Checking exceptions
2025-05-19 20:30:40,467:INFO:Preloading libraries
2025-05-19 20:30:40,473:INFO:Copying training dataset
2025-05-19 20:30:40,473:INFO:Plot type: confusion_matrix
2025-05-19 20:30:40,615:INFO:Fitting Model
2025-05-19 20:30:40,615:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:30:40,616:INFO:Scoring test/hold-out set
2025-05-19 20:30:40,787:INFO:Visual Rendered Successfully
2025-05-19 20:30:40,871:INFO:plot_model() successfully completed......................................
2025-05-19 20:30:43,373:INFO:Initializing create_model()
2025-05-19 20:30:43,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:30:43,374:INFO:Checking exceptions
2025-05-19 20:30:43,396:INFO:Importing libraries
2025-05-19 20:30:43,396:INFO:Copying training dataset
2025-05-19 20:30:43,402:INFO:Defining folds
2025-05-19 20:30:43,403:INFO:Declaring metric variables
2025-05-19 20:30:43,410:INFO:Importing untrained model
2025-05-19 20:30:43,420:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:30:43,430:INFO:Starting cross validation
2025-05-19 20:30:43,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:30:43,983:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:43,991:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,010:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,022:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,169:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,206:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,316:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,320:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,669:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,677:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:44,721:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:44,922:INFO:Calculating mean and std
2025-05-19 20:30:44,924:INFO:Creating metrics dataframe
2025-05-19 20:30:44,930:INFO:Finalizing model
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.
2025-05-19 20:30:45,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:30:45,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:30:45,078:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:30:45,079:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:30:45,120:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:30:45,247:INFO:Uploading results into container
2025-05-19 20:30:45,248:INFO:Uploading model into container now
2025-05-19 20:30:45,261:INFO:_master_model_container: 24
2025-05-19 20:30:45,262:INFO:_display_container: 9
2025-05-19 20:30:45,263:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:30:45,263:INFO:create_model() successfully completed......................................
2025-05-19 20:30:45,353:INFO:Initializing tune_model()
2025-05-19 20:30:45,354:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 20:30:45,354:INFO:Checking exceptions
2025-05-19 20:30:45,373:INFO:Copying training dataset
2025-05-19 20:30:45,378:INFO:Checking base model
2025-05-19 20:30:45,379:INFO:Base model : Ada Boost Classifier
2025-05-19 20:30:45,387:INFO:Declaring metric variables
2025-05-19 20:30:45,393:INFO:Defining Hyperparameters
2025-05-19 20:30:45,501:INFO:Tuning with n_jobs=-1
2025-05-19 20:30:45,501:INFO:Initializing RandomizedSearchCV
2025-05-19 20:30:46,639:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,640:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,650:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,664:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:46,868:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,032:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,284:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:47,501:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,041:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,298:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,630:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:48,729:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:49,453:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,682:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,828:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:50,832:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,000:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,055:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,194:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,203:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:51,865:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,041:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,531:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,543:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,707:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,876:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:52,888:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:53,121:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,071:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,109:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,135:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,262:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:54,537:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,072:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,171:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,266:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,283:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,455:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:55,715:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,591:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:56,865:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,342:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,551:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:57,632:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,063:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,276:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,407:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,572:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,714:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,716:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,775:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:58,963:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,509:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,573:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,712:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:30:59,950:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:00,518:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:00,675:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,150:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,456:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,769:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:01,944:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:02,296:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:02,736:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,070:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,297:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,622:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,803:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:03,863:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,076:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,221:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:04,901:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,021:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,042:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,263:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,469:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,615:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:05,925:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,091:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,466:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,589:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:06,946:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:07,149:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,170:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,297:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,316:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,378:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,398:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:08,402:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 20:31:08,403:INFO:Hyperparameter search completed
2025-05-19 20:31:08,403:INFO:SubProcess create_model() called ==================================
2025-05-19 20:31:08,404:INFO:Initializing create_model()
2025-05-19 20:31:08,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002599A7C4D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 20:31:08,404:INFO:Checking exceptions
2025-05-19 20:31:08,404:INFO:Importing libraries
2025-05-19 20:31:08,405:INFO:Copying training dataset
2025-05-19 20:31:08,414:INFO:Defining folds
2025-05-19 20:31:08,414:INFO:Declaring metric variables
2025-05-19 20:31:08,419:INFO:Importing untrained model
2025-05-19 20:31:08,419:INFO:Declaring custom model
2025-05-19 20:31:08,424:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:31:08,434:INFO:Starting cross validation
2025-05-19 20:31:08,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:31:10,440:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:10,609:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:10,731:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,244:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,434:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,551:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,580:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:11,592:INFO:Calculating mean and std
2025-05-19 20:31:11,598:INFO:Creating metrics dataframe
2025-05-19 20:31:11,616:INFO:Finalizing model
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000062 seconds.
2025-05-19 20:31:11,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:31:11,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:31:11,756:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:31:11,757:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:11,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:12,229:INFO:Uploading results into container
2025-05-19 20:31:12,232:INFO:Uploading model into container now
2025-05-19 20:31:12,233:INFO:_master_model_container: 25
2025-05-19 20:31:12,233:INFO:_display_container: 10
2025-05-19 20:31:12,234:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 20:31:12,234:INFO:create_model() successfully completed......................................
2025-05-19 20:31:12,333:INFO:SubProcess create_model() end ==================================
2025-05-19 20:31:12,333:INFO:choose_better activated
2025-05-19 20:31:12,337:INFO:SubProcess create_model() called ==================================
2025-05-19 20:31:12,338:INFO:Initializing create_model()
2025-05-19 20:31:12,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 20:31:12,338:INFO:Checking exceptions
2025-05-19 20:31:12,340:INFO:Importing libraries
2025-05-19 20:31:12,340:INFO:Copying training dataset
2025-05-19 20:31:12,347:INFO:Defining folds
2025-05-19 20:31:12,348:INFO:Declaring metric variables
2025-05-19 20:31:12,348:INFO:Importing untrained model
2025-05-19 20:31:12,348:INFO:Declaring custom model
2025-05-19 20:31:12,350:INFO:Ada Boost Classifier Imported successfully
2025-05-19 20:31:12,351:INFO:Starting cross validation
2025-05-19 20:31:12,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 20:31:13,008:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,029:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,036:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,098:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,265:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,399:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,540:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,635:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,883:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,923:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:13,979:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 20:31:14,200:INFO:Calculating mean and std
2025-05-19 20:31:14,201:INFO:Creating metrics dataframe
2025-05-19 20:31:14,204:INFO:Finalizing model
2025-05-19 20:31:14,363:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 20:31:14,363:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.
2025-05-19 20:31:14,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 20:31:14,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 20:31:14,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 20:31:14,365:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 20:31:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 20:31:14,409:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 20:31:14,561:INFO:Uploading results into container
2025-05-19 20:31:14,562:INFO:Uploading model into container now
2025-05-19 20:31:14,563:INFO:_master_model_container: 26
2025-05-19 20:31:14,563:INFO:_display_container: 11
2025-05-19 20:31:14,563:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:31:14,563:INFO:create_model() successfully completed......................................
2025-05-19 20:31:14,652:INFO:SubProcess create_model() end ==================================
2025-05-19 20:31:14,652:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for Prec. is 0.4167
2025-05-19 20:31:14,653:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for Prec. is 0.3
2025-05-19 20:31:14,653:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 20:31:14,653:INFO:choose_better completed
2025-05-19 20:31:14,653:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 20:31:14,665:INFO:_master_model_container: 26
2025-05-19 20:31:14,666:INFO:_display_container: 10
2025-05-19 20:31:14,666:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 20:31:14,666:INFO:tune_model() successfully completed......................................
2025-05-19 20:31:14,763:INFO:Initializing plot_model()
2025-05-19 20:31:14,763:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:31:14,763:INFO:Checking exceptions
2025-05-19 20:31:14,768:INFO:Preloading libraries
2025-05-19 20:31:14,774:INFO:Copying training dataset
2025-05-19 20:31:14,774:INFO:Plot type: pr
2025-05-19 20:31:14,924:INFO:Fitting Model
2025-05-19 20:31:14,925:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:31:14,925:INFO:Scoring test/hold-out set
2025-05-19 20:31:15,194:INFO:Visual Rendered Successfully
2025-05-19 20:31:15,281:INFO:plot_model() successfully completed......................................
2025-05-19 20:31:15,281:INFO:Initializing plot_model()
2025-05-19 20:31:15,281:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 20:31:15,281:INFO:Checking exceptions
2025-05-19 20:31:15,287:INFO:Preloading libraries
2025-05-19 20:31:15,293:INFO:Copying training dataset
2025-05-19 20:31:15,294:INFO:Plot type: confusion_matrix
2025-05-19 20:31:15,478:INFO:Fitting Model
2025-05-19 20:31:15,480:WARNING:c:\Users\RAUL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 20:31:15,480:INFO:Scoring test/hold-out set
2025-05-19 20:31:15,678:INFO:Visual Rendered Successfully
2025-05-19 20:31:15,769:INFO:plot_model() successfully completed......................................
2025-05-19 20:31:48,952:INFO:Initializing interpret_model()
2025-05-19 20:31:48,952:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002599BBD2890>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-19 20:31:48,952:INFO:Checking exceptions
2025-05-19 20:31:48,952:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
